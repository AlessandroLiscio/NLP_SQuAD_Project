{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project-X-SQAD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXzTAMPpfB6N"
      },
      "source": [
        "# TODO:\r\n",
        "\r\n",
        "*   Pass tokenizer as function parameter (instead of calling global)\r\n",
        "*   \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6J9_LsBSwk-"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwEFNn5KuGDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c23b80-89db-4cb3-c798-afdae11c45fb"
      },
      "source": [
        "!pip install -q tf-models-official==2.3.0\r\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxC2Vn2KR8pK"
      },
      "source": [
        "import os\r\n",
        "import json, pickle\r\n",
        "\r\n",
        "import re\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import transformers\r\n",
        "from transformers import BertTokenizer, TFBertModel\r\n",
        "transformers.logging.set_verbosity_error() # suppress tokenizer sentences' length warnings so to not disturbate rou beautiful loading bar oh my gosh\r\n",
        "\r\n",
        "from keras import Model\r\n",
        "from keras.utils import plot_model\r\n",
        "from keras.layers import Input, Dense, Flatten\r\n",
        "\r\n",
        "from google.colab import drive, files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--YO7FLemTOD",
        "outputId": "185497ab-ba32-48f6-ef96-a1b422296139"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwEW25ifc3Pt"
      },
      "source": [
        "try:\r\n",
        "  with open('training_set.json') as f:\r\n",
        "    json_data = json.load(f)\r\n",
        "except:\r\n",
        "  with open('/content/drive/My Drive/SQUAD/training_set.json') as f:\r\n",
        "    json_data = json.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG0C8uDPvt0X"
      },
      "source": [
        "# Hyperparameters\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I7Nzb95vvxd"
      },
      "source": [
        "### PARAMETERS ###\r\n",
        "RANDOM_STATE = 42\r\n",
        "\r\n",
        "# Dataset creation\r\n",
        "SEQUENCE_LIMIT = 512\r\n",
        "STRIDE = 256\r\n",
        "\r\n",
        "TRAIN_LIMIT = 3000\r\n",
        "VAL_LIMIT = 1000\r\n",
        "TEST_LIMIT = 1000\r\n",
        "\r\n",
        "# Model Training\r\n",
        "EPOCHS = 1\r\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A23pEgzInJLM"
      },
      "source": [
        "# <s> Dataset </s>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6-zf6cV4e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "bee4aa21-146a-4ef0-84cf-c234bac7f5ec"
      },
      "source": [
        "# Creates DataFrames with useful columns by unpacking 'paragraphs' column\r\n",
        "def preprocess_df(df):\r\n",
        "  temp = []\r\n",
        "  title_dict = {}\r\n",
        "  contexts = []\r\n",
        "\r\n",
        "  for i, row in df.iterrows():\r\n",
        "    for context in row['paragraphs']:\r\n",
        "      contexts.append(context['context'])\r\n",
        "      for qa in context['qas']:\r\n",
        "        question_id = qa['id']\r\n",
        "        question = qa['question']\r\n",
        "        for answer in qa['answers']:\r\n",
        "          answer_text = answer['text']\r\n",
        "          answer_start = answer['answer_start']\r\n",
        "          answer_end = answer_start+len(answer_text)\r\n",
        "          temp.append([question_id, question, answer_text, answer_start, answer_end, i, len(contexts)-1])\r\n",
        "\r\n",
        "  context_dict = dict(enumerate(contexts))\r\n",
        "  df = pd.DataFrame(temp, columns=['question_id', 'question_text', 'answer_text', 'answer_start', 'answer_end', 'title_id', 'context_id'])\r\n",
        "  \r\n",
        "  return df, context_dict\r\n",
        "\r\n",
        "# Read data from json\r\n",
        "data = pd.json_normalize(json_data['data'])\r\n",
        "\r\n",
        "# Split train and test\r\n",
        "train_val, test = train_test_split(data, test_size=0.2, random_state=RANDOM_STATE)\r\n",
        "train, val = train_test_split(train_val, test_size=0.25, random_state=RANDOM_STATE)\r\n",
        "\r\n",
        "# Create DataFrames with useful columns\r\n",
        "train_df, train_context_dict = preprocess_df(train)\r\n",
        "val_df, val_context_dict = preprocess_df(val)\r\n",
        "test_df, test_context_dict = preprocess_df(test)\r\n",
        "\r\n",
        "train_df"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>title_id</th>\n",
              "      <th>context_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5705e78f75f01819005e7734</td>\n",
              "      <td>Where does migration mainly occur?</td>\n",
              "      <td>the northern hemisphere</td>\n",
              "      <td>317</td>\n",
              "      <td>340</td>\n",
              "      <td>109</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5705e78f75f01819005e7735</td>\n",
              "      <td>Why do birds primarily migrate?</td>\n",
              "      <td>availability of food</td>\n",
              "      <td>275</td>\n",
              "      <td>295</td>\n",
              "      <td>109</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5705e78f75f01819005e7736</td>\n",
              "      <td>Which birds migrate?</td>\n",
              "      <td>Many species</td>\n",
              "      <td>127</td>\n",
              "      <td>139</td>\n",
              "      <td>109</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5705e78f75f01819005e7737</td>\n",
              "      <td>What is bird migration?</td>\n",
              "      <td>the regular seasonal movement, often north and...</td>\n",
              "      <td>18</td>\n",
              "      <td>125</td>\n",
              "      <td>109</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5705e78f75f01819005e7738</td>\n",
              "      <td>What is a cause of death to birds during migra...</td>\n",
              "      <td>humans</td>\n",
              "      <td>240</td>\n",
              "      <td>246</td>\n",
              "      <td>109</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49933</th>\n",
              "      <td>57314ace05b4da19006bcfe2</td>\n",
              "      <td>What quality has LEDs been used as?</td>\n",
              "      <td>medium-quality</td>\n",
              "      <td>30</td>\n",
              "      <td>44</td>\n",
              "      <td>417</td>\n",
              "      <td>10869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49934</th>\n",
              "      <td>57314ace05b4da19006bcfe3</td>\n",
              "      <td>What LED has the flattest I/V curve above the ...</td>\n",
              "      <td>Red</td>\n",
              "      <td>216</td>\n",
              "      <td>219</td>\n",
              "      <td>417</td>\n",
              "      <td>10869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49935</th>\n",
              "      <td>57314ace05b4da19006bcfe4</td>\n",
              "      <td>What LEDs have a very steep I/V curve?</td>\n",
              "      <td>Nitride-based LEDs</td>\n",
              "      <td>269</td>\n",
              "      <td>287</td>\n",
              "      <td>417</td>\n",
              "      <td>10869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49936</th>\n",
              "      <td>57314ace05b4da19006bcfe5</td>\n",
              "      <td>LED forward voltage is more current-dependent ...</td>\n",
              "      <td>Zener</td>\n",
              "      <td>418</td>\n",
              "      <td>423</td>\n",
              "      <td>417</td>\n",
              "      <td>10869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49937</th>\n",
              "      <td>57314ace05b4da19006bcfe6</td>\n",
              "      <td>Zener diodes below what voltage are not widely...</td>\n",
              "      <td>3 V</td>\n",
              "      <td>474</td>\n",
              "      <td>477</td>\n",
              "      <td>417</td>\n",
              "      <td>10869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49938 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    question_id  ... context_id\n",
              "0      5705e78f75f01819005e7734  ...          0\n",
              "1      5705e78f75f01819005e7735  ...          0\n",
              "2      5705e78f75f01819005e7736  ...          0\n",
              "3      5705e78f75f01819005e7737  ...          0\n",
              "4      5705e78f75f01819005e7738  ...          0\n",
              "...                         ...  ...        ...\n",
              "49933  57314ace05b4da19006bcfe2  ...      10869\n",
              "49934  57314ace05b4da19006bcfe3  ...      10869\n",
              "49935  57314ace05b4da19006bcfe4  ...      10869\n",
              "49936  57314ace05b4da19006bcfe5  ...      10869\n",
              "49937  57314ace05b4da19006bcfe6  ...      10869\n",
              "\n",
              "[49938 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaUcu-8VyTqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca2dabd-f29b-4cbf-ff1b-fff0ff4cd034"
      },
      "source": [
        "# Inspect data samples\r\n",
        "def print_squad_sample(train_data, context_dict, line_length=120, separator_length=150):\r\n",
        "\r\n",
        "  sample = train_data.sample(frac=1).head(1)\r\n",
        "  context = context_dict[sample['context_id'].item()]\r\n",
        "\r\n",
        "  print('='*separator_length, '\\nCONTEXT:\\n', '='*separator_length)\r\n",
        "\r\n",
        "  lines = [''.join(context[idx:idx+line_length]) for idx in range(0, len(context), line_length)]\r\n",
        "  for l in lines:\r\n",
        "      print(l)\r\n",
        "\r\n",
        "  print('='*separator_length, '\\nQUESTION:', ' '*(3*separator_length//4), 'ANSWER:')\r\n",
        "\r\n",
        "  questions = train_data[train_data['context_id'] == sample['context_id'].item()]\r\n",
        "\r\n",
        "  for idx, row in questions.iterrows():\r\n",
        "    question = row.question_text\r\n",
        "    answer = row.answer_text\r\n",
        "    print(question, ' '*(3*separator_length//4-len(question)+9), answer)\r\n",
        "\r\n",
        "print_squad_sample(train_df, train_context_dict)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================================================================== \n",
            "CONTEXT:\n",
            " ======================================================================================================================================================\n",
            "Approximately 12 million Africans were shipped to the Americas during the Atlantic slave trade from 1492 to 1888, with 1\n",
            "1.5 million of those shipped to South America and the Caribbean. Brazil was the largest importer in the Americas, with 5\n",
            ".5 million African slaves imported, followed by the British Caribbean with 2.76 million, the Spanish Caribbean and Spani\n",
            "sh Mainland with 1.59 million Africans, and the French Caribbean with 1.32 million. Today their descendants number appro\n",
            "ximately 150 million in South America and the Caribbean. In addition to skin color, other physical characteristics such \n",
            "as facial features and hair texture are often variously used in classifying peoples as black in South America and the Ca\n",
            "ribbean. In South America and the Caribbean, classification as black is also closely tied to social status and socioecon\n",
            "omic variables, especially in light of social conceptions of \"blanqueamiento\" (racial whitening) and related concepts.\n",
            "====================================================================================================================================================== \n",
            "QUESTION:                                                                                                                  ANSWER:\n",
            "How many Africans were shipped to the US between 1492 to 1888?                                                             12 million\n",
            "How many were shipped to South America and the Caribbean?                                                                  11.5 million\n",
            "How many slaves were imported by Brazil?                                                                                   5.5 million\n",
            "How many slaves were imported by the British Caribbean?                                                                    2.76 million\n",
            "How is black identified in South America?                                                                                  closely tied to social status and socioeconomic variables,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqrIFmrK2Igt"
      },
      "source": [
        "# <s> Tokenizer </s>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8fuDPtRNDjg",
        "outputId": "96dcfbda-eb23-4a7d-98e1-56123a9d7394"
      },
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n",
        "\r\n",
        "print('[[CLS], [SEP]] = {}'.format(tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]'])))\r\n",
        "\r\n",
        "# Split the sentence into tokens.\r\n",
        "tokenized_text = tokenizer.tokenize(train_df['question_text'][0])\r\n",
        "\r\n",
        "# Print out the tokens.\r\n",
        "print('\\nTokenized sentence:')\r\n",
        "print(tokenized_text)\r\n",
        "\r\n",
        "# Map the token strings to their vocabulary indeces.\r\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\r\n",
        "\r\n",
        "# Display the words with their indices.\r\n",
        "print('\\n{:<12} {:>6}\\n'.format('TOKENS', 'INDICES'))\r\n",
        "for tup in zip(tokenized_text, indexed_tokens):\r\n",
        "    print('{:<12} {:>6}'.format(tup[0], tup[1]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[CLS], [SEP]] = [101, 102]\n",
            "\n",
            "Tokenized sentence:\n",
            "['where', 'does', 'migration', 'mainly', 'occur', '?']\n",
            "\n",
            "TOKENS       INDICES\n",
            "\n",
            "where          2073\n",
            "does           2515\n",
            "migration      9230\n",
            "mainly         3701\n",
            "occur          5258\n",
            "?              1029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuuVNwp50-xF"
      },
      "source": [
        "# Returns start and end indices of sublist in list\r\n",
        "def find_sublist(a, b):\r\n",
        "  if len(a) == 0 or len(b) == 0:\r\n",
        "    raise Exception(\"Lists with length 0\")\r\n",
        "\r\n",
        "  for i in range(len(a) - len(b) +1):\r\n",
        "    if np.array_equal(a[i:i+len(b)], b):\r\n",
        "      return i, i+len(b)-1\r\n",
        "\r\n",
        "  return -1, -1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEy0mp9yzXjn"
      },
      "source": [
        "# Prints COOL progress bar (No, seriously, it's really cool!)\r\n",
        "# REALLY DUDE, THIS STUFF IS GOLD\r\n",
        "def print_progress(value, total, bar_width=100):\r\n",
        "  perc = int(value/total*bar_width)\r\n",
        "  rest = bar_width - perc\r\n",
        "  print(\"\\r{:>3} % [ {}{} ]\".format(perc, perc*'■', rest*'─'), end=\"\")\r\n",
        "\r\n",
        "# ensure to preserve all sub-sequences of length limi-stride. \r\n",
        "def split_long_sequence(my_sequence, limit, stride):\r\n",
        "\r\n",
        "  if len(my_sequence) <= limit: \r\n",
        "    return [my_sequence]\r\n",
        "  \r\n",
        "  rest = my_sequence\r\n",
        "  split = []\r\n",
        "  while len(rest) > limit:\r\n",
        "    left_hand = rest[:limit]\r\n",
        "    rest = rest[stride:]\r\n",
        "    split.append(left_hand)\r\n",
        "    \r\n",
        "  split.append(rest)\r\n",
        "  return split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jayMk-aHPYVB"
      },
      "source": [
        "def from_df_to_model_dict(df, context_dict, verbose=False):\r\n",
        "\r\n",
        "  # initialize structures\r\n",
        "  input_ids = []\r\n",
        "  input_mask = []\r\n",
        "  input_type_ids = []\r\n",
        "  start_indexes = []\r\n",
        "  end_indexes = []\r\n",
        "\r\n",
        "  cut_counter = 0\r\n",
        "  max_iter = len(df)\r\n",
        "  new_entries = 0\r\n",
        "  for i, row in df.iterrows():\r\n",
        "\r\n",
        "    # print progress\r\n",
        "    if (i+1) % (max_iter // 100) == 0 or i == 0:\r\n",
        "      print_progress(i+1, max_iter)\r\n",
        "\r\n",
        "    # encode question and context\r\n",
        "    if verbose: print(\"\\tTokenizing question and context...\", end=\"\")\r\n",
        "    encoded_question = tokenizer.encode(row['question_text'])\r\n",
        "    encoded_context = tokenizer.encode(context_dict[row['context_id']])[1:]\r\n",
        "\r\n",
        "    # concatenate input data \r\n",
        "    if verbose: print(\"\\tChecking sequence length...\")\r\n",
        "    if len(encoded_question + encoded_context) > SEQUENCE_LIMIT:\r\n",
        "      # if the sequence is too long, split it in n subsequences of length <= SEQUENCE_LIMIT\r\n",
        "      encoded_contexts = split_long_sequence(encoded_context,\r\n",
        "                                             limit=SEQUENCE_LIMIT-len(encoded_question), \r\n",
        "                                             stride=STRIDE)\r\n",
        "      cut_counter += 1\r\n",
        "    else:\r\n",
        "      encoded_contexts = [encoded_context]\r\n",
        "    \r\n",
        "    new_entries += len(encoded_contexts)-1\r\n",
        "    # for each too long sequence, the context has been split in n parts. We need to process them separately, creating new entries for the input\r\n",
        "    for context_piece in encoded_contexts:\r\n",
        "      \r\n",
        "      encoded_input = encoded_question + context_piece\r\n",
        "\r\n",
        "      # create mask of ones\r\n",
        "      ones_mask = tf.ones_like(encoded_input)\r\n",
        "\r\n",
        "      # add padding and convert to tensor\r\n",
        "      if verbose: print(\"\\tPadding...\", end=\"\")\r\n",
        "      encoded_input = tf.keras.preprocessing.sequence.pad_sequences([encoded_input], maxlen=512, padding='pre')\r\n",
        "      encoded_input = tf.squeeze(tf.convert_to_tensor(encoded_input))\r\n",
        "\r\n",
        "      # processing answer indices\r\n",
        "      if verbose: print(\"\\tProcessing answer...\", end=\"\")\r\n",
        "      tokenized_answer = tokenizer.encode(row['answer_text'])[1: -1]\r\n",
        "      start_idx, end_idx = find_sublist(encoded_input, tokenized_answer)\r\n",
        "\r\n",
        "      start_indexes.append(start_idx)\r\n",
        "      end_indexes.append(end_idx)\r\n",
        "\r\n",
        "\r\n",
        "      # create input_type_ids\r\n",
        "      if verbose: print(\"\\tInput types creation...\", end=\"\")\r\n",
        "      type_ids = tf.concat([tf.zeros_like(encoded_question, dtype=tf.int32), \r\n",
        "                            tf.ones_like(context_piece, dtype=tf.int32)], \r\n",
        "                          axis=-1)\r\n",
        "      \r\n",
        "      type_ids = tf.keras.preprocessing.sequence.pad_sequences([type_ids], maxlen=512, padding='pre')\r\n",
        "      type_ids = tf.squeeze(tf.convert_to_tensor(type_ids))\r\n",
        "\r\n",
        "\r\n",
        "      # create mask of zeros\r\n",
        "      if verbose: print(\"\\tMask creation...\", end=\"\")\r\n",
        "      zeros_mask = tf.zeros(SEQUENCE_LIMIT - len(ones_mask), dtype=tf.int32)\r\n",
        "      mask = tf.concat([zeros_mask, ones_mask], axis=-1)\r\n",
        "\r\n",
        "      # append elements to lists\r\n",
        "      if verbose: print(\"\\tAppending inputs...\", end=\"\")\r\n",
        "      input_ids.append(encoded_input)\r\n",
        "      input_mask.append(mask)\r\n",
        "      input_type_ids.append(type_ids)\r\n",
        "\r\n",
        "  # save input data as dictionary\r\n",
        "  inputs = {\r\n",
        "    'input_ids': tf.convert_to_tensor(input_ids),\r\n",
        "    'attention_mask': tf.convert_to_tensor(input_mask),\r\n",
        "    'token_type_ids': tf.convert_to_tensor(input_type_ids)\r\n",
        "    }\r\n",
        "\r\n",
        "  assert len(input_ids) == len(df) + new_entries, f\"ATTENTION:\\nci sono {len(input_ids)} input_ids, MA {len(df)} righe nel df e {new_entries} nuove entries\"\r\n",
        "  return inputs, start_indexes, end_indexes"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXCcgd3cSgAm"
      },
      "source": [
        "# <s> Building Progress <s>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irK7yfKKV1LU",
        "outputId": "e283cb35-24c8-4620-cdd4-83a1884b68eb"
      },
      "source": [
        "print(\"Building training set...\")\r\n",
        "train_inputs, train_starts_ids, train_ends_ids = from_df_to_model_dict(train_df[:TRAIN_LIMIT], train_context_dict)\r\n",
        "\r\n",
        "print(\"\\n\\nBuilding validation set...\")\r\n",
        "val_inputs, val_starts_ids, val_ends_ids = from_df_to_model_dict(val_df[:VAL_LIMIT], val_context_dict)\r\n",
        "\r\n",
        "print(\"\\n\\nBuilding test set...\")\r\n",
        "test_inputs, test_starts_ids, test_ends_ids = from_df_to_model_dict(test_df[:TEST_LIMIT], test_context_dict)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building training set...\n",
            "100 % [ ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ ]\n",
            "\n",
            "Building validation set...\n",
            "100 % [ ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ ]\n",
            "\n",
            "Building test set...\n",
            "100 % [ ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ ]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBvYDn5dUSTF"
      },
      "source": [
        "# <s> Index to categorical <s>\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F91QMkCFrKwo"
      },
      "source": [
        "# Replace -1 (answer not found) with 0\r\n",
        "train_starts_ids = [val if val != -1 else 0 for val in train_starts_ids]\r\n",
        "train_ends_ids = [val if val != -1 else 0 for val in train_ends_ids]\r\n",
        "\r\n",
        "val_starts_ids = [val if val != -1 else 0 for val in val_starts_ids]\r\n",
        "val_ends_ids = [val if val != -1 else 0 for val in val_ends_ids]\r\n",
        "\r\n",
        "test_starts_ids = [val if val != -1 else 0 for val in test_starts_ids]\r\n",
        "test_ends_ids = [val if val != -1 else 0 for val in test_ends_ids]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3NdLSFESd5E"
      },
      "source": [
        "# from ints to categorical\r\n",
        "train_starts_cat = tf.keras.utils.to_categorical(train_starts_ids, num_classes=SEQUENCE_LIMIT)\r\n",
        "train_ends_cat = tf.keras.utils.to_categorical(train_ends_ids, num_classes=SEQUENCE_LIMIT)\r\n",
        "\r\n",
        "val_starts_cat = tf.keras.utils.to_categorical(val_starts_ids, num_classes=SEQUENCE_LIMIT)\r\n",
        "val_ends_cat = tf.keras.utils.to_categorical(val_ends_ids, num_classes=SEQUENCE_LIMIT)\r\n",
        "\r\n",
        "test_starts_cat = tf.keras.utils.to_categorical(test_starts_ids, num_classes=SEQUENCE_LIMIT)\r\n",
        "test_ends_cat = tf.keras.utils.to_categorical(test_ends_ids, num_classes=SEQUENCE_LIMIT)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iktKwoXUKAj",
        "outputId": "8c6dc104-8070-47e7-d876-fea5805b3687"
      },
      "source": [
        "# Inspect data\r\n",
        "assert len(train_starts_ids) == len(train_ends_ids) == len(train_inputs['input_ids']) == len(train_inputs['attention_mask']) == len(train_inputs['token_type_ids'])\r\n",
        "assert len(val_starts_ids) == len(val_ends_ids) == len(val_inputs['input_ids']) == len(val_inputs['attention_mask']) == len(val_inputs['token_type_ids'])\r\n",
        "assert len(test_starts_ids) == len(test_ends_ids) == len(test_inputs['input_ids']) == len(test_inputs['attention_mask']) == len(test_inputs['token_type_ids'])\r\n",
        "\r\n",
        "print(\"Shapes\")\r\n",
        "print(\"\\nTrain starts:\\t\", train_starts_cat.shape)\r\n",
        "print(\"Train ends:\\t\", train_ends_cat.shape)\r\n",
        "print(\"\\nVal starts:\\t\", val_starts_cat.shape)\r\n",
        "print(\"Val ends:\\t\", val_ends_cat.shape)\r\n",
        "print(\"\\nTest starts:\\t\", test_starts_cat.shape)\r\n",
        "print(\"Test ends:\\t\", test_ends_cat.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes\n",
            "\n",
            "Train starts:\t (3000, 512)\n",
            "Train ends:\t (3000, 512)\n",
            "\n",
            "Val starts:\t (1010, 512)\n",
            "Val ends:\t (1010, 512)\n",
            "\n",
            "Test starts:\t (1000, 512)\n",
            "Test ends:\t (1000, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5MRM0Q_LXyW"
      },
      "source": [
        "# <s>  Save train and test inputs dataset <s>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWW1mTlHrwe9"
      },
      "source": [
        "## TRAIN\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/train_inputs.p\", \"wb\") as f:\r\n",
        "  pickle.dump(train_inputs, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/train_starts_ids.p\", \"wb\") as f:\r\n",
        "  pickle.dump(train_starts_ids, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/train_ends_ids.p\", \"wb\") as f:\r\n",
        "  pickle.dump(train_ends_ids, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/train_starts_cat.p\", \"wb\") as f:\r\n",
        "  pickle.dump(train_starts_cat, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/train_ends_cat.p\", \"wb\") as f:\r\n",
        "  pickle.dump(train_ends_cat, f)\r\n",
        "\r\n",
        "\r\n",
        "## VALIDATION\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/val_inputs.p\", \"wb\") as f:\r\n",
        "  pickle.dump(val_inputs, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/val_starts_ids.p\", \"wb\") as f:\r\n",
        "  pickle.dump(val_starts_ids, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/val_ends_ids.p\", \"wb\") as f:\r\n",
        "  pickle.dump(val_ends_ids, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/val_starts_cat.p\", \"wb\") as f:\r\n",
        "  pickle.dump(val_starts_cat, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/val_ends_cat.p\", \"wb\") as f:\r\n",
        "  pickle.dump(val_ends_cat, f)\r\n",
        "\r\n",
        "\r\n",
        "## TEST\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/test_inputs.p\", \"wb\") as f:\r\n",
        "  pickle.dump(test_inputs, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/test_starts_ids.p\", \"wb\") as f:\r\n",
        "  pickle.dump(test_starts_ids, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/test_ends_ids.p\", \"wb\") as f:\r\n",
        "  pickle.dump(test_ends_ids, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/test_starts_cat.p\", \"wb\") as f:\r\n",
        "  pickle.dump(test_starts_cat, f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/test_ends_cat.p\", \"wb\") as f:\r\n",
        "  pickle.dump(test_ends_cat, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok4Z7Xhltev_"
      },
      "source": [
        "# Load train and test inputs datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECyBOk-mtaHG"
      },
      "source": [
        "## TRAIN\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/train_inputs.p\", \"rb\") as f:\r\n",
        "  train_inputs = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/train_starts_ids.p\", \"rb\") as f:\r\n",
        "  train_starts_ids = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/train_ends_ids.p\", \"rb\") as f:\r\n",
        "  train_ends_ids = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/train_starts_cat.p\", \"rb\") as f:\r\n",
        "  train_starts_cat = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/train_ends_cat.p\", \"rb\") as f:\r\n",
        "  train_ends_cat = pickle.load(f)\r\n",
        "\r\n",
        "\r\n",
        "## VALIDATION\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/val_inputs.p\", \"rb\") as f:\r\n",
        "  val_inputs = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/val_starts_ids.p\", \"rb\") as f:\r\n",
        "  val_starts_ids = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/val_ends_ids.p\", \"rb\") as f:\r\n",
        "  val_ends_ids = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/val_starts_cat.p\", \"rb\") as f:\r\n",
        "  val_starts_cat = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/val_ends_cat.p\", \"rb\") as f:\r\n",
        "  val_ends_cat = pickle.load(f)\r\n",
        "\r\n",
        "\r\n",
        "## TEST\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/test_inputs.p\", \"rb\") as f:\r\n",
        "  test_inputs = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/test_starts_ids.p\", \"rb\") as f:\r\n",
        "  test_starts_ids = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/test_ends_ids.p\", \"rb\") as f:\r\n",
        "  test_ends_ids = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/test_starts_cat.p\", \"rb\") as f:\r\n",
        "  test_starts_cat = pickle.load(f)\r\n",
        "\r\n",
        "with open(\"/content/drive/MyDrive/SQUAD/test_ends_cat.p\", \"rb\") as f:\r\n",
        "  test_ends_cat = pickle.load(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mZbcRg48o3E"
      },
      "source": [
        "# Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI0_mr1eyRgl"
      },
      "source": [
        "from keras.layers import Reshape, GlobalAveragePooling1D"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "3PJ2O1Zn8nqr",
        "outputId": "ea1fe084-c1a1-401a-faa3-8c6b435ae73f"
      },
      "source": [
        "@tf.autograph.experimental.do_not_convert\r\n",
        "def build_model():\r\n",
        "\r\n",
        "  # Define Input layers\r\n",
        "  input_ids_layer = Input(shape = (512,), dtype='int64')\r\n",
        "  attention_mask_layer = Input(shape = (512,), dtype='int64')\r\n",
        "  token_ids_layer = Input(shape = (512,), dtype='int64')\r\n",
        "\r\n",
        "  # Load Bert model\r\n",
        "  bert_model = TFBertModel.from_pretrained('bert-base-uncased')\r\n",
        "  \r\n",
        "  # Set bert layers to not-trainable\r\n",
        "  for layer in bert_model.layers:\r\n",
        "    layer.trainable = False\r\n",
        "  \r\n",
        "  # Initialize bert model\r\n",
        "  bert = bert_model(input_ids = input_ids_layer,\r\n",
        "                    attention_mask = attention_mask_layer,\r\n",
        "                    token_type_ids = token_ids_layer,\r\n",
        "                    return_dict = False,\r\n",
        "                    output_attentions = False,\r\n",
        "                    output_hidden_states = False\r\n",
        "                    ).last_hidden_state\r\n",
        "\r\n",
        "  # flat = Flatten()(bert)  \r\n",
        "  \r\n",
        "  # # Define output classifiers\r\n",
        "  # start_classifier = Dense(units=512, activation=\"softmax\", name=\"Start_classifier\")(flat)\r\n",
        "  # end_classifier = Dense(units=512, activation=\"softmax\", name=\"End_classifier\")(flat)\r\n",
        "\r\n",
        "  # pooler = GlobalAveragePooling1D()(bert)\r\n",
        "  classifier = Dense(units=1,  name=\"classifier\")(bert)\r\n",
        "\r\n",
        "  # Build model\r\n",
        "  model = Model(inputs=[input_ids_layer, attention_mask_layer, token_ids_layer], \r\n",
        "                outputs=classifier)\r\n",
        "  \r\n",
        "  model.summary()\r\n",
        "  return model\r\n",
        "\r\n",
        "model = build_model()\r\n",
        "plot_model(model, show_shapes=True)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_34 (InputLayer)           [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_35 (InputLayer)           [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_36 (InputLayer)           [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_11 (TFBertModel)  TFBaseModelOutputWit 109482240   input_34[0][0]                   \n",
            "                                                                 input_35[0][0]                   \n",
            "                                                                 input_36[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 512, 1)       769         tf_bert_model_11[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 109,483,009\n",
            "Trainable params: 769\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABuMAAAEnCAYAAACzNT4ZAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzde1xVdb7/8feW+x28k0gq5C3xUnp+Spk1lpkevKQSpY3WyVGsFLFSvJQpMmqNcFDJR+Ywc7JRRB10NK1pjIfjST02XjIaDe94SbyCCibC+v3hg11bQNm6N5vL6/l47D9a67vW+qy1ab/Bz9rfZTIMwxAAAAAAAAAAAAAAm6vn6AIAAAAAAAAAAACA2opmHAAAAAAAAAAAAGAnNOMAAAAAAAAAAAAAO6EZBwAAAAAAAAAAANiJs6MLAAAAtcOCBQu0fft2R5cBAKiGevToodjYWLvsm/wBAFSE/AEAOEJ5+cM34wAAgE1s375dO3bscHQZgN2tXr1aJ0+edHQZNcqOHTv4fKjDduzYYdd/rCR/UFeQP9Yjf+o28gewDfLHeuRP3VZR/vDNOAAAYDPdu3dXenq6o8sA7MpkMmnixImKjIx0dCk1xrBhwySJz4c6qvT9tyfyB3UB+WM98qduI38A2yB/rEf+1G0V5Q/fjAMAAAAAAAAAAADshGYcAAAAAAAAAAAAYCc04wAAAAAAAAAAAAA7oRkHAAAAAAAAAAAA2AnNOAAAAAAAAAAAAMBOaMYBAAAADvD555/Lz89Pf/vb3xxdSrU0duxYmUwm82vEiBFlxnz11VeKi4vTmjVr1KpVK/PYl19+uczYPn36yMfHR05OTnr44Ye1e/fuqjiNexYfH29x/qWvDh06lDu+pKREiYmJCg8PL3f9rFmz1L59e/n6+srNzU2hoaF65513dPXqVfOY9evXa968eSouLrbYNiMjw6KGhg0b2u5EAVQ58ufOyB/yB4B9kD93Rv7U/vyhGQcAAAA4gGEYji6h2qtfv742bdqkgwcPatmyZRbr3nvvPSUnJ2vq1KkaMmSIjhw5opCQEDVo0EDLly/Xxo0bLcZ/+eWXSk9PV0REhLKysvTII49U5anYVXZ2tp544gnFxsaqoKCg3DFbtmzRG2+8oWPHjun8+fNKSEhQUlKShg0bZh4zYMAAubu7q3fv3rp8+bJ5+cCBA3Xy5Elt3bpV/fr1s/v5ALAv8ufuyJ/KIX8AWIP8uTvyp3Jqav7QjAMAAAAcoH///srLy1NERISjS1FhYWGFdxQ6koeHh/r27avWrVvLzc3NvHzu3LlauXKlVq1aJR8fH4ttkpOTVa9ePY0ZM0Z5eXlVXbJNffrppzIMw+L1/fffW4zZt2+fpkyZoujoaHXu3LnCfXl7e2vMmDGqX7++fHx8FBkZqcGDB2vz5s3Kyckxj5swYYI6deqkfv366ebNm5Ikk8mkZs2aqWfPnnrooYfsc7IAqgz5c3fkD/kDwPbIn7sjf2p3/tCMAwAAAOq4ZcuWKTc319FlVMqhQ4c0Y8YMvf/++3J3dy+zPjw8XDExMTp16pTeeustB1RYtTp16qQ1a9Zo+PDhFn+w327Dhg1ycnKyWFY63crtd5POnDlTe/fuVVJSku0LBoBfIX9qLvIHQE1G/tRcNTl/aMYBAAAAVWzbtm0KDg6WyWTSokWLJEkpKSny8vKSp6en1q1bp+eee06+vr4KCgrSihUrzNsmJyfL3d1djRs31tixYxUYGCh3d3eFh4dr586d5nHjx4+Xq6urmjZtal72+uuvy8vLSyaTSefPn5ckxcTEaNKkSTp8+LBMJpNCQ0MlSZs3b5avr6/mzJlTFZek0pKTk2UYhgYMGFDhmPj4eLVu3VqffPKJvvrqqzvuzzAMLViwQO3atZObm5sCAgI0aNAgHThwwDymsu+NJBUXF+vdd99VcHCwPDw81LFjR6Wlpd3fSdvJqVOn5OHhoZYtW1osDwgIUK9evZSUlMR0QkAtQ/7cO/LHdsgfoO4hf+4d+WM7js4fmnEAAABAFXv88cf1zTffWCwbN26cJk6cqMLCQvn4+CgtLU2HDx9Wq1atNHr0aBUVFUm69UfmqFGjVFBQoAkTJujYsWPavXu3bt68qWeeecY85UZycrIiIyMtjrF48WK9//77FsuSkpIUERGhkJAQGYahQ4cOSZL5IdYlJSV2uQb3auPGjWrTpo08PT0rHOPh4aE//elPqlevnkaPHq1r165VOHbmzJmKi4vTtGnTlJubq61btyonJ0c9e/bU2bNnJVX+vZGkKVOmaP78+UpMTNSZM2cUERGhl156Sd9++63V5xoXF6eAgAC5urqqZcuWGjRokHbt2mX1fspTUFCgLVu2aPTo0XJ1dS2zvkuXLjp16pT27dtnk+MBqB7In3tH/pA/AO4d+XPvyJ/akz804wAAAIBqJjw8XL6+vmrUqJGioqJ07do1nThxwmKMs7Oz+W7G9u3bKyUlRVeuXFFqaqpNaujfv7/y8/M1Y8YMm+zPFq5du6ajR48qJCTkrmN79OihiRMn6tixY5oyZUq5YwoLC7VgwQI9//zzGjFihPz8/BQWFqYlS5bo/Pnz+vjjj8tsc6f35vr160pJSdHgwYM1ZMgQ+fv7a/r06XJxcbH6fRk5cqTWr1+vnJwcXb16VStWrNCJEyfUq1cvZWVlWbWv8iQkJCgwMFDx8fHlri99NsL+/fvv+1gAag7yp3zkD/kDwL7In/KRP7Urf2jGAQAAANVY6V17v777sDxdu3aVp6enxfQitU1ubq4Mw7jjXaG/Fh8frzZt2mjx4sXatm1bmfVZWVm6evWqunbtarG8W7ducnV1tZj2pjy3vzcHDx5UQUGBOnToYB7j4eGhpk2bWv2+NG/eXF26dJG3t7dcXV3VvXt3paamqrCwUIsXL7ZqX7dbu3atVq1apS+++KLMA+BLlV7j0rtjAdQ95M8vyB/yB0DVIX9+Qf7UrvyhGQcAAADUEm5ubjp37pyjy7Cb69evS9IdH9T9a+7u7kpNTZXJZNKrr76qwsJCi/WXL1+WJHl7e5fZ1t/fX1euXLGqvtLpYKZPny6TyWR+HT9+vMxDwu9FWFiYnJyc9OOPP97zPlauXKm5c+cqMzNTLVq0qHCch4eHpF+uOQDcCfljifwpi/wBYA/kjyXyp6zqlD804wAAAIBaoKioSJcvX1ZQUJCjS7Gb0j+QSp/nUBk9evRQbGyssrOzNXv2bIt1/v7+klTuH533ci0bNWokSUpMTJRhGBav7du3W7Wv8pSUlKikpKTSf4zfbuHChVq+fLm2bNmiBx544I5jb9y4IemXaw4AFSF/ykf+/IL8AWAP5E/5yJ9fVLf8oRkHAAAA1AKZmZkyDEPdu3c3L3N2dr7r9C41SePGjWUymZSXl2fVdrNnz1bbtm21Z88ei+UdOnSQt7d3mYeL79y5Uzdu3NCjjz5q1XGaN28ud3d37d2716rtyvPss8+WWbZr1y4ZhqEePXpYtS/DMDR58mTt379fGRkZ5d4Je7vSa9ykSROrjgWg7iF/Kkb+kD8A7If8qRj5Uz3zh2YcAAAAUAOVlJTo0qVLunnzpr777jvFxMQoODhYo0aNMo8JDQ3VxYsXlZGRoaKiIp07d07Hjx8vs6/69evr9OnTOnbsmK5cuaKioiJt2rRJvr6+mjNnThWe1Z15enqqVatWOnnypFXblU7X4uTkVGb5pEmTtHbtWi1fvlz5+fnav3+/oqOjFRgYqDFjxlh9nFdeeUUrVqxQSkqK8vPzVVxcrJMnT+rMmTOSpKioKDVp0kS7d+++475OnTqllStX6vLlyyoqKtL27dv12muvKTg4WNHR0VbV9cMPP2j+/PlaunSpXFxcLKaQMZlM+vDDD8tsU3qNw8LCrDoWgNqP/Kk88of8AWA75E/lkT/VM39oxgEAAABVbNGiRerWrZskafLkyRo4cKBSUlKUmJgoSerYsaOOHDmipUuXatKkSZKkvn37Kjs727yP69evKywsTB4eHurZs6dat26tr7/+2mIKj3Hjxumpp57Siy++qDZt2mj27NnmaTd69OihnJwcSVJ0dLQaN26s9u3bq1+/frp48WKVXId70b9/f2VlZVk8/+Cvf/2rQkNDdfjwYXXr1k1vvvlmme26d++u2NjYMsvfe+89JSQkaNasWWrYsKF69eqlFi1aKDMzU15eXpJk1XuTlJSkiRMnat68eWrQoIECAwMVExOjS5cuSbo1/Ulubq7WrVt3x/Ps27evpk+frqCgIHl6eioyMlKPPfaYduzYoQYNGpjH7dixQ48//rgeeOAB7dy5U/v27VNgYKAee+wxbd26VdKtO0OttWvXLjVr1kwdO3a0elsA1Rf5c+/IH/IHwL0jf+4d+VN78sdk3EtlAAAAtxk2bJgkKT093cGVAPZlMpmUlpamyMhIh9UwduxYpaen68KFCw6rwRr38vkwduxYbdiwocxdoIcOHVK7du2UmpqqESNG2LTOqlBSUqInn3xSo0aN0quvvurocsp14cIFBQUFKT4+3vwHd6mYmBgtX75c58+fr/T+7J0P5A/qCvLHeuTPL8gf2yN/UFeQP9Yjf35B/vyCb8YBAAAANZA1D/GuqQoLC/XFF18oOzvb/EDt0NBQzZo1S7NmzdLVq1cdXKF1iouLlZGRoStXrigqKsrR5VRo5syZ6ty5s8aPHy/p1p2lp0+f1rZt23To0CEHVwfA0cgf8sdeyB8Ad0L+kD/2UlX5QzMOAAAAQLV08eJF9e3bV61bt7a4izIuLk7Dhg1TVFSU1Q8zd6TMzEytWbNGmzZtkqenp6PLKdeCBQu0d+9eff7553JxcZEkrVu3Ts2aNVPPnj21ceNGB1cIAPZH/lQ98gcAyB9HqMr8oRkHAAAc5vPPP5efn5/+9re/ObqU+zJv3jy1bdtWHh4e8vLyUtu2bTVjxgzl5+ffcbvr16+rbdu2mj59utXH3LFjh9q1a6d69erJZDKpSZMmio+Pv9dTsIs1a9aoVatW5ockN23atEZOq1HdTJ06VampqcrLy1PLli21evVqR5dkF0uWLJFhGObX8uXLLdbPmTNH48eP1+9//3sHVWi93r1767PPPlPTpk0dXUq51q1bp59//lmZmZkKCAgwLx80aJDFe2HNFC3VVV3Ln/j4+DIPrjeZTOrQoYPVxyR/6i7y5xbyx/bIn5rHmr9/ioqKlJCQoNDQULm6usrf318dOnTQsWPHrDom+VN3kT+3kD+2V9X542yTvQAAANyD2vLo2n/+858aPXq0fvvb38rDw0ObNm3S8OHDtXPnTn355ZcVbjdt2jQdPHjwno7ZvXt3/fvf/1bfvn31xRdf6ODBg/L397/XU7CLIUOGaMiQIQoNDdX58+f1008/ObqkWiEhIUEJCQmOLqNa6NOnj/r06ePoMmqNgQMHauDAgY4uo0rU9fy5H+RP3UX+/IL8sS3yp+axJn9eeOEF/fDDD/rss8/06KOP6ty5cxo7dqzV0+2RP3UX+fML8se2qjp/+GYcAABwmP79+ysvL08RERGOLkWFhYUKDw+/p21dXV31+uuvq1GjRvL29tawYcM0aNAg/f3vf9eZM2fK3eabb77R999/fz8lVzv3cw0BoCrVxfz59NNPLe7wNQyj1uQQ+QOgpqhr+bNy5UplZGQoPT1d/+///T85OzsrMDBQ69atu6dvZ1c35A8Aa9CMAwAAkLRs2TLl5ube07Zr166Vu7u7xbJmzZpJUrl3fBYWFurtt99WUlLSPR2vurqfawgAdVVV5k9tRf4AgPWqIn8++ugjPfLIIwoLC7v3Qqsx8geANWjGAQAAh9i2bZuCg4NlMpm0aNEiSVJKSoq8vLzk6empdevW6bnnnpOvr6+CgoK0YsUK87bJyclyd3dX48aNNXbsWAUGBsrd3V3h4eHauXOnedz48ePl6upqMT/566+/Li8vL5lMJvO83zExMZo0aZIOHz4sk8mk0NDQ+z6/7Oxs+fv768EHHyyzbtq0aeY7ScuzefNm+fr6as6cOVYft6Zfw3/+859q3769/Pz85O7urrCwMH3xxReSpNdee838/IWQkBDt2bNHkvTKK6/I09NTfn5+Wr9+vSSpuLhY7777roKDg+Xh4aGOHTsqLS1NkjR//nx5enrKx8dHubm5mjRpkpo1a3bPU4YCqFnqcv7cDflD/gCwn7qWPzdu3NCOHTvUuXPnu25L/pA/QJ1gAAAA2MDQoUONoUOHWrVNTk6OIclYuHChedm0adMMScY//vEPIy8vz8jNzTV69uxpeHl5GTdu3DCPGzNmjOHl5WX88MMPxvXr142srCyjW7duho+Pj3HixAnzuOHDhxtNmjSxOO4HH3xgSDLOnTtnXjZkyBAjJCTE2tO2cOPGDePkyZPGwoULDTc3N+PTTz8tM2bbtm3GgAEDDMMwjHPnzhmSjGnTplmM2bBhg+Hj42PMmjXrrsd89tlnDUnGpUuXzMuq2zUMCQkx/Pz87nouhmEY6enpxsyZM42LFy8aFy5cMLp37240aNDA4hhOTk7GqVOnLLZ76aWXjPXr15v/+6233jLc3NyM1atXG5cuXTKmTp1q1KtXz9i1a5fFNZowYYKxcOFC4/nnnzf+/e9/V6pGSUZaWlqlxuKWe/l8QO1h7/ef/Ll7/syePdsICgoy/P39DRcXF6NFixbGwIEDjf/7v/+zGEf+kD+1DflTt5E/v3BE/hw9etSQZHTu3Nl48sknjaZNmxpubm5G27ZtjUWLFhklJSXmseQP+VPbkD91W0XvP9+MAwAA1VJ4eLh8fX3VqFEjRUVF6dq1azpx4oTFGGdnZ7Vr105ubm5q3769UlJSdOXKFaWmpjqk5ubNmysoKEgzZ87U/Pnz9cILL1isLywsVExMjFJSUu64n/79+ys/P18zZsy4r3pq4jUcOnSo3nvvPQUEBKh+/foaMGCALly4oHPnzkmSoqOjVVxcbFFffn6+du3apX79+kmSrl+/rpSUFA0ePFhDhgyRv7+/pk+fLhcXlzLnNXfuXL3xxhtas2aN2rZtW3UnCqDaqomfnXfLn5EjR2r9+vXKycnR1atXtWLFCp04cUK9evVSVlaWeRz5Q/4AcJya+Nl5p/wpna6yUaNGmjNnjrKysnT27FkNGjRIb7zxhv7yl7+Yx5I/5A9QF9CMAwAA1Z6rq6skqaio6I7junbtKk9PTx04cKAqyiojJydHubm5+stf/qI///nP6tKli8UzBKZOnarf/e535ucpVKWacg1v5+LiIunWtCuS9Jvf/EatW7fWH//4RxmGIenWg+GjoqLk5OQkSTp48KAKCgosHgrv4eGhpk2b2uy8XnjhBfOUMbzu/lq9erVWr17t8Dp4Oe79r6lqymfn3fKnefPm6tKli7y9veXq6qru3bsrNTVVhYWFWrx4sV1rqynX8HbkT+14kT91+0X+2N+d8sfNzU2S9PDDDys8PFz169eXn5+f3n//ffn5+enjjz+2a2015RrejvypHS/yp26/KsofZ5v83wgAAFBNuLm5me8irGouLi5q1KiR+vTpo5YtW6p169ZKSEhQUlKStm3bpv3792vBggUOqc0ajryGGzdu1AcffKCsrCzl5+eX+ePZZDJp7Nixio2N1T/+8Q89/fTT+p//+R999tln5jHXrl2TJE2fPl3Tp0+32D4wMNAmdcbExKhHjx422VddkJiYKEmaOHGigyuBI5S+/7Vddc2fioSFhcnJyUk//vhjFVZ6Z+TP3ZE/1iF/6jbyx/7ulD+ln3ulz1gr5erqqgcffFCHDx92RMnlIn/ujvyxDvlTt1WUPzTjAABArVFUVKTLly8rKCjI0aUoNDRUTk5O5um/li1bpn/84x+qV6/sxARz5szRnDlztGvXLnXt2rWqS7VQ1ddw69at+te//qWJEyfqxIkTGjx4sJ5//nn98Y9/1AMPPKCFCxfqnXfesdhm1KhRmjp1qj755BM1b95cvr6+5gfFS7emwpFu/QIcExNjl7p79OihyMhIu+y7NkpPT5ckrlkdVfr+12bVOX8qUlJSopKSEvM3FxyN/Kkc8sc65E/dRv5Urdvzx9vbWw899JB++OGHMmNv3rwpPz+/qi6xXORP5ZA/1iF/6raK8odpKgEAQK2RmZkpwzDUvXt38zJnZ+e7Tk1yPy5cuKCXXnqpzPLs7GwVFxerefPmkqTU1FQZhmHxKr37ctq0aTIMw+GNOKnqr+G//vUveXl5SZL279+voqIijRs3Tq1atZK7u7tMJlOZbQICAvTCCy8oIyNDH374oUaPHm2xvnnz5nJ3d9fevXvtUjMA3K46548kPfvss2XG7dq1S4ZhVJu73MkfALBedc+fF154QXv27NGRI0fMywoKCnT8+HGFhYXZrUZrkD8AqgrNOAAAUGOVlJTo0qVLunnzpr777jvFxMQoODhYo0aNMo8JDQ3VxYsXlZGRoaKiIp07d07Hjx8vs6/69evr9OnTOnbsmK5cuVLpP768vLz05ZdfasuWLeZpRfbs2aORI0fKy8tLsbGxVp/Xpk2b5Ovrqzlz5li9rbUcdQ2Liop09uxZZWZmmv8YDQ4OliR99dVXun79urKzs7Vz585yt4+OjtbPP/+sDRs2KCIiwmKdu7u7XnnlFa1YsUIpKSnKz89XcXGxTp48qTNnzlh7iQCgjJqWP6dOndLKlSt1+fJlFRUVafv27XrttdcUHBys6Oho8zjyh/wBUL3VtPyJjY3Vgw8+qFGjRunEiRO6cOGCJk+erMLCQk2ZMsU8jvwhf4A6wQAAALCBoUOHGkOHDq30+IULFxpNmzY1JBmenp7GgAEDjMWLFxuenp6GJOOhhx4yDh8+bHz88ceGr6+vIcl48MEHjR9//NEwDMMYM2aM4eLiYjRr1sxwdnY2fH19jUGDBhmHDx+2OM6FCxeMp556ynB3dzdatmxpvPnmm8bbb79tSDJCQ0ONEydOGIZhGLt37zYefPBBw8PDw3j88ceNn376qdLnMmDAAKNly5aGt7e34ebmZoSEhBhRUVHG/v3777jduXPnDEnGtGnTLJZ//vnnho+PjxEfH1/htjt27DAefvhho169eoYko2nTpsacOXOq1TX86KOPjJCQEEPSHV9r1641H2vy5MlG/fr1DX9/f2PYsGHGokWLDElGSEiI+TilunTpYsTFxZV7fX7++Wdj8uTJRnBwsOHs7Gw0atTIGDJkiJGVlWXMmzfP8PDwMCQZzZs3Nz799NM7vk+3k2SkpaVZtU1dZ+3nA2oXe7//5M/d82fSpElGSEiI4eXlZTg7OxtBQUHG6NGjjdOnT1uMI3/In9qG/KnbyB/H549hGEZOTo7x4osvGgEBAYabm5vxH//xH8amTZssxpA/5E9tQ/7UbRW9/ybDMAxbNfYAAEDdNWzYMElV92yGsWPHKj09XRcuXKiS49VGNf0a9u/fX4sWLVLLli2r9Lgmk0lpaWnM/2+Fqv58QPVi7/ef/Kl5avo1JH9qDvKnbiN/cLuafg3Jn5qD/KnbKnr/maYSAADUWMXFxY4uocarSdfw19O+fPfdd3J3d6/yP0QBQKpZn53VVU26huQPgOqiJn12Vlc16RqSP0DtQjMOAADgNgcOHJDJZLrrKyoqytGl1imTJ09Wdna2fvzxR73yyiuaPXu2o0uCHY0dO9bi/7cRI0aUGfPVV18pLi5Oa9asUatWrcxjX3755TJj+/TpIx8fHzk5Oenhhx/W7t27q+I07ll8fHy5nzsdOnQod3xJSYkSExMVHh5e7vpZs2apffv28vX1lZubm0JDQ/XOO+/o6tWr5jHr16/XvHnzyvwjVUZGhkUNDRs2tN2JwgL5Uz2RP3UL+UP+1EXkT/VE/tQt5E/tzx+acQAAoMaZOnWqUlNTlZeXp5YtW2r16tU23X/btm1lGMZdXytXrrTpcauSva+hPXh6eqpt27Z6+umnNXPmTLVv397RJcHO6tevr02bNungwYNatmyZxbr33ntPycnJmjp1qoYMGaIjR44oJCREDRo00PLly7Vx40aL8V9++aXS09MVERGhrKwsPfLII1V5KnaVnZ2tJ554QrGxsSooKCh3zJYtW/TGG2/o2LFjOn/+vBISEpSUlGSeQkWSBgwYIHd3d/Xu3VuXL182Lx84cKBOnjyprVu3ql+/fnY/n+qM/Ll/5A9qAvKncsifqkP+3D/yBzUB+VM5NTV/aMYBAIAaJyEhQT///LMMw9DRo0c1dOhQR5dU49TEaxgfH6/i4mKdOHFCERERji7HYQoLCyu8+68mHaMyPDw81LdvX7Vu3Vpubm7m5XPnztXKlSu1atUq+fj4WGyTnJysevXqacyYMcrLy6vqkm3q008/LfOPYN9//73FmH379mnKlCmKjo5W586dK9yXt7e3xowZo/r168vHx0eRkZEaPHiwNm/erJycHPO4CRMmqFOnTurXr59u3rwp6dZzQpo1a6aePXvqoYcess/J1hA18bOzuqmJ15D8uYX8IX9+jfypWjXxs7O6qYnXkPy5hfwhf36tJucPzTgAAACgBlm2bJlyc3Nr/DHu1aFDhzRjxgy9//77cnd3L7M+PDxcMTExOnXqlN566y0HVFi1OnXqpDVr1mj48OEWf7DfbsOGDXJycrJYVjrdyu13k86cOVN79+5VUlKS7QsGUGORP+TPr5E/AKoK+UP+/FpNzh+acQAAAIAdGYahBQsWqF27dnJzc1NAQIAGDRqkAwcOmMeMHz9erq6uatq0qXnZ66+/Li8vL5lMJp0/f16SFBMTo0mTJunw4cMymUwKDQ1VcnKy3N3d1bhxY40dO1aBgYFyd3dXeHi4du7caZNjSNLmzZvl6+urOXPm2PV63U1ycrIMw9CAAQMqHBMfH6/WrVvrk08+0VdffXXH/VXm/UlJSZGXl5c8PT21bt06Pffcc/L19VVQUJBWrFhhsb/i4mK9++67Cg4OloeHhzp27Ki0tLT7O2k7OXXqlDw8PNSyZUuL5QEBAerVq5eSkpJkGIaDqgNwv8gf2yJ/bIf8AWo38se2yB/bcXT+0IwDAAAA7GjmzJmKi4vTtGnTlP6f0hMAACAASURBVJubq61btyonJ0c9e/bU2bNnJd36AysyMtJiu8WLF+v999+3WJaUlKSIiAiFhITIMAwdOnRI48eP16hRo1RQUKAJEybo2LFj2r17t27evKlnnnnGPAXH/RxDkvmh1iUlJba7OPdg48aNatOmjTw9PSsc4+HhoT/96U+qV6+eRo8erWvXrlU4tjLvz7hx4zRx4kQVFhbKx8dHaWlpOnz4sFq1aqXRo0erqKjIvL8pU6Zo/vz5SkxM1JkzZxQREaGXXnpJ3377rdXnGhcXp4CAALm6uqply5YaNGiQdu3aZfV+ylNQUKAtW7Zo9OjRcnV1LbO+S5cuOnXqlPbt22eT4wGoeuSPbZE/5A+AyiF/bIv8qT35QzMOAAAAsJPCwkItWLBAzz//vEaMGCE/Pz+FhYVpyZIlOn/+vD7++GObHcvZ2dl8d2P79u2VkpKiK1euKDU11Sb779+/v/Lz8zVjxgyb7O9eXLt2TUePHlVISMhdx/bo0UMTJ07UsWPHNGXKlHLH3Mv7Ex4eLl9fXzVq1EhRUVG6du2aTpw4IUm6fv26UlJSNHjwYA0ZMkT+/v6aPn26XFxcrH4fRo4cqfXr1ysnJ0dXr17VihUrdOLECfXq1UtZWVlW7as8CQkJCgwMVHx8fLnrS5+NsH///vs+FoCqR/7YFvlD/gCoHPLHtsif2pU/NOMAAAAAO8nKytLVq1fVtWtXi+XdunWTq6urxTQqtta1a1d5enpaTDdS0+Xm5sowjDveFfpr8fHxatOmjRYvXqxt27aVWX+/70/pHZWld4YePHhQBQUF6tChg3mMh4eHmjZtavX70Lx5c3Xp0kXe3t5ydXVV9+7dlZqaqsLCQi1evNiqfd1u7dq1WrVqlb744osyD4AvVXqNS++OBVCzkD+2Rf6QPwAqh/yxLfKnduUPzTgAAADATi5fvixJ8vb2LrPO399fV65csevx3dzcdO7cObseoypdv35dku74oO5fc3d3V2pqqkwmk1599VUVFhZarLf1+1M6Hcz06dNlMpnMr+PHj5d5SPi9CAsLk5OTk3788cd73sfKlSs1d+5cZWZmqkWLFhWO8/DwkPTLNQdQs5A/tkX+kD8AKof8sS3yp3blD804AAAAwE78/f0lqdw/ai5fvqygoCC7HbuoqMjux6hqpX8glT6/oTJ69Oih2NhYZWdna/bs2RbrbP3+NGrUSJKUmJgowzAsXtu3b7dqX+UpKSlRSUlJpf8Yv93ChQu1fPlybdmyRQ888MAdx964cUPSL9ccQM1C/tgW+UP+AKgc8se2yJ/alT804wAAAAA76dChg7y9vcs8vHrnzp26ceOGHn30UfMyZ2dniwdh36/MzEwZhqHu3bvb7RhVrXHjxjKZTMrLy7Nqu9mzZ6tt27bas2ePxXJr3p/KaN68udzd3bV3716rtivPs88+W2bZrl27ZBiGevToYdW+DMPQ5MmTtX//fmVkZJR7J+ztSq9xkyZNrDoWgOqB/LEt8of8AVA55I9tkT+1K39oxgEAAAB24u7urkmTJmnt2rVavny58vPztX//fkVHRyswMFBjxowxjw0NDdXFixeVkZGhoqIinTt3TsePHy+zz/r16+v06dM6duyYrly5Yv7jsqSkRJcuXdLNmzf13XffKSYmRsHBwRo1apRNjrFp0yb5+vpqzpw5tr9QleTp6alWrVrp5MmTVm1XOl2Lk5NTmeWVfX8qe5xXXnlFK1asUEpKivLz81VcXKyTJ0/qzJkzkqSoqCg1adJEu3fvvuO+Tp06pZUrV+ry5csqKirS9u3b9dprryk4OFjR0dFW1fXDDz9o/vz5Wrp0qVxcXCymkDGZTPrwww/LbFN6jcPCwqw6FoDqgfyxLfKH/AFQOeSPbZE/tSt/aMYBAAAAdvTee+8pISFBs2bNUsOGDdWrVy+1aNFCmZmZ8vLyMo8bN26cnnrqKb344otq06aNZs+ebZ4io0ePHsrJyZEkRUdHq3Hjxmrfvr369eunixcvSro1t31YWJg8PDzUs2dPtW7dWl9//bXFlB73e4zqoH///srKyrJ4/sFf//pXhYaG6vDhw+rWrZvefPPNMtt1795dsbGxZZZX5v1JSUlRYmKiJKljx446cuSIli5dqkmTJkmS+vbtq+zsbElSUlKSJk6cqHnz5qlBgwYKDAxUTEyMLl26JOnW9Ce5ublat27dHc+zb9++mj59uoKCguTp6anIyEg99thj2rFjhxo0aGAet2PHDj3++ON64IEHtHPnTu3bt0+BgYF67LHHtHXrVkm37gy11q5du9SsWTN17NjR6m0BVA/kj22RP+QPgMohf2yL/Kk9+WMy7qUyAACA2wwbNkySlJ6e7uBKAPsymUxKS0tTZGSko0sxGzt2rNLT03XhwgVHl1Kue/l8GDt2rDZs2FDmLtBDhw6pXbt2Sk1N1YgRI2xaZ1UoKSnRk08+qVGjRunVV191dDnlunDhgoKCghQfH2/+g7tUTEyMli9frvPnz1d6f/bOB/IHdQX5Yz3y5xfkj+2RP6gryB/rkT+/IH9+wTfjAAAAgFrAmod61xSFhYX64osvlJ2dbX6gdmhoqGbNmqVZs2bp6tWrDq7QOsXFxcrIyNCVK1cUFRXl6HIqNHPmTHXu3Fnjx4+XdOvO0tOnT2vbtm06dOiQg6sDUN2QP9Uf+QOgNiJ/qj/yxxLNOAAAAADV0sWLF9W3b1+1bt3a4i7KuLg4DRs2TFFRUVY/zNyRMjMztWbNGm3atEmenp6OLqdcCxYs0N69e/X555/LxcVFkrRu3To1a9ZMPXv21MaNGx1cIQDYH/lT9cgfACB/HKEq84dmHAAAAFCDTZ06VampqcrLy1PLli21evVqR5dkE0uWLJFhGObX8uXLLdbPmTNH48eP1+9//3sHVWi93r1767PPPlPTpk0dXUq51q1bp59//lmZmZkKCAgwLx80aJDFe2HNFC0Aai/yh/yxFfIHgDXIH/LHVqo6f5xtshcAAAAADpGQkKCEhARHl+EQffr0UZ8+fRxdRq0xcOBADRw40NFlAKghyB/yx1bIHwDWIH/IH1up6vzhm3EAAAAAAAAAAACAndCMAwAAAAAAAAAAAOyEZhwAAAAAAAAAAABgJzTjAAAAAAAAAAAAADtxdnQBAACg9jh58qRWrVrl6DIAu9u+fbujS6hRTp48KUl8PtRRJ0+eVFBQkN2Pwc8X6gLyxzrkT91G/gC2Q/5Yh/yp2yrKH5NhGIYD6gEAALXMsGHDtHr1akeXAQCohoYOHar09HS77Jv8AQBUhPwBADhCeflDMw4AAACwscjISEncCQkAAAAAAHhmHAAAAAAAAAAAAGA3NOMAAAAAAAAAAAAAO6EZBwAAAAAAAAAAANgJzTgAAAAAAAAAAADATmjGAQAAAAAAAAAAAHZCMw4AAAAAAAAAAACwE5pxAAAAAAAAAAAAgJ3QjAMAAAAAAAAAAADshGYcAAAAAAAAAAAAYCc04wAAAAAAAAAAAAA7oRkHAAAAAAAAAAAA2AnNOAAAAAAAAAAAAMBOaMYBAAAAAAAAAAAAdkIzDgAAAAAAAAAAALATmnEAAAAAAAAAAACAndCMAwAAAAAAAAAAAOyEZhwAAAAAAAAAAABgJzTjAAAAAAAAAAAAADuhGQcAAAAAAAAAAADYCc04AAAAAAAAAAAAwE5oxgEAAAAAAAAAAAB2QjMOAAAAAAAAAAAAsBOacQAAAAAAAAAAAICd0IwDAAAAAAAAAAAA7IRmHAAAAAAAAAAAAGAnNOMAAAAAAAAAAAAAO6EZBwAAAAAAAAAAANgJzTgAAAAAAAAAAADATmjGAQAAAAAAAAAAAHZCMw4AAAAAAAAAAACwE5pxAAAAAAAAAAAAgJ3QjAMAAAAAAAAAAADshGYcAAAAAAAAAAAAYCcmwzAMRxcBAAAA1FSfffaZli1bppKSEvOyo0ePSpJatmxpXlavXj3913/9l4YPH17lNQIAAAAAAMehGQcAAADch++++06dOnWq1Nh9+/apY8eOdq4IAAAAAABUJzTjAAAAgPvUtm1bHTx48I5jQkNDlZ2dXUUVAQAAAACA6oJnxgEAAAD36eWXX5aLi0uF611cXPTKK69UYUUAAAAAAKC64JtxAAAAwH06cuSIQkNDdadfrbOzsxUaGlqFVQEAAAAAgOqAb8YBAAAA96lVq1Z65JFHZDKZyqwzmUzq2rUrjTgAAAAAAOoomnEAAACADfz2t7+Vk5NTmeVOTk767W9/64CKAAAAAABAdcA0lQAAAIAN5ObmKjAwUCUlJRbL69Wrp9OnT6tJkyYOqgwAAAAAADgS34wDAAAAbKBx48bq1auXxbfjnJyc9OSTT9KIAwAAAACgDqMZBwAAANjIyy+/rNsnnnj55ZcdVA0AAAAAAKgOmKYSAAAAsJH8/Hw1atRIN27ckCS5uLgoNzdX/v7+Dq4MAAAAAAA4Ct+MAwAAAGzE19dXffv2lbOzs5ydndWvXz8acQAAAAAA1HE04wAAAAAbGjFihIqLi1VcXKzhw4c7uhwAAAAAAOBgTFMJAAAA2ND169fVsGFDGYah8+fPy8PDw9ElAQAAAAAAByrTjFu1apVeeOEFR9UDAAAAAAAAAIDS0tIUGRnp6DIA4L45V7QiLS2tKusAUMskJiZKkiZOnOjgSmqO7du3Kykpic9fAKgF9u7dK5PJpE6dOjm6FAAAAKBG4gsjAGqTCptx3HEA4H6kp6dL4rPEWklJSVwzAKgFnn/+eUmSs3OFv24DAAAAuAOacQBqE/51AAAAALAxmnAAAAAAAKBUPUcXAAAAAAAAAAAAANRWNOMAAAAAAAAAAAAAO6EZBwAAAAAAAAAAANgJzTgAAAAAAAAAAADATmjGAajWPv/8c/n5+elvf/ubo0sBAAC4L1999ZXi4uK0Zs0atWrVSiaTSSaTSS+//HKZsX369JGPj4+cnJz08MMPa/fu3Q6ouPLi4+PN5/PrV4cOHcodX1JSosTERIWHh5e7ftasWWrfvr18fX3l5uam0NBQvfPOO7p69ap5zPr16zVv3jwVFxfb5ZwAAAAAwFZoxgGo1gzDcHQJAAAA9+29995TcnKypk6dqiFDhujIkSMKCQlRgwYNtHz5cm3cuNFi/Jdffqn09HRFREQoKytLjzzyiIMqt73s7Gw98cQTio2NVUFBQbljtmzZojfeeEPHjh3T+fPnlZCQoKSkJA0bNsw8ZsCAAXJ3d1fv3r11+fLlqiofAAAAAKxGMw5Atda/f3/l5eUpIiLC0aWosLCwwru3AQAAKjJ37lytXLlSq1atko+Pj8W65ORk1atXT2PGjFFeXp6DKrSNTz/9VIZhWLy+//57izH79u3TlClTFB0drc6dO1e4L29vb40ZM0b169eXj4+PIiMjNXjwYG3evFk5OTnmcRMmTFCnTp3Ur18/3bx5027nBgAAAAD3g2YcAFTSsmXLlJub6+gyAABADXLo0CHNmDFD77//vtzd3cusDw8PV0xMjE6dOqW33nrLARVWrU6dOmnNmjUaPny43NzcKhy3YcMGOTk5WSxr2LChJJX5Nt3MmTO1d+9eJSUl2b5gAAAAALABmnEAqq1t27YpODhYJpNJixYtkiSlpKTIy8tLnp6eWrdunZ577jn5+voqKChIK1asMG+bnJwsd3d3NW7cWGPHjlVgYKDc3d0VHh6unTt3mseNHz9erq6uatq0qXnZ66+/Li8vL5lMJp0/f16SFBMTo0mTJunw4cMymUwKDQ2VJG3evFm+vr6aM2dOVVwSAABQwyQnJ8swDA0YMKDCMfHx8WrdurU++eQTffXVV3fcn2EYWrBggdq1ayc3NzcFBARo0KBBOnDggHlMZX9fkqTi4mK9++67Cg4OloeHhzp27Ki0tLT7O2k7OXXqlDw8PNSyZUuL5QEBAerVq5eSkpKY4hwAAABAtUQzDkC19fjjj+ubb76xWDZu3DhNnDhRhYWF8vHxUVpamg4fPqxWrVpp9OjRKioqknSryTZq1CgVFBRowoQJOnbsmHbv3q2bN2/qmWeeMU9vlJycrMjISItjLF68WO+//77FsqSkJEVERCgkJESGYejQoUOSbv0DliSVlJTY5RoAAICabePGjWrTpo08PT0rHOPh4aE//elPqlevnkaPHq1r165VOHbmzJmKi4vTtGnTlJubq61btyonJ0c9e/bU2bNnJVX+9yVJmjJliubPn6/ExESdOXNGEREReumll/Ttt99afa5xcXEKCAiQq6urWrZsqUGDBmnXrl1W76c8BQUF2rJli0aPHi1XV9cy67t06aJTp05p3759NjkeAAAAANgSzTgANVZ4eLh8fX3VqFEjRUVF6dq1azpx4oTFGGdnZ/Od4+3bt1dKSoquXLmi1NRUm9TQv39/5efna8aMGTbZHwAAqD2uXbumo0ePKiQk5K5je/TooYkTJ+rYsWOaMmVKuWMKCwu1YMECPf/88xoxYoT8/PwUFhamJUuW6Pz58/r444/LbHOn35euX7+ulJQUDR48WEOGDJG/v7+mT58uFxcXq39XGjlypNavX6+cnBxdvXpVK1as0IkTJ9SrVy9lZWVZta/yJCQkKDAwUPHx8eWuf+ihhyRJ+/fvv+9jAQAAAICt0YwDUCuU3iH96zu9y9O1a1d5enpaTOUEAABgD7m5uTIM447fivu1+Ph4tWnTRosXL9a2bdvKrM/KytLVq1fVtWtXi+XdunWTq6urxVTc5bn996WDBw+qoKBAHTp0MI/x8PBQ06ZNrf5dqXnz5urSpYu8vb3l6uqq7t27KzU1VYWFhVq8eLFV+7rd2rVrtWrVKn3xxRfy8fEpd0zpNS79diAAAAAAVCc04wDUOW5ubjp37pyjywAAALXc9evXJd363aMy3N3dlZqaKpPJpFdffVWFhYUW6y9fvixJ8vb2LrOtv7+/rly5YlV9pdNhTp8+XSaTyfw6fvy4CgoKrNpXecLCwuTk5KQff/zxnvexcuVKzZ07V5mZmWrRokWF4zw8PCT9cs0BAAAAoDqhGQegTikqKtLly5cVFBTk6FIAAEAtV9ogKn3GbGX06NFDsbGxys7O1uzZsy3W+fv7S1K5Tbd7+f2mUaNGkqTExEQZhmHx2r59u1X7Kk9JSYlKSkoq3Yy83cKFC7V8+XJt2bJFDzzwwB3H3rhxQ9Iv1xwAAAAAqhOacQDqlMzMTBmGoe7du5uXOTs733V6SwAAAGs1btxYJpNJeXl5Vm03e/ZstW3bVnv27LFY3qFDB3l7e+vbb7+1WL5z507duHFDjz76qFXHad68udzd3bV3716rtivPs88+W2bZrl27ZBiGevToYdW+DMPQ5MmTtX//fmVkZJT7TcDblV7jJk2aWHUsAAAAAKgKNOMA1GolJSW6dOmSbt68qe+++04xMTEKDg7WqFGjzGNCQ0N18eJFZWRkqKioSOfOndPx48fL7Kt+/fo6ffq0jh07pitXrqioqEibNm2Sr6+v5syZU4VnBQAAagJPT0+1atVKJ0+etGq70ukqnZycyiyfNGmS1q5dq+XLlys/P1/79+9XdHS0AgMDNWbMGKuP88orr2jFihVKSUlRfn6+iouLdfLkSZ05c0aSFBUVpSZNmmj37t133NepU6e0cuVKXb58WUVFRdq+fbtee+01BQcHKzo62qq6fvjhB82fP19Lly6Vi4uLxRSaJpNJH374YZltSq9xWFiYVccCAAAAgKpAMw5AtbVo0SJ169ZNkjR58mQNHDhQKSkpSkxMlCR17NhRR44c0dKlSzVp0iRJUt++fZWdnW3ex/Xr1xUWFiYPDw/17NlTrVu31tdff20xXdK4ceP01FNP6cUXX1SbNm00e/Zs8xRHPXr0UE5OjiQpOjpajRs3Vvv27dWvXz9dvHixSq4DAACoufr376+srCyL57/99a9/VWhoqA4fPqxu3brpzTffLLNd9+7dFRsbW2b5e++9p4SEBM2aNUsNGzZUr1691KJFC2VmZsrLy0uSrPp9KSkpSRMnTtS8efPUoEEDBQYGKiYmRpcuXZJ0a/rH3NxcrVu37o7n2bdvX02fPl1BQUHy9PRUZGSkHnvsMe3YsUMNGjQwj9uxY4cef/xxPfDAA9q5c6f27dunwMBAPfbYY9q6daukW9+Ms9auXbvUrFkzdezY0eptAQAAAMDeTMZtf+msWrVKL7zwwj39AQQApYYNGyZJSk9Pd1gNY8eOVXp6ui5cuOCwGqzB5y8AALXPoUOH1K5dO6WmpmrEiBGOLsdqJSUlevLJJzVq1Ci9+uqrji6nXBcuXFBQUJDi4+PNDUcAAFDzmUwmpaWlKTIy0tGlAMB945txAGq14uJiR5cAAADqsNDQUM2aNUuzZs3S1atXHV2OVYqLi5WRkaErV64oKirK0eVUaObMmercubPGjx/v6FIAAAAAoFx2bcb9/PPPmjBhgpo2bSpPT09t3ry5Utt169ZNTk5O6ty5sz3Lq1Fee+01+fj4yGQyVfoB6x9++KH5ofFLliy552OXlJQoMTFR4eHh9zXmbqKioso8D6Ki14YNG7RmzRq1atXqjuNatGghSRWOdXZ2VsOGDfX0009r7dq191z73dx+/BkzZtxx/IIFC2QymVSvXj21bdvWPGXPvXLkzw8AAEBdFxcXp2HDhikqKkp5eXmOLqfSMjMztWbNGm3atEmenp6OLqdcCxYs0N69e/X555/LxcXF0eUAAAAAQLns2oz7wx/+oM2bN+vAgQNKSkqq9J2gu3bt0lNPPWXP0mqcTz75REuXLrVqm7feekvffPPNfR03OztbTzzxhGJjY1VQUHDPYyrryy+/ND/0vfSh8QMGDNCNGzd07do15ebmavTo0ZKkIUOG6MiRIwoJCZGfn58Mw5BhGLp586YKCgp09uxZ8z8aVDT23LlzSktL06lTpzRkyBClpaXdV/0V+fXxpVvvZ1FRUblji4uLlZycLEn6zW9+owMHDuiJJ564r+M76ufHkaZOnarU1FTl5eWpZcuWWr16taNLAgAAddicOXM0fvx4/f73v3d0KZXWu3dvffbZZ2ratKmjSynXunXr9PPPPyszM1MBAQGOLgcAAAAAKmSTZlxhYWG534jKyMhQ165d5e/vr9/97ncaOnSoVfs1mUy2KK9cFdWMX+zbt09TpkxRdHR0hd9SrMyYyjKZTHrsscfk5+cnZ2dni+UuLi7y9PRUo0aN9Oijj95xP05OTvLw8FDjxo3VunXrO44NCAhQ79699d///d+Sbj2zyxbu9PP16KOP6qefflJGRka569esWaNmzZrZpI66LCEhQT///LMMw9DRo0et/vwBAACwtT59+mju3LmOLqPWGDhwoOLi4uTk5OToUgAAAADgjmzSjFu2bJlyc3PLLD958uR9TRViz2lGKqq5OrNnc7I8nTp10po1azR8+HC5ubnd85jKWrFiRaWmvxkzZoz+8z//s1L7rKjhdbvS6SwvX75cqfF3c6efr3HjxkmSPvroo3LXL1iwwC4Pnq/qnx8AAAAAAAAAAGCDZlxMTIwmTZqkw4cPy2QyKTQ0VH//+98VGhqqM2fO6M9//rNMJpO8vb2t3vehQ4fUtm1beXl5ycPDQz179tS2bdssxhQXF+vdd99VcHCwPDw81LFjR/NUg/Pnz5enp6d8fHyUm5urSZMmqVmzZnruuefK1FxZSUlJ8vLyUr169fToo4+qSZMmcnFxkZeXlx555BH17NlTzZs3l7u7u/z9/fXOO+9YbG8YhhYsWKB27drJzc1NAQEBGjRokA4cOFBm3AcffKA2bdrIzc1Nfn5+evvtt8vUc6fzr042b94sX19fzZkzx9GllOu7776TJPXq1ctiuT1+vn7zm9+oXbt2+vrrr3Xw4EGLdf/7v/+rgoIC9enTp9w66+rPDwAAAAAAAAAANdV9N+OSkpIUERGhkJAQGYahQ4cO6ZlnntGhQ4fUpEkTjRw5UoZhVPp5cb8WEBCgzZs3Ky8vT99++62Kior0zDPPKDs72zxmypQpmj9/vhITE3XmzBlFRETopZde0rfffqt33nlHsbGxunr1qhISEtSyZUt1795diYmJZWqurJiYGL399tsyDEMfffSRjh49qp9++klPPPGE9uzZo7i4OO3Zs0cXL17UyJEj9cEHH2jfvn3m7WfOnKm4uDhNmzZNubm52rp1q3JyctSzZ0+dPXvWPG7GjBmaPHmyxowZo7Nnz+qnn37SlClTytRzp/OvToqLiyVJJSUlVXK8LVu26MMPP7zruMLCQm3evFlvvfWW+vTpU+Ybafb6+Ro7dqwkacmSJRbL//CHPyg2NrbCeuvqzw8AAAAAAAAAADWVTaaptBcfHx+1aNFCzs7Oevjhh7V06VJdv35dH3/8sSTp+vXrSklJ0eDBgzVkyBD5+/tr+vTpcnFxUWpqqsW+5s6dqzfeeENr1qxR27ZtbVJf+/bt5enpqQYNGujFF1+UJAUHB6thw4by9PTUiBEjJMn8raXCwkItWLBAzz//vEaMGCE/Pz+FhYVpyZIlOn/+vPm8CgsLlZiYqKefflqxsbHy9/eXh4eH6tevb3F8a87f0fr376/8/HzNmDHDLvvPy8uTyWQyv3r37l2psZ6ennruuefk6+ur4cOHW0yNas+fr5EjR8rLy0t//vOfVVhYKEk6cuSIdu36/+zdeXxM9/4/8NdknWwzSSSREEHELna9hFZwS1tFQyQp7u/SVpHr2tJaSl1bVGhFLWlvtXxvaYnt2qmrqrRFqZ3ai0TsRBIJ2d6/PzwyNZnJZCaZyWR5PR+P/OGczznnfT7n8/mcMe8553MYAwYM0LtNVW4/REREREREREREREQVlZ21AzBFcHAw1Gq15pWC58+fR2ZmJpo1a6Yp4+TkBF9fX53X9lmag4MDACA3N1ezrCCxRU6OTwAAIABJREFUk5OTAwA4c+YMMjIy0LZtW61t27VrBwcHBxw6dAjAs9dzZmZmGkwoAeXr/K1NrVZrzfe2d+/eIp/uer5sbm4ubt++jV27dmHUqFGYPXs2fvrpJ3h5eVm0ftVqNQYMGIClS5di9erVGDJkCOLj4xEdHQ0HBwdkZ2frbFMR209ycjLWrFljln1VBQcOHAAA1hkRERERERERERFRJVKhknHAswRXQXLr8ePHAIApU6ZgypQpWuX8/PzKPLbiFCSA9M2f5+7ujvT0dADPEhgA4O3tbXB/Fe38y1JoaChCQ0OLLWdnZ4eaNWtiyJAhyMvLw9ChQ/HRRx/hk08+sXj9RkdHY+nSpfj8888RFhaGtWvX4vfffy+yfEVsPwcPHkRkZKRZ9lWVsM6IiIiIiIiIiIiIKo8KlYzLzc3FgwcPEBAQAODPZEN8fDzGjBljzdCM4u7uDgCapMnzUlNT4e/vDwBQKpUAgKdPnxrcX0U7//IuODgYAHD27FkAlq/fli1bon379jh48CCGDRuG/v37w8PDo8jyFbH9hIeHY+3atRbZd2W0Zs0aREZGQkSsHQoRERERERERkVUpFAprh0BEZDbles64wn744Qfk5+ejdevWAIBatWpBqVTi+PHjVo7MOM2aNYOrq6vO6xMPHTqE7OxstGnTRlPOxsYGP/74o8H9VbTzL+9+++03AEDDhg0BlE39RkdHAwDWrVuHsWPHGizL9kNEREREREREREREVPGYJRnn6emJlJQUXL16Fenp6ZrXSJZWdnY2Hj16hNzcXBw9ehSjRo1C7dq1MXjwYADPngAaMmQIVq1ahYSEBKSlpSEvLw/Jycm4efOmVWI2RKlUIiYmBhs2bMDKlSuRlpaGU6dOYcSIEfDz88OwYcMAPHtiqV+/fli3bh2++uorpKWl4eTJk/jiiy909lfS8y9rO3bsgEqlQmxsrLVDAQBkZWUhPz8fIoKUlBQsX74cU6ZMgZeXlyYpVhbtKyIiAl5eXggLC0NgYKDBfVbl9kNEREREREREREREVGFJIYmJiaJnsUFHjx6V2rVri5OTk3Tq1EkOHTokrVq1EgBiZ2cnrVu3lnXr1pm0z+XLl0uXLl3Ex8dH7OzspFq1avLmm2/KtWvXtMo9ffpUJkyYIAEBAWJnZyfe3t7Sr18/OXPmjMTFxYmTk5MAkFq1asmKFSuKjPnWrVtGxbVgwQJxdnYWAFKnTh3Zv3+/zJkzR9RqtQCQ6tWryzfffCOrV6+W6tWrCwDx8PCQVatWiYhIfn6+zJs3T+rXry/29vbi4eEhYWFhcv78ea3jpKenyzvvvCPVqlUTV1dX6dSpk0ydOlUAiL+/v5w4caLY8//kk080Mbi4uEjfvn1NugYHDhyQjh07ip+fnwAQAOLr6yshISHy448/Gl1GRGT79u3i5uYms2bNKva4aWlp8tJLL4mnp6cAEBsbGwkKCpLY2Fitcj///LM0aNBA67jdunXTu88NGzZIvXr1NGWf/3N0dJT69etLdHS0XL9+XWs7c7Wvzz77THN8Ly8vGTlypKbs+PHj5ZdfftH8e8qUKeLr66s59yZNmsj+/ftFpGK1n/DwcAkPDzdpm6quJOMvEREREREREVFlBEASExOtHQYRkVkoRLQnJ+KcRURkDv379wcAzhlnAo6/RERERERERETPKBQKJCYmIiIiwtqhEBGVWoWaM46IiIiIiIiIiIiIiIioIimzZNy5c+egUCiK/YuKiiqrkCpEbOZUVc6TiIiIiIiIiIiIiIiovCizZFyjRo0gIsX+rV69uqxCqhCxmVNVOU+iqiIqKsqoBLtCocDWrVuxfv16BAYGGixXp04dACiyrJ2dHby8vPDXv/4VGzZsKLNzLRzPhx9+aLD8/PnzoVAoYGNjg0aNGmHfvn2lOv4777wDNzc3KBQKHD9+3KhtPv74Y/j4+EChUODzzz/XWb97926Eh4ejVq1acHR0hKurK5o2bYqxY8fi2rVrpYq3rLVu3Vpzbfz8/DB69Ohit7lw4QLatWsHV1dX2NjY4JVXXsH27duhVquxZcuWIrcbMmQIlEolFAoFnjx5UmQ5fW3Y3t4eNWvWxMCBA/H777+X6FyNUdS1N+b8zGn37t2YNGlSsW2xLBl7/QDj6svYvlmSPkzaCtpT4b71t7/9Tads9+7d4ebmBltbWzRt2hRHjx61QsTGmzVrlt57YrNmzfSWz8/PR3x8PEJCQvSunzFjBpo0aQKVSgVHR0cEBQVh/PjxyMjIKFF8oaGhRd63XV1dtcrm5ORg9uzZCAoKgoODA9zd3dGsWTNcvXpVq9y3336Ldu3awc3NDbVr18aQIUNw69YtzfrNmzcjLi4OeXl5JYrZWsrTeFeVVObxoSL2P95rK4fK2J8qgrL+vF5SFaV9VNTPE0REFlN4ErnExETRs5iIyCTh4eESHh5u7TAqFFPH38jISNm1a5ekpqZKTk6O3Lx5UwBI7969JTs7Wx4/fix37tyRoUOHypYtWzTb1atXT9Rqtebfubm5kpmZKbdv35bGjRtrHaNw2QcPHsju3bulUaNGAkBWr15dijM2Xb169QSA+Pr6SnZ2tt4yubm5Urt2bQEg3bp1M9uxV61aJQDk2LFjRm9z8eJFASCfffaZ1vIJEyYIABkyZIgcO3ZMsrKy5NGjR7Jz505p06aNqFQq+f77780We1no3r27KBQKuXnzps663Nxc6dKli97tPv30Uxk4cKCIiGzdulVUKpVs3rzZ4LEmT54sACQrK6vYuJ5vwxkZGbJ582YJCAgQV1dXOXfuXLHbl5S+a2/s+ZnD1KlTpVevXpKWllZkPNZi7PUztr6M7Zsl6cP0TOH2JPKsb1WrVk0AyNatW3W22bFjh/Tp06cswyyxmTNnCgCdv6ZNm+qUvXDhgnTs2FEASIsWLfTur3PnzrJkyRK5f/++pKWlSWJiotjb28srr7xSovg6d+6sNz4A0qNHD62yYWFh0rBhQzl48KDk5ORISkqK9O7dW06dOqUps3r1agEgcXFxkpqaKseOHZPAwEBp2bKl5OTkaMotWLBAOnfuLA8fPixR3NZSnsa7qqCyjw8Vtf/xXlt5VKb+VBGU5ed1c6gI7aO04xkASUxMNHNURETWwTnjiKjSysrKKvJX6xXpGEVRKBTo2LEj1Go17OzstJbb29vD2dkZ3t7eaNOmjcH92NrawsnJCT4+PmjQoIHBsh4eHujWrRs+/fRTAMCaNWtKfyImatOmDW7duoWNGzfqXb9+/XrUrFmzjKMy3qZNmxAXF4d3330Xy5YtQ8uWLaFUKqFSqdCjRw/s3bsXvr6+iIiIwP37903ev7XafVRUFEQEW7du1Sn/ww8/4IcffsDZs2d11m3fvh2RkZEAgJ49e+LRo0fo1auXwWOVlIuLC3r16oVPP/0UGRkZWLRokVn2ayx952cJc+bMwerVq7FmzRq4ublZ5Bhl0c7Kqr7Ki5LUaVlcB0PtaeHChbCxscGwYcPw6NEji8ZhaStWrNB5W8Tp06e1ypw4cQITJ07EiBEj0LJlyyL35erqimHDhsHT0xNubm6IiIhAWFgYdu7ciaSkJJNjUyqVSEtL04lv2LBhGD9+vKbc6tWrsXHjRqxduxZ/+ctfYGdnBz8/P2zatEnrKb9///vfqFGjBt5//32o1Wq0bNkS48aNw/Hjx3Ho0CFNudGjR6NFixZ47bXXkJuba3LcVHIV5TNsVRgfKnv/473WMtuYW2XpT8XRV9eWrH99+66IfaK8tw9+niAi+hOTcURUaX311Ve4c+dOhT9GUVatWgVnZ+diyw0bNgyvv/66UfssKsFVWMHrLFNTU40qb07R0dEAgM8++0zv+vnz5yMmJsbsx1UoFGbZz8cffwwAmDJlit71rq6uGDduHO7fv48vv/zS5P1bq9337dsXDg4O2Lx5s075Xbt2oUaNGli3bp3W8qysLJw4cQI9evQw6VgFSnpNXnjhBQDQ+aK9ohERrF27Fl988YVm2aVLl/Dhhx9i+vTpUCqVFju2OdqZufqUsfsx1/EspSR1aun+Xlx7CgkJwZgxY3Djxg289957FoujvGjRogXWr1+PgQMHwtHRschyW7duha2trdYyLy8vAEBmZqbJx925c6dOoiMpKQmnT59G165dNcs+++wztG7dGsHBwQb3l5SUBD8/P60+UatWLQDQeU3ytGnTcPz4cSxYsMDkuKnkKsJn2KoyPlT0/sd7rbbyeK81RmXpT8XRV9eWrP/ycG3NoSK0D36eICJ6hsk4Iio3RATz589H48aN4ejoCA8PD7zxxhs4d+6cpsyoUaPg4OAAX19fzbJ//OMfcHFxgUKhwL179wAAY8aMQUxMDC5fvgyFQoGgoCAsXLgQSqUSPj4+GD58OPz8/KBUKhESEqL1S9TSHAN49p92lUqF2NhYi9aXNZ08eRIA0LlzZ63l+/fvR5MmTaBWq6FUKhEcHIzvvvtOs/7HH3/ECy+8AGdnZ6hUKgQHByMtLQ0AkJeXh6lTpyIgIABOTk5o3rw5EhMTdY7dtWtXNG7cGD/88APOnz+vte7nn39GZmYmunfvrjduY9pYQbl58+ahYcOGcHR0hFqtxvvvv6+zP2NjLpCZmYmDBw8iICBA88WLPh06dAAA/O9//wNQMdq9Wq1Gjx49sHv3bmRlZWn2kZOTAwAIDw/XScZ9//336NGjBxwcHPDTTz8hICAACoUCixcvNngsALCxscG2bdvw6quvQq1Ww8/PD8uWLSuyTp9X8IvM579MN6VtGFOuMH3nl5CQABcXFzg7O2PTpk149dVXoVKp4O/vj1WrVmltn5eXh9mzZ6Nhw4ZwcnKCl5cX6tati9mzZyMiIkJTbuHChRAR9O7du9h6KGl/NXRdjFXc9dNXX4DxfdMcfdiU62MsU+vU0DUqahtD55SRkVHsHKPt27fXxGtMe5o1axYaNGiAL7/8Ert37zZ4/sb0H1P7hSljsDXduHEDTk5OqFu3rln2N2fOHK35ObOzs3Hw4EGDT+wVCAwM1PnysWC+qsDAQK3lHh4e6Ny5MxYsWAARMTo+Y+89gOXHX8BwW5k7dy6cnZ3h5uaGO3fuICYmBjVr1tT5jGFIZfgMy/HBeOW9/xXgvdY691pDMZjaz55XGfqTqXVdkvo39rz07dtQnzBnfVbF9lHa8YyIqNIo/N5KzhlHROZQkjnjpk6dKg4ODrJixQpJTU2VkydPSuvWrcXLy0tu3bqlKTdw4ECpXr261rbz5s0TAHL37l3Nsn79+km9evW0yg0bNkxcXFzk7Nmz8uTJEzlz5oy0a9dO3Nzc5Pr162Y5xtatW8XNzU1mzJhh0vmXdvwtmDOuuHfCF54HTkTk+++/l3nz5hVbNjMzU3bs2CG1a9eW7t27S0ZGhlb5tWvXyrRp0+TBgwdy//59ad++vVSrVk1Ens3XpVKpJC4uTrKysuTWrVvSt29fTX2+99574ujoKOvWrZOHDx/KBx98IDY2NnL48GGteP744w/59NNPBYCMGTNG6/hhYWGyfPlySU9P1ztnnLFtbPLkyaJQKOSTTz6Rhw8fSmZmpixZskRnDoziYi48b83vv/8uAKRt27YGr9Ht27cFgNStW1ezrLy3exGRb775RgBozbGwbds2+e6772T//v0CQM6fP69ZN2LECNm+fbvm30lJSQJAFi1aZPBYBfOgfP/995KamioPHjyQ1157TRwdHeXx48daZfW19xUrVggAef/99zXLjG0bxpbTN2eRvvN7/lwePXokd+7ckRdffFFcXFy05kWMjY0VW1tb2bRpk2RmZspvv/0m1atXl9DQUK1zCwwMlCZNmhS+NHrjKU1/LaoNGMPY61dUfRnTN83Vh429PsYoSZ0aukZFbWPMWGqsotqTyJ/jsYjIL7/8IjY2NlKnTh3NfUHfHCWmjMHG1Lu5znXmzJni7+8v7u7uYm9vL3Xq1JE+ffrIr7/+WuQ2f/nLX4qcM66wx48fi5ubm4waNcqkuIqSnJwsTZo0kby8PM2yP/74QwBIy5YtJTQ0VHx9fcXR0VEaNWokixcvlvz8fE3ZvXv3ir29vSxcuFDS0tLk9OnT0rhxY535rwpMmjSpRHNAGXvvKYvx19i+Pnr0aFm0aJH07dtXfv/9d6PPtbJ8hjVFVRkfCqso/Y/3Wuvda4uLwVSVqT+VpK5L8lnH2PPSt299fcKc9VmV20dJxzNwzjgiqkSYjCMiizA1GZeZmSmurq4SFRWltfzXX38VAFqJrdJ+kVH4i/nDhw8LAJk+fbpZjlFSZZmMg55J6ItKxukrGxwcLP/5z3/k6dOnBo81e/ZsASB37tyR06dPFzmxdFZWljg7O2td/8zMTHF0dJTo6GiteP744w9JTU0VFxcX8fDwkMzMTBERuXz5svj7+8vTp0/1JuOMbWOZmZni7OwsL7/8sla5whPSGxNz4S8EC9pa165dDdbb06dPBYB4eXlpllWEdp+eni5OTk7yzjvvaJbFxMRITk6O5OfnS40aNWTWrFmada1bt9b6j5ypybisrCzNsq+//loAyOnTp7XKPp+My8jIkHXr1kn16tXFx8dHkpOTRcS0tmHsOGVqMu75cyn4IuvSpUuaZe3atZMXXnhB67jvvvuu2NjYaPphRkaGKBQK6dWrlxSmL57CjO2vIuZJxhV3/QrXl7F905x92NjrYwxz1Onz10jfNsaOpcYw1J5EtL/8EXnW1wHIyJEjRUT3yx9T+o8x9W7Oc71+/bocPXpU0tPT5enTp3LgwAFp1aqVODk56YwpBUxJxk2ePFkaNGggaWlpJsVVlJEjR+r05VOnTgkAefnll+Xnn3+W+/fvS2pqqkycOFEAyMqVK7XKT5kyReu+7u/vL0lJSXqPt2zZMgEgX3/9tUlxGnPvKYvxt6R93VhV8TNsVRofCqso/Y/3Wuvda4uLwVSVuT8VV9f6lpmzTRmTjDN3fVbl9lHS8YzJOCKqTPiaSiIqF86cOYOMjAy0bdtWa3m7du3g4OCg80ojc2rbti2cnZ2Nes1RZaFWq7Umof/hhx+MKpuTk4Pk5GSMHTsWo0aNQvPmzTWvPNLH3t4ewLNXVwQGBsLHxweDBg3CtGnTcPXqVU258+fPIzMzU2uCeycnJ/j6+uq9Lmq1GgMGDMDDhw+xevVqAEB8fDyio6Ph4OCgNxZj29ilS5eQmZmJbt26FXleJYkZgGbOkeLm2nvw4AEAQKVSGSxXGpZo966urujZsye2bt0KEcHTp09hZ2cHOzs7KBQK9OvXT/OqyrNnz6JVq1aaNlJaBfspeC3m8x49egSFQgG1Wo3Ro0fjtddew6+//oqaNWsCML5tlNU4VdCGnz+XJ0+e6LzSJS8vD/b29pq5qe7cuQMRMWouSX2M7a+WYOj6FTC2b1qyDwP6r48xzFGnz18jfUp6TvqY2p5mzZqFhg0bYsmSJfjpp5901pe2/xSud3Oea61atdCqVSu4urrCwcEB7du3x/Lly5GVlYUlS5aYtK/CNmzYgDVr1uC7777TmXeqJFJSUrB582YMHjxYa3nBa3ebNm2KkJAQeHp6Qq1WY/r06VCr1VpzS06ePBlffPEFvv/+e2RkZODKlSsICQlBhw4dkJSUpHPMgjZw+/btUsdf+N5TFuOvOduKPlXxM2xVGh+eV9H7H++1xintvdbSn6EqS38Ciq9rfcq6TZm7Pqty+zDneEZEVFExGUdE5UJBcsLV1VVnnbu7O9LT0y16fEdHR9y9e9eixyjPQkNDjZrs2c7ODjVr1sSQIUPw8ccf4/z58/joo48067dt24bQ0FB4e3vD0dER48eP16xzcnLCnj170KlTJ8TGxiIwMBBRUVHIysrC48ePAQBTpkzReif+tWvXkJmZqTeW6OhoAMDnn3+O1NRUrF27FsOHDy8ydmPbWHJyMgDA29vbYF2UJObatWvD3t6+2P+AFMwdUr9+fYPlSssS7T4qKgq3bt3C4cOHsX37drzyyiuadeHh4Th+/DguX76M7du3IzIy0qzHLkpBQjk3NxfJyclYtmwZateurVlvbNuw5jj12muv4bfffsOmTZuQlZWFI0eOYOPGjXj99dc1ybgnT54A0J4Lz5CS9ldrMbZvWrIPl0ZJ6tTQNdKnuHMyZS4SU9uTUqnE8uXLoVAo8NZbb+mcl7n7j6WvX3BwMGxtbXHhwoUS72P16tWYM2cO9u7dizp16pQ6JgCIi4vD0KFDoVQqtZb7+fkBgM4PZBwcHFC7dm1cvnwZAHDz5k3ExcXh3XffRdeuXeHi4oK6deti6dKlSElJwbx583SO6eTkBODPNlFaz997ymL8tXRbqSyfYTk+FK8y9L/i8F5b+nutoRhKMydYgYrcn0yta0vHYwxz12dVbh9lPZ4REZVHTMYRUbng7u4OAHo//KWmpsLf399ix87JybH4MSqj4OBgAM+ecAKA69evIywsDL6+vjh06BAePXqEuLg4rW2aNm2KLVu2ICUlBRMmTEBiYiI+/vhjzX/k4+PjtZ7YExEcOHBA7/FbtmyJ9u3b49dff8WwYcPQv39/eHh4FBmvsW2s4AuWp0+fGjz/ksSsVCrx4osv4saNG/jjjz+K3HfBrxh79OhhMIbSsFS779mzJ9zc3LB582bs27cPL730kmZdp06d4Ofnh3Xr1uHIkSPo0qWLWY9dUsa2DWuOU9OmTUPXrl0xePBgqFQq9O3bFxEREVi6dKmmTMF/cI35dXFp+qu1GNs3LdmHS8uUOjXmGhVW3Dm5urrqLC/8d/DgQQCmtacCHTp0wLhx43Dx4kXMnDlTa525+4+lr19+fj7y8/ONTjYUtmjRIqxcuRJ79uxBjRo1Sh0P8OyHGt9++63mxyjPc3V1Rf369TX35Ofl5uZCrVYDAC5evIi8vDydmFQqFTw9PXHmzBmd7bOzswH82SZKo/C9pyzGX0u3lcryGZbjg2GVof8Zg/fa0t9rDcVgSj8zpCL2p5LUtSXjMZYlxviq2j7KejwjIiqPmIwjonKhWbNmcHV1xZEjR7SWHzp0CNnZ2WjTpo1mmZ2dncmvlzBk7969EBGtX5mZ+xiV0W+//QYAaNiwIQDg1KlTyMnJQXR0NAIDA6FUKqFQKDTlU1JSNF9SeHt746OPPkLr1q1x9uxZ1KpVC0qlEsePHzcphoIvRNatW4exY8caLGtsG2vWrBlsbGzw448/GtxfSWOeOHEiAGDGjBl616elpSE+Ph4+Pj546623NMsrSrtXKpXo3bs31q1bBycnJ9jY/PlRw8bGBn379sXXX38NHx8f2NnZlepY5mJK2zB2nDK3M2fO4PLly7h79y5ycnJw/fp1JCQkaCWgfXx8oFAo8OjRo2L3V5r+ai3G9k1L9+GSMrVOi7tG+pjznExpT8+bOXMmGjVqhGPHjmktN3f/Mee56vvhw+HDhyEi6NChg0n7EhFMmDABp06dwsaNG/X+8ryk4uLiMGjQIHh6eupdHxkZiWPHjuHKlSuaZZmZmbh27ZrmBzQFX7LdvHlTa9v09HQ8ePAAtWrV0tlvQRuoXr16qc+h8L2nLMZfS/f1qvgZtiqNDwUqQ/8zBu+1pb/XltVnqIrWn0pS15aMx1jmrs+q3D7KejwjIiqPmIwjonJBqVQiJiYGGzZswMqVK5GWloZTp05hxIgR8PPzw7BhwzRlg4KC8ODBA2zcuBE5OTm4e/curl27prNPT09PpKSk4OrVq0hPT9d8MZGfn4+HDx8iNzcXJ0+exJgxYxAQEKA1/0NpjrFjxw6oVCrExsaav6KsJCsrC/n5+RARpKSkYPny5ZgyZQq8vLw0SbCAgAAAwO7du/HkyRNcvHhR653zKSkpGD58OM6dO4fs7GwcO3YM165dQ/v27aFUKjFkyBCsWrUKCQkJSEtLQ15eHpKTk3W+sHheREQEvLy8EBYWhsDAQIPnYGwb8/b21sxt9tVXXyEtLQ0nT57Umu+jYH8lifnll1/GRx99hP/85z8YPHgwTpw4gSdPniAtLQ27du1Cly5d8PDhQ6xbt07zS2qg/Lf750VFReH8+fN4/fXXdbbt378/zp49i7CwsCLryJRjmYOxbcOUccrcRo4ciYCAAGRkZBRZxtnZGYGBgZpXRxlSmv4KlM11KczYvmnpPlxSptZpwWvPirpG+raxtbU12zmZ0p6eV/B6pILXpz6/3Jz9x5jrFxUVherVq+Po0aMG93Xjxg2sXr0aqampyMnJwYEDB/DOO+8gICAAI0aMMCmus2fPYu7cuVi6dCns7e11Xi/1/NMZxsYHPJtfZdmyZQZ/eDJu3DjUrl0bgwcPxvXr13H//n1MmDABWVlZmh+C1K1bF126dMHSpUuxb98+ZGVlISkpSVP/b7/9ts5+C9pAQULBlLiLu/eUxfhr6b5emT7DGqsqjQ9Axe1/JcF7benvtcXFYC4VrT8V99kT0D8uWfKzjjHjoLnrsyq2jwKFxzMioipJCklMTBQ9i4mITBIeHi7h4eEmbZOfny/z5s2T+vXri729vXh4eEhYWJicP39eq9z9+/elS5cuolQqpW7duvLPf/5T3n//fQEgQUFBcv36dREROXr0qNSuXVucnJykU6dOcuvWLRk2bJjY29tLzZo1xc7OTlQqlbzxxhty+fJlsx1j+/bt4ubmJrNmzTLp/Es6/qalpclLL70knp6eAkBsbGwkKChIYmNjtcr9/PPP0qBBAwEgAMTX11e6deumd58bNmyQevXqaco+/+fo6Cj169eX6OhoTT0UmDBhgnh6eoq7u7v0799fFi9eLACkXr16sn//fgkJCREPDw+xtbWVGjVqyOTJkyU3N1dERJ4+fSoTJkyQgIAAsbOzE29vb+nXr5+cOXNGKx4vLy8ZOXKk5pjjx4+XX375RfPvKVOmiK+vr6YumjRpIvv37xcR49tYenqVzco6AAAgAElEQVS6vPPOO1KtWjVxdXWVTp06ydSpUwWA+Pv7y4kTJ4qN+ZNPPpHq1asLAHFxcZG+fftqHePAgQMyYMAACQgIEAcHB3FxcZFmzZpJTEyMJCcn61yT8t7un5ednS0tWrSQ/Px8nfPIy8uTFi1aSF5entbyRYsWaa6bs7Oz9O7dW++xxo0bJ05OTgJA6tevL5cvX5aVK1eKh4eH5vqcPn1ap737+flJ//79deIpYGzbMKacvmuv7/yWLFkizs7OWufyxRdfiEqlEgBSu3ZtuXDhgoiI7NmzR6pVq6bVF+3t7aVx48ayfv16zbFHjRol9vb2kpmZaTAekdL11+LaQFHi4uKMun5FtQdj+6Y5+rAp18cYV69eNblODV2j69ev693G0DmZSl97MjQeP+/999+XPn36aC0zpv+YUu/FnWtYWJgAkKlTpxo8z5iYGKlXr564uLiInZ2d+Pv7y9ChQyUlJUWr3IEDB6Rjx47i5+endS8NCQmRH3/8UURETp06pffeWfA3b948zf6MjU9EZNy4cTJo0KBiyyUlJcmbb74pHh4e4ujoKC+88ILs2LFDq8y9e/dkzJgxEhQUJI6OjuLq6iodO3aU//73v3r32bNnT6lZs6ZmTDc2bmPvPZYef0UMt5Xnx6VatWrJihUriq3nwirLZ1hTVJXxQaTi9T/ea617ry0uBmNVxv5Ukro2tf5NOa/C+37+/5HP9wlz1mdVbB8FCo9nxgIgiYmJJm1DRFReKUREnk/OrVmzBpGRkSi0mIjIJP379wcArF271sqRaBs+fDjWrl2L+/fvWzsUHRx/yVLKc7sn4yQkJODixYuIj4/XLMvOzsbEiRORkJCAhw8fwsnJCZcuXULjxo2xfPlyDBo0yIoRU2VQ0dtTfn4+QkNDMXjwYK3X/pYX5T0+ALh//z78/f0xa9YsxMTEADA+bt57zKu81SfHB8srTf8jKktsl1QcfeOZsRQKBRITExEREWGh6IiIyg5fU0lEVY4pk80TVRZs9xXXrVu3MGrUKJ3XVzk4OCAgIAA5OTma1+oEBQVhxowZmDFjhsFXWhIZoyK3p7y8PGzcuBHp6emIioqydjg6ynt8BaZNm4aWLVti1KhRAEyPm/ce8ypP9cnxwfJK2/+IygLbJRmj8HhGRFRVMRlHREREVI45OTnB3t4eX331FW7fvo2cnBykpKTgyy+/xNSpUxEVFQWVSqUpP2nSJPTv3x9RUVGaidIt6dy5czrzYun7q4xf0FSFcy/r9mQue/fuxfr167Fjxw44OztbOxwd5T0+AJg/fz6OHz+O7du3w97eHkDFiNscqkLfNgeOD5ZTlftfYeyP5VtVbZdkPH3jGRFRVcXXVBKRRZTH11R+8MEH+OSTT5CdnY06depg3rx5CA8Pt3ZYGhx/yRLKe7sn4+zfvx8zZszAr7/+isePH8PV1RVNmzbFwIED8e6778LOzk5nm127dmHPnj2YM2eOFSKmyobtqWrZtGkTzp49i/Hjx8PW1tbk7XnvMa/yXp8cH8yrtP2PiKi8MMd4xtdUElFlwmQcEVlEeUzGlXccf4mIiIiIiIiInmEyjogqE76mkoiIiIiIiIiIiIiIiMhCmIwjIiIiIiIiIiIiIiIishAm44iIiIiIiIiIiIiIiIgshMk4IiIiIiIiIiIiIiIiIguxK2pF//79yzIOIqpkDh48CIBjiSmSk5MBsM6IiIiIiIiIiIiIKhOFiMjzCw4cOID58+dbKx4iIiIiogrv2LFjAIBWrVpZORIiIiIioopr3Lhx6NChg7XDICIqNZ1kHBERERERlU5ERAQAYM2aNVaOhIiIiIiIiIisjXPGEREREREREREREREREVkIk3FEREREREREREREREREFsJkHBEREREREREREREREZGFMBlHREREREREREREREREZCFMxhERERERERERERERERFZCJNxRERERERERERERERERBbCZBwRERERERERERERERGRhTAZR0RERERERERERERERGQhTMYRERERERERERERERERWQiTcUREREREREREREREREQWwmQcERERERERERERERERkYUwGUdERERERERERERERERkIUzGEREREREREREREREREVkIk3FEREREREREREREREREFsJkHBEREREREREREREREZGFMBlHREREREREREREREREZCFMxhERERERERERERERERFZCJNxRERERERERERERERERBbCZBwRERERERERERERERGRhTAZR0RERERERERERERERGQhTMYRERERERERERERERERWQiTcUREREREREREREREREQWwmQcERERERERERERERERkYUwGUdERERERERERERERERkIUzGEREREREREREREREREVkIk3FEREREREREREREREREFsJkHBEREREREREREREREZGFMBlHREREREREREREREREZCFMxhERERERERERERERERFZCJNxRERERERERERERERERBbCZBwRERERERERERERERGRhTAZR0RERERERERERERERGQhdtYOgIiIiIioIsvMzMTTp0+1lmVnZwMAHj58qLXc0dERzs7OZRYbEREREREREVmfQkTE2kEQEREREVVUCQkJ+Mc//mFU2SVLliA6OtrCERERERERERFRecJkHBERERFRKdy9exd+fn7Iy8szWM7W1hY3b96Et7d3GUVGREREREREROUB54wjIiIiIioFb29vdOvWDba2tkWWsbW1xV//+lcm4oiIiIiIiIiqICbjiIiIiIhKadCgQTD0wgkRwaBBg8owIiIiIiIiIiIqL/iaSiIiIiKiUkpPT4e3tzeePn2qd72DgwPu3r0LlUpVxpERERERERERkbXxyTgiIiIiolJyc3NDr169YG9vr7POzs4Offr0YSKOiIiIiIiIqIpiMo6IiIiIyAwGDhyI3NxcneV5eXkYOHCgFSIiIiIiIiIiovKAr6kkIiIiIjKD7OxseHl5IT09XWu5q6sr7t27B0dHRytFRkRERERERETWxCfjiIiIiIjMwMHBAf3794eDg4Nmmb29PSIjI5mIIyIiIiIiIqrCmIwjIiIiIjKTAQMGIDs7W/PvnJwcDBgwwIoREREREREREZG18TWVRERERERmkp+fD19fX9y9excA4OXlhVu3bsHW1tbKkRERERERERGRtfDJOCIiIiIiM7GxscGAAQPg4OAAe3t7DBw4kIk4IiIiIiIioiqOyTgiIiIiIjN68803kZ2dzVdUEhEREREREREAwM7aARAREVHll5ycjF9++cXaYRCVCRFBtWrVAAB//PEHrl69at2AiMpISEgI/P39rR0GERERERFRucM544iIiMji1qxZg8jISGuHQUREFpSYmIiIiAhrh0FERERERFTu8Mk4IiIiKjP8DRCVREEytyK1n7NnzwIAmjRpYrUYFAoFkyNUZhQKhbVDICIiIiIiKreYjCMiIiIiMjNrJuGIiIiIiIiIqHyxsXYARERERERERERERERERJUVk3FEREREREREREREREREFsJkHBEREREREREREREREZGFMBlHREREREREREREREREZCFMxhERERERERERERERERFZCJNxRERERFQlbN++HWq1Glu2bLF2KOXe7t27MWnSJKxfvx6BgYFQKBRQKBT429/+plO2e/fucHNzg62tLZo2bYqjR49aIWLjzZo1S3M+z/81a9ZMb/n8/HzEx8cjJCRE7/oZM2agSZMmUKlUcHR0RFBQEMaPH4+MjIwSxRcaGqo3PoVCAVdXV62yOTk5mD17NoKCguDg4AB3d3c0a9YMV69e1Sr37bffol27dnBzc0Pt2rUxZMgQ3Lp1S7N+8+bNiIuLQ15eXoliJiIiIiIiIsOYjCMiIiKiKkFErB1ChfCvf/0LCxcuxAcffIB+/frhypUrqFevHqpVq4aVK1di27ZtWuV37dqFtWvXolevXjhz5gxat25tpcjN7+LFi3jppZcwbtw4ZGZm6i2zZ88ejBw5ElevXsW9e/cwe/ZsLFiwAP379zd7PJ06ddL6d2RkJL7++mt88803yMzMxO+//4569eppJQITExMxcOBA9O/fH8nJydi0aRP27duHV199Fbm5uQCA3r17Q6lUolu3bkhNTTV73ERERERERFUdk3FEREREVCX07NkTjx49Qq9evawdCrKysop80sqa5syZg9WrV2PNmjVwc3PTWrdw4ULY2Nhg2LBhePTokZUiNI8VK1ZARLT+Tp8+rVXmxIkTmDhxIkaMGIGWLVsWuS9XV1cMGzYMnp6ecHNzQ0REBMLCwrBz504kJSWZHJtSqURaWppOfMOGDcP48eM15VavXo2NGzdi7dq1+Mtf/gI7Ozv4+flh06ZNWk/5/fvf/0aNGjXw/vvvQ61Wo2XLlhg3bhyOHz+OQ4cOacqNHj0aLVq0wGuvvaZJ0hEREREREZF5MBlHRERERFTGvvrqK9y5c8faYWi5dOkSPvzwQ0yfPh1KpVJnfUhICMaMGYMbN27gvffes0KEZatFixZYv349Bg4cCEdHxyLLbd26Fba2tlrLvLy8AKDIp+kM2blzp04iNCkpCadPn0bXrl01yz777DO0bt0awcHBBveXlJQEPz8/KBQKzbJatWoBAK5du6ZVdtq0aTh+/DgWLFhgctxERERERERUNCbjiIiIiKjS++mnnxAQEACFQoHFixcDABISEuDi4gJnZ2ds2rQJr776KlQqFfz9/bFq1SrNtgsXLoRSqYSPjw+GDx8OPz8/KJVKhISEaD1ZNGrUKDg4OMDX11ez7B//+AdcXFygUChw7949AMCYMWMQExODy5cvQ6FQICgoCMCzJIxKpUJsbGxZVImOhQsXQkTQu3fvIsvMmjULDRo0wJdffondu3cb3J+IYP78+WjcuDEcHR3h4eGBN954A+fOndOUMfYaAEBeXh6mTp2KgIAAODk5oXnz5khMTCzdSVvIjRs34OTkhLp165plf3PmzMHo0aM1/87OzsbBgwcNPrFXIDAwUCfxWzBfXGBgoNZyDw8PdO7cGQsWLOBrXYmIiIiIiMyIyTgiIiIiqvQ6deqEX375RWtZdHQ0xo4di6ysLLi5uSExMRGXL19GYGAghg4dipycHADPkmyDBw9GZmYmRo8ejatXr+Lo0aPIzc3Fyy+/rHkV4cKFCxEREaF1jCVLlmD69OlayxYsWIBevXqhXr16EBFcunQJwLNkEwDk5+dbpA6Ks23bNjRs2BDOzs5FlnFycsL//d//wcbGBkOHDsXjx4+LLDtt2jRMmjQJkydPxp07d7Bv3z4kJSXhxRdfxO3btwEYfw0AYOLEiZg7dy7i4+Nx8+ZN9OrVCwMGDMCRI0dMPtdJkybBw8MDDg4OqFu3Lt544w0cPnzY5P3ok5mZiT179mDo0KFwcHAo9f5u3LiBvXv3ol+/fpplKSkpyM7Oxm+//YYuXbpoEsSNGzfGkiVLtBJpH3zwAW7duoVFixYhPT0dZ86cwYIFC9CjRw+0b99e53itWrXCjRs3cOLEiVLHTkRERERERM8wGUdEREREVV5ISAhUKhW8vb0RFRWFx48f4/r161pl7OzsNE95NWnSBAkJCUhPT8fy5cvNEkPPnj2RlpaGDz/80Cz7M8Xjx4/xxx9/oF69esWW7dChA8aOHYurV69i4sSJestkZWVh/vz56Nu3LwYNGgS1Wo3g4GB8/vnnuHfvHr744gudbQxdgydPniAhIQFhYWHo168f3N3dMWXKFNjb25tc/3//+9+xefNmJCUlISMjA6tWrcL169fRuXNnnDlzxqR96TN79mz4+flh1qxZpd4X8OypuH/+85+wsfnzv24ZGRkAAG9vb8TGxuLMmTO4ffs23njjDYwcORLffvutpmznzp0xYcIEjBo1CiqVCs2aNUN6ejq+/PJLvcerX78+AODUqVNmiZ+IiIiIiIiYjCMiIiIi0lLwNNPzT2Xp07ZtWzg7O2u9drGiunPnDkTE4FNxz5s1axYaNmyIJUuW4KefftJZf+bMGWRkZKBt27Zay9u1awcHBwet13vqU/ganD9/HpmZmWjWrJmmjJOTE3x9fU2u/1q1aqFVq1ZwdXWFg4MD2rdvj+XLlyMrKwtLliwxaV+FbdiwAWvWrMF3332nM+9bSaSkpGDz5s0YPHiw1vKCOeyaNm2KkJAQeHp6Qq1WY/r06VCr1VrJzsmTJ+OLL77A999/j4yMDFy5cgUhISHo0KGD5qnO5xW0gYKnF4mIiIiIiKj0mIwjIiIiIiohR0dH3L1719phlNqTJ08A/JnkKY5SqcTy5cuhUCjw1ltvISsrS2t9amoqAMDV1VVnW3d3d6Snp5sUX8HrMKdMmQKFQqH5u3btGjIzM03alz7BwcGwtbXFhQsXSryP1atXY86cOdi7dy/q1KlT6pgAIC4uDkOHDoVSqdRa7ufnBwCaeQgLODg4oHbt2rh8+TIA4ObNm4iLi8O7776Lrl27wsXFBXXr1sXSpUuRkpKCefPm6RzTyckJwJ9tgoiIiIiIiEqPyTgiIiIiohLIyclBamoq/P39rR1KqRUkYArmrTNGhw4dMG7cOFy8eBEzZ87UWufu7g4AepNuJakzb29vAEB8fDxEROvvwIEDJu1Ln/z8fOTn5xudjCxs0aJFWLlyJfbs2YMaNWqUOh4AuHXrFr799ltER0frrHN1dUX9+vVx9uxZnXW5ublQq9UAgIsXLyIvL08nJpVKBU9PT72v5czOzgbwZ5sgIiIiIiKi0mMyjoiIiIioBPbu3QsRQfv27TXL7Ozsin29ZXnk4+MDhUKBR48embTdzJkz0ahRIxw7dkxrebNmzeDq6oojR45oLT906BCys7PRpk0bk45Tq1YtKJVKHD9+3KTt9OnRo4fOssOHD0NE0KFDB5P2JSKYMGECTp06hY0bN+p9ErCk4uLiMGjQIHh6eupdHxkZiWPHjuHKlSuaZZmZmbh27RqCg4MBQJP0vHnzpta26enpePDgAWrVqqWz34I2UL16dbOcBxERERERETEZR0RERERklPz8fDx8+BC5ubk4efIkxowZg4CAAK35vIKCgvDgwQNs3LgROTk5uHv3Lq5du6azL09PT6SkpODq1atIT09HTk4OduzYAZVKhdjY2DI8q2ecnZ0RGBiI5ORkk7YreF2lra2tzvKYmBhs2LABK1euRFpaGk6dOoURI0bAz88Pw4YNM/k4Q4YMwapVq5CQkIC0tDTk5eUhOTlZk2iKiopC9erVcfToUYP7unHjBlavXo3U1FTk5OTgwIEDeOeddxAQEIARI0aYFNfZs2cxd+5cLF26FPb29lqv0FQoFPj44481ZY2ND3g2X9uyZcswduzYIsuMGzcOtWvXxuDBg3H9+nXcv38fEyZMQFZWFiZOnAgAqFu3Lrp06YKlS5di3759yMrKQlJSkqb+3377bZ39FrSBgoQeERERERERlR6TcURERERU6S1evBjt2rUDAEyYMAF9+vRBQkIC4uPjAQDNmzfHlStXsHTpUsTExAAAXnnlFVy8eFGzjydPniA4OBhOTk548cUX0aBBA/zwww9arzaMjo5Gly5d8Oabb6Jhw4aYOXOm5nV/HTp0QFJSEgBgxIgR8PHxQZMmTfDaa6/hwYMHZVIPhvTs2RNnzpzRmv/tv//9L4KCgnD58mW0a9cO//znP3W2a9++PcaNG6ez/F//+hdmz56NGTNmwMvLC507d0adOnWwd+9euLi4AIBJ12DBggUYO3Ys4uLiUK1aNfj5+WHMmDF4+PAhgGevV7xz5w42bdpk8DxfeeUVTJkyBf7+/nB2dkZERAQ6duyIgwcPolq1appyBw8eRKdOnVCjRg0cOnQIJ06cgJ+fHzp27Ih9+/YBePZknLGMjQ8A5s6di969eyMgIKDIMh4eHti/fz/8/f3RsmVL1KxZE7/++iu2bduGli1bAgAUCgXWrl2LqKgovP322/Dw8ECTJk1w/fp1rF+/Hi+++KLOfg8fPoyaNWuiefPmRp8bERERERERGaYQU/4HSURERFQCa9asQWRkpElfXBMVKA/tZ/jw4Vi7di3u379vtRhMpVAokJiYiIiICKPKX7p0CY0bN8by5csxaNAgC0dnfvn5+QgNDcXgwYPx1ltvWTscHeU9PgC4f/8+/P39MWvWLE1C1FimtjciIiIiIqKqhE/GEREREREZIS8vz9ohWFRQUBBmzJiBGTNmICMjw9rhmCQvLw8bN25Eeno6oqKirB2OjvIeX4Fp06ahZcuWGDVqlLVDISIiIiIiqlSYjCMiIqIK5+OPP4aPjw8UCgU+//xzix9v+/btUKvV2LJli9byp0+fYvTo0fD19YWzszN27txZZFlLWb9+PQIDA3XmqnJwcICPjw9CQ0Mxb948zav8iAyZNGkS+vfvj6ioKDx69Mja4Rht7969WL9+PXbs2AFnZ2drh6OjvMcHAPPnz8fx48exfft22NvbWzscIiIiIiKiSoXJOCIiIqpw3nvvPfzyyy9ldryiXo/4ySefYOfOnTh37hwWLFiAjIyMMn+VYr9+/XDlyhXUq1cParUaIoL8/HzcuXMHa9asQd26dTFhwgQ0bdoUR44cKdPYKosPPvgAy5cvx6NHj1C3bl2sW7fO2iFZVGxsLEaNGoWPPvrI2qEYrVu3bvjmm2/g6+tr7VD0Ku/xbdq0CU+fPsXevXvh4eFh7XCIiIiIiIgqHTtrB0BERERU3vXs2VPvU0IbN25E27Zt4e7ujnfffVez3NpPFCkUCri7uyM0NBShoaHo2bMnIiMj0bNnT1y4cAFqtdqq8VU0s2fPxuzZs60dRpnq3r07unfvbu0wqIz06dMHffr0sXYYRERERERElRafjCMiIiIqoeTk5ArxOrfw8HAMHjwYd+7cKZPXehIRERERERER0Z+YjCMiIqJya8WKFWjbti2USiVcXFxQp04dzJw5s8jy+/fvR5MmTaBWq6FUKhEcHIzvvvtOs/7HH3/ECy+8AGdnZ6hUKgQHByMtLc3gup9++gkBAQFQKBRYvHgxAOB///sfgoKCcPPmTfznP/+BQqGAq6ur3rIAkJeXh6lTpyIgIABOTk5o3rw5EhMTAQBz586Fs7Mz3NzccOfOHcTExKBmzZo4f/48du7cCZVKhdjY2FLX5eDBgwEAO3bsMCquhIQEuLi4wNnZGZs2bcKrr74KlUoFf39/rFq1SmvfhurV0DGIiIiIiIiIiKoCJuOIiIioXFqwYAH+3//7fwgPD0dKSgqSk5PxwQcf4Pz580Vuc/v2bURGRuLq1atISUmBq6srBg4cCAB4/PgxevfujfDwcDx48AAXL15EgwYNkJ2dbXBdp06ddOane/nll3Hp0iVUr14df//73yEiyMjI0FsWACZOnIi5c+ciPj4eN2/eRK9evTBgwAAcOXIE48ePx7hx45CRkYHZs2ejbt26aN++PUQEeXl5AID8/PxS12fLli0BAFeuXDEqrujoaIwdOxZZWVlwc3NDYmIiLl++jMDAQAwdOhQ5OTnF1mtxxyAiIiIiIiIiqgqYjCMiIqJyJycnB9OnT0eXLl0wceJEeHp6wsPDA2+//TbatWtX5Hbh4eH417/+BQ8PD3h6eqJ37964f/8+7t69i6tXryItLQ1NmzaFUqlE9erVsX79enh5eRlcV1pPnjxBQkICwsLC0K9fP7i7u2PKlCmwt7fH8uXLtcrOmTMHI0eOxPr169GoUSP07NkTaWlp+PDDD0sdh5ubGxQKBdLT002OKyQkBCqVCt7e3oiKisLjx49x/fp1ADBYd6Ycg4iIiIiIiIiosrKzdgBEREREhZ08eRKpqano0aOH1nJbW1uMHj3a6P0UzOeWl5eHwMBA+Pj4YNCgQRg9ejQGDx6MOnXqAIDBdaV1/vx5ZGZmolmzZpplTk5O8PX1xblz58xyDGM8fvwYIgKVSlWquBwcHABA82Scoboz97n379/f5G2quvj4eKxdu9baYRARERERERFVaXwyjoiIiMqdgvnG3N3dTdpu27ZtCA0Nhbe3NxwdHTF+/HjNOicnJ+zZswedOnVCbGwsAgMDERUVhaysLIPrSuvx48cAgClTpkChUGj+rl27hszMzFLv31gXLlwAADRq1MiscRmqu/Jy7kRERERERERE1sQn44iIiKjcqVGjBgDg3r17Rm9z/fp1hIWFoW/fvli2bBlq1KiBRYsWaSXkmjZtii1btuDu3buYP38+5syZg6ZNm+LDDz80uK40vL29ATx7QmnMmDGl2ldp7Ny5EwDw6quvmj2uououKirKbMcAwCe8TKRQKDB27FhERERYOxSqAhQKhbVDICIiIiIiKrf4ZBwRERGVO3Xq1IGnpyd27dpl9DanTp1CTk4OoqOjERgYCKVSqfXlcEpKCs6ePQvgWSLqo48+QuvWrXH27FmD60qrVq1aUCqVOH78eKn3VVK3bt1CfHw8/P398dZbb5k1LkN1Vx7OnYiIiIiIiIjI2piMIyIionLH0dERH3zwAfbt24dRo0bhxo0byM/PR3p6epEJsoCAAADA7t278eTJE1y8eBGHDh3SrE9JScHw4cNx7tw5ZGdn49ixY7h27Rrat29vcF1pKZVKDBkyBKtWrUJCQgLS0tKQl5eH5ORk3Lx50+C2O3bsgEqlQmxsrFHHEhFkZGQgPz8fIoK7d+8iMTERHTt2hK2tLTZu3KiZM640cT3PUN2Z6xhERERERERERBUZk3FERERULsXExGDx4sXYu3cvgoKC4OLigs6dO2Pv3r2YP38+OnXqBAB477330K9fPwQHB2PChAlYsmQJ/Pz8MHnyZISGhgIAOnXqhCdPniAvLw8hISFwdnbG66+/juHDh2PkyJHw9vYuct3ixYvRrl07AMCECRPQp08fXLt2DRG3T90AAA0cSURBVK1bt8bt27fxzTffoE2bNli/fr3esgCwYMECjB07FnFxcahWrRr8/PwwZswYPHz4EHPnzsX8+fMBAA0aNMDKlStNqqctW7agRYsWuHnzJp48eQK1Wg1bW1vY2tqiQYMGmD9/PgYPHowzZ86gTZs2WtsaiishIQHx8fEAgObNm+PKlStYunQpYmJiAACvvPIKLl68aLDuijsGEREREREREVFVoBARsXYQREREVLmtWbMGkZGR4McOKgm2n5JRKBRITEzknHFUJtjeiIiIiIiIisYn44iIiIiIiIiIiIiI/n979x9TZfnGcfxzROGAQCL+wpCJkqSBP0o3wIyay0yHP3IClS1yMcUKUVuBaSICqWvCaLCWNdqiKZgmLtOaI+Za6nCEGa0CDAVyISoIgolwvn84qPMF9Rw5x1P0fm3nn/u5n+u6nnOff+DafT8AYCc04wAAAADclSNHjigpKUl79+7VuHHjZDAYZDAY9MILL/SYO2fOHHl4eMjJyUkPPfSQSktLHVCx5VJTU7uf5++foKCgXud3dnYqIyNDYWFhvV5PSUnRpEmT5OnpKRcXFwUEBOiNN95QS0tLn+q8Xd4DBw5o27Zt6ujo6FMOAAAAAEDf0IwDAAAAYLVNmzYpKytL69ev15IlS3TmzBmNHz9e3t7eysvL08GDB83mf/3119qzZ48iIiJUXl6uhx9+2EGV215FRYUee+wxrV27Vq2trb3OKSoq0quvvqrq6mo1NDQoPT1dmZmZWrp0qd3yLliwQEajUbNnz1ZjY+Nd5wEAAAAA9A3NOAAAAOAO2trabrnj6d+Uw1a2bt2q3bt3q6CgQB4eHmbXsrKyNGDAAK1YsUJNTU0OqtA2PvnkE5lMJrPPjz/+aDbn1KlTSkxMVFxcnKZOnXrLWO7u7lqxYoWGDh0qDw8PRUZGavHixTp8+LBqamqsrs3SvKtXr9aUKVM0b9483bhxw+o8AAAAAIC+oxkHAAAA3MFHH32k+vr6f30OW6isrNTGjRu1efNmGY3GHtfDwsKUkJCguro6vf766w6o8N6aMmWK9u7dq+eff14uLi63nPfFF1/IycnJbGzYsGGSdMvddLbIK0nJyckqKytTZmam1XkAAAAAAH1HMw4AAAD9jslk0o4dOzRx4kS5uLjIy8tLixYt0s8//9w9Jz4+Xs7Ozho1alT32CuvvKLBgwfLYDCooaFBkpSQkKB169apqqpKBoNBAQEBysrKktFo1IgRI7Ry5Ur5+PjIaDQqLCxMJ06csEkOSTp8+LA8PT2VlpZm1+/LGllZWTKZTFqwYMEt56SmpmrChAn68MMPdeTIkdvGs2StcnJyNHjwYLm5uamwsFBPP/20PD095evrq127dpnF6+jo0Ntvvy0/Pz+5urpq8uTJys/P79tD20ldXZ1cXV3l7+9v1zxeXl4KDw9XZmamTCaTXXMBAAAAAHqiGQcAAIB+Jzk5WUlJSXrrrbdUX1+vo0ePqqamRrNmzdIff/wh6WZTKTIy0uy+7Oxsbd682WwsMzNTERERGj9+vEwmkyorKxUfH6+YmBi1trZq9erVqq6uVmlpqW7cuKEnn3yy+9jBvuSQbjaWJKmzs9N2X04fHTx4UIGBgXJzc7vlHFdXV3388ccaMGCAYmNjdfXq1VvOtWStVq1apTVr1qitrU0eHh7Kz89XVVWVxo0bp9jYWLW3t3fHS0xM1Pbt25WRkaHz588rIiJCzz33nE6ePGn1syYlJcnLy0vOzs7y9/fXokWLVFJSYnWc3rS2tqqoqEixsbFydna2SczbmTZtmurq6nTq1Cm75wIAAAAAmKMZBwAAgH6lra1NO3bs0DPPPKNly5bpvvvuU3BwsN5//301NDTogw8+sFmugQMHdu/omjRpknJyctTc3Kzc3FybxJ8/f76uXLmijRs32iReX129elW//fabxo8ff8e5oaGhWrNmjaqrq5WYmNjrnLtZq7CwMHl6emr48OGKjo7W1atXde7cOUnStWvXlJOTo8WLF2vJkiUaMmSINmzYoEGDBlm9Ji+++KIOHDigmpoatbS0aNeuXTp37pzCw8NVXl5uVazepKeny8fHR6mpqX2OZYkHHnhAknT69Ol7kg8AAAAA8BeacQAAAOhXysvL1dLSounTp5uNz5gxQ87OzmbHSNra9OnT5ebmZnbEYn9SX18vk8l0211xf5eamqrAwEBlZ2fr22+/7XG9r2vVtaOsa2fcL7/8otbWVgUFBXXPcXV11ahRo6xekzFjxmjatGlyd3eXs7OzQkJClJubq7a2NmVnZ1sV6//t27dPBQUF+uqrr+Th4dGnWJbqWrOu3YYAAAAAgHuHZhwAAAD6lcbGRkmSu7t7j2tDhgxRc3OzXfO7uLjowoULds3hKNeuXZN08xktYTQalZubK4PBoOXLl6utrc3suq3Xqus4zA0bNshgMHR/zp49q9bWVqti9SY4OFhOTk769ddf7zrG7t27tXXrVhUXF2vs2LF9rslSrq6ukv5aQwAAAADAvUMzDgAAAP3KkCFDJKnXRk5jY6N8fX3tlru9vd3uORypq6HT9S47S4SGhmrt2rWqqKjQli1bzK7Zeq2GDx8uScrIyJDJZDL7HDt2zKpYvens7FRnZ6fFzcj/99577ykvL09FRUUaPXp0n+uxxvXr1yX9tYYAAAAAgHuHZhwAAAD6laCgILm7u+vkyZNm4ydOnND169f1yCOPdI8NHDiw+4hDWyguLpbJZFJISIjdcjjSiBEjZDAY1NTUZNV9W7Zs0YMPPqjvv//ebNyatbLEmDFjZDQaVVZWZtV9vXnqqad6jJWUlMhkMik0NNSqWCaTSW+++aZOnz6t/fv397oT0N661mzkyJH3PDcAAAAA/NfRjAMAAEC/YjQatW7dOu3bt095eXm6cuWKTp8+rbi4OPn4+GjFihXdcwMCAnTp0iXt379f7e3tunDhgs6ePdsj5tChQ/X777+rurpazc3N3c21zs5OXb58WTdu3NAPP/yghIQE+fn5KSYmxiY5Dh06JE9PT6Wlpdn+i7oLbm5uGjdunGpra626r+u4Sicnpx7jlq6VpXleeukl7dq1Szk5Obpy5Yo6OjpUW1ur8+fPS5Kio6M1cuRIlZaW3jZWXV2ddu/ercbGRrW3t+vYsWN6+eWX5efnp7i4OKvq+umnn7R9+3bt3LlTgwYNMjtC02Aw6N133+2ea2l91upas+DgYJvGBQAAAADcGc04AAAA9DubNm1Senq6UlJSNGzYMIWHh2vs2LEqLi7W4MGDu+etWrVKTzzxhJ599lkFBgZqy5Yt3cf4hYaGqqamRpIUFxenESNGaNKkSZo3b54uXbok6eb7t4KDg+Xq6qpZs2ZpwoQJ+uabb8yOMexrjn+a+fPnq7y83Oz9b59//rkCAgJUVVWlGTNm6LXXXutxX0hIiNauXdtj3JK1ysnJUUZGhiRp8uTJOnPmjHbu3Kl169ZJkubOnauKigpJUmZmptasWaNt27bJ29tbPj4+SkhI0OXLlyXdPK6xvr5ehYWFt33OuXPnasOGDfL19ZWbm5siIyM1c+ZMHT9+XN7e3t3zjh8/rkcffVSjR4/WiRMndOrUKfn4+GjmzJk6evSopJs74yxlaX2W5P27kpIS3X///Zo8ebLFtQAAAAAAbMNgsuYvQwAAgLtQUFCgqKgoq/4hDXT5p/5+Vq5cqT179ujixYuOLqVXBoNB+fn5ioyMtGncyspKTZw4Ubm5uVq2bJlNY98LnZ2devzxxxUTE6Ply5c7upwe7FHfxYsX5evrq9TU1O4Gpq3Z6/cGAAAAAP0BO+MAAACAu9TR0eHoEu65gIAApaSkKCUlRS0tLY4uxyodHR3av3+/mpubFR0d7ehyerBXfcnJyZo6dari4+NtFhMAAAAAYDmacQAAAACskpSUpKVLlyo6OlpNTU2OLsdixcXF2rt3rw4dOiQ3NzdHl9ODPerbsWOHysrK9OWXX2rQoEE2iQkAAAAAsA7NOAAAAMBK69evV25urpqamuTv76/PPvvM0SXdc2lpaYqPj9c777zj6FIsNnv2bH366acaNWqUo0vpla3rKyws1J9//qni4mJ5eXnZJCYAAAAAwHoDHV0AAAAA8G+Tnp6u9PR0R5fhcHPmzNGcOXMcXQZuYeHChVq4cKGjywAAAACA/zx2xgEAAAAAAAAAAAB2QjMOAAAAAAAAAAAAsBOacQAAAAAAAAAAAICd0IwDAAAAAAAAAAAA7IRmHAAAAAAAAAAAAGAnAx1dAAAA+O8wGAyOLgH/Yvx+rBcVFaWoqChHlwEAAAAAwH+awWQymRxdBAAA6N9qa2v13XffOboMAIAdhYWFydfX19FlAAAAAMA/Ds04AAAAAAAAAAAAwE54ZxwAAAAAAAAAAABgJzTjAAAAAAAAAAAAADuhGQcAAAAAAAAAAADYyUBJexxdBAAAAAAAAAAAANAf/Q8ixcnBeIvQbQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLGUF1CIFHIA"
      },
      "source": [
        "def compute_loss(labels, logits):\r\n",
        "  \r\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\r\n",
        "  \r\n",
        "  start_logits = logits[:, :, 0]\r\n",
        "  end_logits = logits[:, :, 1]\r\n",
        "\r\n",
        "  start_pred = np.argmax(start_logits, axis=1)\r\n",
        "  end_pred = np.argmax(end_logits, axis=1)\r\n",
        "\r\n",
        "  start_labels = labels[0, :, 0]\r\n",
        "  end_labels = labels[0, :, 1]\r\n",
        "\r\n",
        "  start_loss = loss_fn(start_labels, start_logits)\r\n",
        "  end_loss = loss_fn(end_labels, end_logits)\r\n",
        "\r\n",
        "  return start_loss + end_loss"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PDyisc6I5rw",
        "outputId": "5ab95890-99ac-4fc4-9453-9baac4ff47af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "compute_loss(labels = [[150, 152],[147, 148]],\r\n",
        "             logits = [[127.0, 152.3], [147.0, 148.0]])"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 17630, 2)\n",
            "(17630,)\n",
            "(1000, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-de4c73e44368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_starts_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ends_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-152-5404327f85a1>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(labels, logits)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mstart_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mend_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    154\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    254\u001b[0m           y_pred, y_true)\n\u001b[1;32m    255\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, axis)\u001b[0m\n\u001b[1;32m   1567\u001b[0m   \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m   return K.sparse_categorical_crossentropy(\n\u001b[0;32m-> 1569\u001b[0;31m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[0m\u001b[1;32m   1570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4942\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4943\u001b[0m     res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n\u001b[0;32m-> 4944\u001b[0;31m         labels=target, logits=output)\n\u001b[0m\u001b[1;32m   4945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4946\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mupdate_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_rank\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m   4239\u001b[0m   \"\"\"\n\u001b[1;32m   4240\u001b[0m   return sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 4241\u001b[0;31m       labels=labels, logits=logits, name=name)\n\u001b[0m\u001b[1;32m   4242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   4154\u001b[0m                        \u001b[0;34m\"should equal the shape of logits except for the last \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m                        \"dimension (received %s).\" % (labels_static_shape,\n\u001b[0;32m-> 4156\u001b[0;31m                                                      logits.get_shape()))\n\u001b[0m\u001b[1;32m   4157\u001b[0m     \u001b[0;31m# Check if no reshapes are required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape mismatch: The shape of labels (received (17630,)) should equal the shape of logits except for the last dimension (received (1000, 512))."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsv_uILTwmFR"
      },
      "source": [
        "# Define model parameters\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\r\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "# loss = compute_loss\r\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\r\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfUxCHLSusuV"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "69cHTOSZGuyG",
        "outputId": "1c1dff62-07ca-4814-e6c0-f867f6bc8e3b"
      },
      "source": [
        "# Fit model with train set\r\n",
        "model_fit = model.fit(x = [train_inputs['input_ids'],\r\n",
        "                           train_inputs['attention_mask'],\r\n",
        "                           train_inputs['token_type_ids']],\r\n",
        "                      # y = np.transpose(np.array(list(zip(train_starts_cat, train_ends_cat))), axes = (0, 2, 1)),\r\n",
        "                      # y = np.dstack((train_starts_ids, train_ends_ids))[0],\r\n",
        "                      y = np.array(train_starts_ids, dtype=np.float32),\r\n",
        "                       \r\n",
        "                      batch_size=BATCH_SIZE, epochs=EPOCHS, \r\n",
        "                      \r\n",
        "                      validation_data=([val_inputs['input_ids'],\r\n",
        "                                        val_inputs['attention_mask'],\r\n",
        "                                        val_inputs['token_type_ids']], \r\n",
        "                                        # np.transpose(np.array(list(zip(val_starts_cat, val_ends_cat))), axes = (0, 2, 1))\r\n",
        "                                        # np.dstack((val_starts_ids, val_ends_ids))[0]\r\n",
        "                                       np.array(val_starts_ids, dtype=np.float32)\r\n",
        "                                       )\r\n",
        "                      )"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "  38/1563 [..............................] - ETA: 41:22 - loss: 6.1914 - accuracy: 0.0098"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-4aef1ba550a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                                         \u001b[0;31m# np.transpose(np.array(list(zip(val_starts_cat, val_ends_cat))), axes = (0, 2, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                         \u001b[0;31m# np.dstack((val_starts_ids, val_ends_ids))[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                        \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_starts_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                                        )\n\u001b[1;32m     18\u001b[0m                       )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBZuBfspH47n"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB8A1y-iaK_w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "70590662-745c-4392-98bf-4f5961ca9c3f"
      },
      "source": [
        "# Predict test set\r\n",
        "pred = model.predict([test_inputs[\"input_ids\"][:TEST_LIMIT], \r\n",
        "                      test_inputs[\"attention_mask\"][:TEST_LIMIT], \r\n",
        "                      test_inputs[\"token_type_ids\"][:TEST_LIMIT]])\r\n",
        "\r\n",
        "pred_start_ids = np.argmax(pred, axis= 1)[:, 0]\r\n",
        "pred_end_ids = np.argmax(pred, axis= 1)[:, 1]\r\n",
        "\r\n",
        "print(\"test start accuracy:\", sklearn.metrics.accuracy_score(test_starts_ids[:TEST_LIMIT], pred_start_ids))\r\n",
        "print(\"test end accuracy:\", sklearn.metrics.accuracy_score(test_ends_ids[:TEST_LIMIT], pred_end_ids))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-e02d898384e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m print(\"test accuracy:\", sklearn.metrics.accuracy_score(\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_starts_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTEST_LIMIT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ends_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTEST_LIMIT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m ))\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test start accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_starts_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTEST_LIMIT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_start_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \"\"\"\n\u001b[0;32m--> 653\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transpose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: axes don't match array"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReaGmFCEu0bX"
      },
      "source": [
        "# Predict val set\r\n",
        "pred = model.predict([val_inputs[\"input_ids\"][:VAL_LIMIT], \r\n",
        "                      val_inputs[\"attention_mask\"][:VAL_LIMIT], \r\n",
        "                      val_inputs[\"token_type_ids\"][:VAL_LIMIT]])\r\n",
        "\r\n",
        "pred_start_ids = np.argmax(pred, axis= 1)[:, 0]\r\n",
        "pred_end_ids = np.argmax(pred, axis= 1)[:, 1]\r\n",
        "\r\n",
        "print(\"validation start accuracy:\", sklearn.metrics.accuracy_score(val_starts_ids[:VAL_LIMIT], pred_start_ids))\r\n",
        "print(\"validation end accuracy:\", sklearn.metrics.accuracy_score(val_ends_ids[:VAL_LIMIT], pred_end_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFDBM_-rPuX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad0b1ea-82e4-4c25-8b4b-167be8736853"
      },
      "source": [
        "def get_text_from_token_ids(context, start_id, end_id):\r\n",
        "  return tokenizer.decode(context[start_id:end_id])\r\n",
        "\r\n",
        "boom_baby = 0\r\n",
        "for i, row in test_df.iterrows():\r\n",
        "  if i == TEST_LIMIT: break\r\n",
        "  true_answer = row[\"answer_text\"]\r\n",
        "  predicted_answer = get_text_from_token_ids(test_inputs[\"input_ids\"][i], start_pred_ids[i], end_pred_ids[i])\r\n",
        "\r\n",
        "  if true_answer == predicted_answer:\r\n",
        "    boom_baby += 1\r\n",
        "\r\n",
        "  if i % 100 == 0:\r\n",
        "    print(\"\\n\\nQuestion: \\n\", row[\"question_text\"])\r\n",
        "    print(\"Context: \\n\", test_context_dict[row[\"context_id\"]])\r\n",
        "    # print(\"Answer text: \\n\", true_answer)\r\n",
        "    print(f\"Our answer: \\n\\tids {(start_pred_ids[i], end_pred_ids[i])}\\n\\ttext: {predicted_answer}\")\r\n",
        "    print(f\"True answer: \\n\\tids {(test_starts_ids[i], test_ends_ids[i])}\\n\\ttext: {row['answer_text']}\")\r\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Question: \n",
            " What is the Latin for Order of Preachers?\n",
            "Context: \n",
            " The Order of Preachers (Latin: Ordo Praedicatorum, hence the abbreviation OP used by members), more commonly known after the 15th century as the Dominican Order or Dominicans, is a Roman Catholic religious order founded by the Spanish priest Saint Dominic de Guzman in France and approved by Pope Honorius III (1216–27) on 22 December 1216. Membership in this \"mendicant\" order includes friars, nuns, active sisters, and lay or secular Dominicans (formerly known as tertiaries, though recently there has been a growing number of Associates, who are unrelated to the tertiaries) affiliated with the order.\n",
            "Our answer: \n",
            "\tids (280, 432)\n",
            "\ttext: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [CLS] what is the latin for order of preachers? [SEP] the order of preachers ( latin : ordo praedicatorum, hence the abbreviation op used by members ), more commonly known after the 15th century as the dominican order or dominicans, is a roman catholic religious order founded by the spanish priest saint dominic\n",
            "True answer: \n",
            "\tids (387, 393)\n",
            "\ttext: Ordo Praedicatorum\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question: \n",
            " What did Dominic greatly struggle with?\n",
            "Context: \n",
            " Dominic's search for a close relationship with God was determined and unceasing. He rarely spoke, so little of his interior life is known. What is known about it comes from accounts written by people near to him. St. Cecilia remembered him as cheerful, charitable and full of unceasing vigor. From a number of accounts, singing was apparently one of Dominic's great delights. Dominic practiced self-scourging and would mortify himself as he prayed alone in the chapel at night for 'poor sinners.' He owned a single habit, refused to carry money, and would allow no one to serve him.\n",
            "Our answer: \n",
            "\tids (296, 313)\n",
            "\ttext: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "True answer: \n",
            "\tids (390, 392)\n",
            "\ttext: relationship with God\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question: \n",
            " What did the English Dominicans like to concentrate on?\n",
            "Context: \n",
            " Concerning humanity as the image of Christ, English Dominican spirituality concentrated on the moral implications of image-bearing rather than the philosophical foundations of the imago Dei. The process of Christ's life, and the process of image-bearing, amends humanity to God's image. The idea of the \"image of God\" demonstrates both the ability of man to move toward God (as partakers in Christ's redeeming sacrifice), and that, on some level, man is always an image of God. As their love and knowledge of God grows and is sanctified by faith and experience, the image of God within man becomes ever more bright and clear.\n",
            "Our answer: \n",
            "\tids (392, 506)\n",
            "\ttext: image - bearing rather than the philosophical foundations of the imago dei. the process of christ's life, and the process of image - bearing, amends humanity to god's image. the idea of the \" image of god \" demonstrates both the ability of man to move toward god ( as partakers in christ's redeeming sacrifice ), and that, on some level, man is always an image of god. as their love and knowledge of god grows and is sanctified by faith and experience, the image of god within man becomes ever\n",
            "True answer: \n",
            "\tids (389, 394)\n",
            "\ttext: moral implications of image-bearing\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question: \n",
            " Who designated BYU as having high research activity?\n",
            "Context: \n",
            " For 2016, U.S. News & World Report ranked BYU as tied for 66th for national universities in the United States. A 2013 Quarterly Journal of Economics study of where the nation's top high school students choose to enroll ranked BYU No. 21 in its peer-reviewed study. The Princeton Review has ranked BYU the best value for college in 2007, and its library is consistently ranked in the nation's top ten — No. 1 in 2004 and No. 4 in 2007. BYU is also ranked No. 19 in the U.S. News and World Report's \"Great Schools, Great Prices\" lineup, and No. 12 in lowest student-incurred debt. Due in part to the school's emphasis on undergraduate research, in rankings for 2008-2009, BYU was ranked No. 10 nationally for the number of students who go on to earn PhDs, No. 1 nationally for students who go on to dental school, No. 6 nationally for students who go on to law school, and No. 10 nationally for students who go on to medical school. BYU is designated as a research university with high research activity by the Carnegie Foundation for the Advancement of Teaching.]] Forbes Magazine ranked it as the No. 1 \"Top University to Work For in 2014\" and as the best college in Utah.\n",
            "Our answer: \n",
            "\tids (222, 392)\n",
            "\ttext: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [CLS] who designated byu as having high research activity? [SEP] for 2016, u. s. news & world report ranked byu as tied for 66th for national universities in the united states. a 2013 quarterly journal of economics study of where the nation's top high school students choose to enroll ranked byu no. 21 in its peer - reviewed study. the princeton review has ranked byu the best value for college in 2007, and its library is consistently ranked in the nation's top ten — no. 1 in 2004 and no. 4 in 2007. byu is also ranked no. 19 in the u. s. news and world report's \" great schools, great prices \" lineup, and no. 12 in lowest student - incurred debt. due in part to the school's emphasis on\n",
            "True answer: \n",
            "\tids (475, 481)\n",
            "\ttext: Carnegie Foundation for the Advancement of Teaching\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question: \n",
            " What percentage of BYU's class of 2005 were married?\n",
            "Context: \n",
            " One of the characteristics of BYU most often pointed out is its reputation for emphasizing a \"marriage culture\". Members of The Church of Jesus Christ of Latter-day Saints highly value marriage and family, especially marriage within the faith. Approximately 51 percent of the graduates in BYU's class of 2005 were married. This is compared to a national marriage average among college graduates of 11 percent. BYU students on average marry at the age of 22, according to a 2005 study, while the national average age is 25 years for men and 27 years for women.\n",
            "Our answer: \n",
            "\tids (440, 155)\n",
            "\ttext: \n",
            "True answer: \n",
            "\tids (447, 448)\n",
            "\ttext: Approximately 51\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question: \n",
            " Serbo-Croatian is the only Slavic language to use what two scripts together?\n",
            "Context: \n",
            " The Croatian Latin alphabet (Gajica) followed suit shortly afterwards, when Ljudevit Gaj defined it as standard Latin with five extra letters that had diacritics, apparently borrowing much from Czech, but also from Polish, and inventing the unique digraphs \"lj\", \"nj\" and \"dž\". These digraphs are represented as \"ļ, ń and ǵ\" respectively in the \"Rječnik hrvatskog ili srpskog jezika\", published by the former Yugoslav Academy of Sciences and Arts in Zagreb. The latter digraphs, however, are unused in the literary standard of the language. All in all, this makes Serbo-Croatian the only Slavic language to officially use both the Latin and Cyrillic scripts, albeit the Latin version is more commonly used.\n",
            "Our answer: \n",
            "\tids (392, 320)\n",
            "\ttext: \n",
            "True answer: \n",
            "\tids (497, 499)\n",
            "\ttext: Latin and Cyrillic\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question: \n",
            " What did the monastery help fuel?\n",
            "Context: \n",
            " The proximity of the Palace of Westminster did not extend to providing monks or abbots with high royal connections; in social origin the Benedictines of Westminster were as modest as most of the order. The abbot remained Lord of the Manor of Westminster as a town of two to three thousand persons grew around it: as a consumer and employer on a grand scale the monastery helped fuel the town economy, and relations with the town remained unusually cordial, but no enfranchising charter was issued during the Middle Ages. The abbey built shops and dwellings on the west side, encroaching upon the sanctuary.[citation needed]\n",
            "Our answer: \n",
            "\tids (501, 431)\n",
            "\ttext: \n",
            "True answer: \n",
            "\tids (460, 462)\n",
            "\ttext: the town economy\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question: \n",
            " What was included in the new organ from the previous Hill organ of 1848?\n",
            "Context: \n",
            " The organ was built by Harrison & Harrison in 1937, then with four manuals and 84 speaking stops, and was used for the first time at the coronation of King George VI. Some pipework from the previous Hill organ of 1848 was revoiced and incorporated in the new scheme. The two organ cases, designed in the late 19th century by John Loughborough Pearson, were re-instated and coloured in 1959.\n",
            "Our answer: \n",
            "\tids (198, 360)\n",
            "\ttext: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "True answer: \n",
            "\tids (464, 465)\n",
            "\ttext: pipework\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question: \n",
            " What was the earliest divergence within the Neognathes?\n",
            "Context: \n",
            " The earliest divergence within the Neognathes was that of the Galloanserae, the superorder containing the Anseriformes (ducks, geese, swans and screamers) and the Galliformes (the pheasants, grouse, and their allies, together with the mound builders and the guans and their allies). The earliest fossil remains of true birds come from the possible galliform Austinornis lentus, dated to about 85 million years ago, but the dates for the actual splits are much debated by scientists. The Aves are agreed to have evolved in the Cretaceous, and the split between the Galloanseri from other Neognathes occurred before the Cretaceous–Paleogene extinction event, but there are different opinions about whether the radiation of the remaining Neognathes occurred before or after the extinction of the other dinosaurs. This disagreement is in part caused by a divergence in the evidence; molecular dating suggests a Cretaceous radiation, while fossil evidence supports a Cenozoic radiation. Attempts to reconcile the molecular and fossil evidence have proved controversial, but recent results show that all the extant groups of birds originated from only a small handful of species that survived the Cretaceous–Paleogene extinction.\n",
            "Our answer: \n",
            "\tids (5, 178)\n",
            "\ttext: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "True answer: \n",
            "\tids (278, 281)\n",
            "\ttext: Galloanserae\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question: \n",
            " What is a cost of flocking?\n",
            "Context: \n",
            " While some birds are essentially territorial or live in small family groups, other birds may form large flocks. The principal benefits of flocking are safety in numbers and increased foraging efficiency. Defence against predators is particularly important in closed habitats like forests, where ambush predation is common and multiple eyes can provide a valuable early warning system. This has led to the development of many mixed-species feeding flocks, which are usually composed of small numbers of many species; these flocks provide safety in numbers but increase potential competition for resources. Costs of flocking include bullying of socially subordinate birds by more dominant birds and the reduction of feeding efficiency in certain cases.\n",
            "Our answer: \n",
            "\tids (438, 463)\n",
            "\ttext: eyes can provide a valuable early warning system. this has led to the development of many mixed - species feeding flocks, which\n",
            "True answer: \n",
            "\tids (492, 500)\n",
            "\ttext: bullying of socially subordinate birds by more dominant birds\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzMIwH85RATH"
      },
      "source": [
        "print(f\"Total matches\\t{boom_baby} / {TEST_LIMIT} \\t({round(boom_baby / TEST_LIMIT, 3)*100} %)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRdxAI9ug1kE"
      },
      "source": [
        "with open(\"results_2101_start_pred.txt\", \"w\") as f:\r\n",
        "  f.write(start_pred)\r\n",
        "\r\n",
        "with open(\"results_2101_end_pred.txt\", \"w\") as f:\r\n",
        "  f.write(end_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}