{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project-X-SQAD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4cd76f42e740423a8aa9b3ca53c01245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d635a85e72f54c3f95869fcd0b585a71",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a368e4d25ea44755bee4854ce5db6a8c",
              "IPY_MODEL_60b98c33cab84804a429455de0b1efeb"
            ]
          }
        },
        "d635a85e72f54c3f95869fcd0b585a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a368e4d25ea44755bee4854ce5db6a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_763bc5240ad1438e95b159a65a80726e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_511903d5a7224ff690027089bd613466"
          }
        },
        "60b98c33cab84804a429455de0b1efeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8bbb8069719a44c18747e39e38c3395c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.13MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3518db05415641aea3036d9a0d18ff8d"
          }
        },
        "763bc5240ad1438e95b159a65a80726e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "511903d5a7224ff690027089bd613466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bbb8069719a44c18747e39e38c3395c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3518db05415641aea3036d9a0d18ff8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "905c8315acb842168afc8522d30689f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9d7dc7cb46f45b79f93b18b5f6df11c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_688fc3d034f64ca2bb5e24ca507ee100",
              "IPY_MODEL_21690099fb2846c58469b152c34b0367"
            ]
          }
        },
        "b9d7dc7cb46f45b79f93b18b5f6df11c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "688fc3d034f64ca2bb5e24ca507ee100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2548b6ba9a6c4942849c02d647d671bb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42f7146e656f422a8e6961f5325fbe2a"
          }
        },
        "21690099fb2846c58469b152c34b0367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c5fd3df50b6b46f094e7c4832bd41352",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 53.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d775dd441d0437e86a0e6348b5264dc"
          }
        },
        "2548b6ba9a6c4942849c02d647d671bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42f7146e656f422a8e6961f5325fbe2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5fd3df50b6b46f094e7c4832bd41352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d775dd441d0437e86a0e6348b5264dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae99f967d1af4afeb65afb34d9c45e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e916e523cc3c484a95a19954d5b9df4a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc3d7b1208a2496ba06edbb9cf681b6e",
              "IPY_MODEL_d73b2eac3ecc48709f3b4150e3b455c5"
            ]
          }
        },
        "e916e523cc3c484a95a19954d5b9df4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc3d7b1208a2496ba06edbb9cf681b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8615f0855ac14c33b1b899474799c95c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_126a0bfb70284c91ac661865627d06e6"
          }
        },
        "d73b2eac3ecc48709f3b4150e3b455c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6397c2dd5f2c4989858626463950823b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:07&lt;00:00, 67.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fa74a717a6344a2b5db62bff77f7b11"
          }
        },
        "8615f0855ac14c33b1b899474799c95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "126a0bfb70284c91ac661865627d06e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6397c2dd5f2c4989858626463950823b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fa74a717a6344a2b5db62bff77f7b11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6J9_LsBSwk-"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwEFNn5KuGDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f616ca-808b-4d69-dab8-e4b07a510079"
      },
      "source": [
        "!pip install -q tf-models-official==2.3.0\r\n",
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 849kB 17.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 23.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 85kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 49.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 56.5MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 18.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 55.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c5dd23c0fdca072f8c5bfed34e12d5da3a425f0d39a633238088006f0d2e2fc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxC2Vn2KR8pK"
      },
      "source": [
        "import os\r\n",
        "import json\r\n",
        "\r\n",
        "import re\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85YO229Wu0iJ"
      },
      "source": [
        "This directory contains the configuration, vocabulary, and a pre-trained checkpoint used in this tutorial:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A23pEgzInJLM"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwEW25ifc3Pt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5b176e-b5b5-40b4-f8d6-d4e30d614847"
      },
      "source": [
        "# import sys\r\n",
        "# !git clone \"https://github.com/giuliofortini/NLP_SQuAD_Project\"\r\n",
        "# sys.path.append(\"NLP_SQuAD_Project/\")\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "try:\r\n",
        "  with open('training_set.json') as f:\r\n",
        "    json_data = json.load(f)\r\n",
        "except:\r\n",
        "  from google.colab import drive\r\n",
        "  drive.mount('/content/drive')\r\n",
        "  with open('/content/drive/My Drive/SQUAD/training_set.json') as f:\r\n",
        "    json_data = json.load(f)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o1FPMIyWWgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "76000efb-7a07-4ec3-dc38-cc0e3a733c5d"
      },
      "source": [
        "data = pd.json_normalize(json_data['data'])\r\n",
        "data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraphs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[{'context': 'Architecturally, the school has ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[{'context': 'Beyoncé Giselle Knowles-Carter (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Montana</td>\n",
              "      <td>[{'context': 'Montana i/mɒnˈtænə/ is a state i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Genocide</td>\n",
              "      <td>[{'context': 'The phrase \"in whole or in part\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Antibiotics</td>\n",
              "      <td>[{'context': 'The emergence of resistance of b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>Police</td>\n",
              "      <td>[{'context': 'A police force is a constituted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>Punjab,_Pakistan</td>\n",
              "      <td>[{'context': 'Punjab (Urdu, Punjabi: پنجاب, pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>Infection</td>\n",
              "      <td>[{'context': ' Among the vast varieties of mic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>Hunting</td>\n",
              "      <td>[{'context': 'Hunting is the practice of killi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>[{'context': 'Kathmandu(/ˌkɑːtmɑːnˈduː/; Nepal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        title                                         paragraphs\n",
              "0    University_of_Notre_Dame  [{'context': 'Architecturally, the school has ...\n",
              "1                     Beyoncé  [{'context': 'Beyoncé Giselle Knowles-Carter (...\n",
              "2                     Montana  [{'context': 'Montana i/mɒnˈtænə/ is a state i...\n",
              "3                    Genocide  [{'context': 'The phrase \"in whole or in part\"...\n",
              "4                 Antibiotics  [{'context': 'The emergence of resistance of b...\n",
              "..                        ...                                                ...\n",
              "437                    Police  [{'context': 'A police force is a constituted ...\n",
              "438          Punjab,_Pakistan  [{'context': 'Punjab (Urdu, Punjabi: پنجاب, pa...\n",
              "439                 Infection  [{'context': ' Among the vast varieties of mic...\n",
              "440                   Hunting  [{'context': 'Hunting is the practice of killi...\n",
              "441                 Kathmandu  [{'context': 'Kathmandu(/ˌkɑːtmɑːnˈduː/; Nepal...\n",
              "\n",
              "[442 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVKxOMQ8pEEg"
      },
      "source": [
        "train, test = train_test_split(data, test_size=0.2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6-zf6cV4e6"
      },
      "source": [
        "def preprocess_df(df):\r\n",
        "  temp = []\r\n",
        "  title_dict = {}\r\n",
        "  contexts = []\r\n",
        "\r\n",
        "  for i, row in df.iterrows():\r\n",
        "    for context in row['paragraphs']:\r\n",
        "      contexts.append(context['context'])\r\n",
        "      for qa in context['qas']:\r\n",
        "        question_id = qa['id']\r\n",
        "        question = qa['question']\r\n",
        "        for answer in qa['answers']:\r\n",
        "          answer_text = answer['text']\r\n",
        "          answer_start = answer['answer_start']\r\n",
        "          answer_end = answer_start+len(answer_text)\r\n",
        "          temp.append([question_id, question, answer_text, answer_start, answer_end, i, len(contexts)-1])\r\n",
        "\r\n",
        "\r\n",
        "  context_dict = dict(enumerate(contexts))\r\n",
        "\r\n",
        "  df = pd.DataFrame(temp, columns=['question_id', 'question_text', 'answer_text', 'answer_start', 'answer_end', 'title_id', 'context_id'])\r\n",
        "  \r\n",
        "  return df, context_dict\r\n",
        "\r\n",
        "train_df, train_context_dict = preprocess_df(train)\r\n",
        "test_df, test_context_dict = preprocess_df(test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtYH3UjM7M_6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "609809ec-2973-4532-ba49-9c30d80647d6"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>title_id</th>\n",
              "      <th>context_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570c2257ec8fbc190045bc62</td>\n",
              "      <td>What type of land is Antarctica considered to be?</td>\n",
              "      <td>desert</td>\n",
              "      <td>160</td>\n",
              "      <td>166</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570c2257ec8fbc190045bc63</td>\n",
              "      <td>What is Antarctica's annual precipitation alon...</td>\n",
              "      <td>200 mm (8 in)</td>\n",
              "      <td>202</td>\n",
              "      <td>215</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570c2257ec8fbc190045bc64</td>\n",
              "      <td>What is Antarctica's average temperature durin...</td>\n",
              "      <td>−63 °C (−81 °F)</td>\n",
              "      <td>392</td>\n",
              "      <td>407</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570c2257ec8fbc190045bc65</td>\n",
              "      <td>Approximately how many people live throughout ...</td>\n",
              "      <td>anywhere from 1,000 to 5,000</td>\n",
              "      <td>453</td>\n",
              "      <td>481</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570c2257ec8fbc190045bc66</td>\n",
              "      <td>What are some animals native to Antarctica?</td>\n",
              "      <td>mites, nematodes, penguins, seals and tardigrades</td>\n",
              "      <td>697</td>\n",
              "      <td>746</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69866</th>\n",
              "      <td>5706b6aa2eaba6190074ac60</td>\n",
              "      <td>In what city is the Asian and Pacific Centre f...</td>\n",
              "      <td>New Delhi</td>\n",
              "      <td>183</td>\n",
              "      <td>192</td>\n",
              "      <td>107</td>\n",
              "      <td>14967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69867</th>\n",
              "      <td>5706b6aa2eaba6190074ac61</td>\n",
              "      <td>What major city is home to most regional UN of...</td>\n",
              "      <td>New Delhi</td>\n",
              "      <td>194</td>\n",
              "      <td>203</td>\n",
              "      <td>107</td>\n",
              "      <td>14967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69868</th>\n",
              "      <td>5706b6aa2eaba6190074ac62</td>\n",
              "      <td>What is one regional UN office located in New ...</td>\n",
              "      <td>UNDP</td>\n",
              "      <td>260</td>\n",
              "      <td>264</td>\n",
              "      <td>107</td>\n",
              "      <td>14967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69869</th>\n",
              "      <td>5706b6aa2eaba6190074ac63</td>\n",
              "      <td>The regional office of the World Bank in India...</td>\n",
              "      <td>New Delhi</td>\n",
              "      <td>194</td>\n",
              "      <td>203</td>\n",
              "      <td>107</td>\n",
              "      <td>14967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69870</th>\n",
              "      <td>5706b6aa2eaba6190074ac64</td>\n",
              "      <td>The regional offices of the IMF, UNICEF, and U...</td>\n",
              "      <td>New Delhi</td>\n",
              "      <td>194</td>\n",
              "      <td>203</td>\n",
              "      <td>107</td>\n",
              "      <td>14967</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69871 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    question_id  ... context_id\n",
              "0      570c2257ec8fbc190045bc62  ...          0\n",
              "1      570c2257ec8fbc190045bc63  ...          0\n",
              "2      570c2257ec8fbc190045bc64  ...          0\n",
              "3      570c2257ec8fbc190045bc65  ...          0\n",
              "4      570c2257ec8fbc190045bc66  ...          0\n",
              "...                         ...  ...        ...\n",
              "69866  5706b6aa2eaba6190074ac60  ...      14967\n",
              "69867  5706b6aa2eaba6190074ac61  ...      14967\n",
              "69868  5706b6aa2eaba6190074ac62  ...      14967\n",
              "69869  5706b6aa2eaba6190074ac63  ...      14967\n",
              "69870  5706b6aa2eaba6190074ac64  ...      14967\n",
              "\n",
              "[69871 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaUcu-8VyTqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2048ea2f-065a-4de4-97b1-f42aecb8ed6f"
      },
      "source": [
        "import random\r\n",
        "def print_squad_sample(train_data, context_dict, line_length=120, separator_length=150):\r\n",
        "  sample = train_data.sample(frac=1).head(1)\r\n",
        "  context = context_dict[sample['context_id'].item()]\r\n",
        "  print('='*separator_length)\r\n",
        "  print('CONTEXT: ')\r\n",
        "  print('='*separator_length)\r\n",
        "  lines = [''.join(context[idx:idx+line_length]) for idx in range(0, len(context), line_length)]\r\n",
        "  for l in lines:\r\n",
        "      print(l)\r\n",
        "  #print(context)\r\n",
        "  print('='*separator_length)\r\n",
        "  questions = train_data[train_data['context_id'] == sample['context_id'].item()]\r\n",
        "  print('QUESTION:', ' '*(3*separator_length//4), 'ANSWER:')\r\n",
        "  for idx, row in questions.iterrows():\r\n",
        "    question = row.question_text\r\n",
        "    answer = row.answer_text\r\n",
        "    print(question, ' '*(3*separator_length//4-len(question)+9), answer)\r\n",
        "\r\n",
        "print_squad_sample(train_df, train_context_dict)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======================================================================================================================================================\n",
            "CONTEXT: \n",
            "======================================================================================================================================================\n",
            "About that time the \"executionist movement\" (Polish: \"egzekucja praw\"--\"execution of the laws\") began to take form. Its \n",
            "members would seek to curb the power of the magnates at the Sejm and to strengthen the power of king and country. In 156\n",
            "2 at the Sejm in Piotrków they would force the magnates to return many leased crown lands to the king, and the king to c\n",
            "reate a standing army (wojsko kwarciane). One of the most famous members of this movement was Jan Zamoyski. After his de\n",
            "ath in 1605, the movement lost its political force.\n",
            "======================================================================================================================================================\n",
            "QUESTION:                                                                                                                  ANSWER:\n",
            "What was the movement called also known as execution of laws?                                                              \"executionist movement\n",
            "What were the intentions of executionists movement?                                                                        seek to curb the power of the magnates at the Sejm and to strengthen the power of king and country\n",
            "what did the Sejm in Piotrków forced the magnates to do?                                                                   return many leased crown lands to the king,\n",
            "WHen did Jan Zamoyski. die?                                                                                                1605\n",
            "What happened when Jan Zamoyski died?                                                                                      movement lost its political force.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAzY4ocznL8v"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqrIFmrK2Igt"
      },
      "source": [
        "#Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "4cd76f42e740423a8aa9b3ca53c01245",
            "d635a85e72f54c3f95869fcd0b585a71",
            "a368e4d25ea44755bee4854ce5db6a8c",
            "60b98c33cab84804a429455de0b1efeb",
            "763bc5240ad1438e95b159a65a80726e",
            "511903d5a7224ff690027089bd613466",
            "8bbb8069719a44c18747e39e38c3395c",
            "3518db05415641aea3036d9a0d18ff8d"
          ]
        },
        "id": "i8fuDPtRNDjg",
        "outputId": "e73ed101-1086-4957-8a3d-e9f82732ebca"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\r\n",
        "\r\n",
        "# Load pre-trained model tokenizer (vocabulary)\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n",
        "\r\n",
        "print('[[CLS], [SEP]] = {}'.format(tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]'])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cd76f42e740423a8aa9b3ca53c01245",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[[CLS], [SEP]] = [101, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avVC8QotmvgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9652e0c1-57ea-43e6-ae6b-aa985f05ba4e"
      },
      "source": [
        "# Split the sentence into tokens.\r\n",
        "tokenized_text = tokenizer.tokenize(train_df['question_text'][0])\r\n",
        "\r\n",
        "# Print out the tokens.\r\n",
        "print(tokenized_text)\r\n",
        "\r\n",
        "# Map the token strings to their vocabulary indeces.\r\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\r\n",
        "\r\n",
        "# Display the words with their indeces.\r\n",
        "for tup in zip(tokenized_text, indexed_tokens):\r\n",
        "    print('{:<12} {:>_6}'.format(tup[0], tup[1]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'type', 'of', 'land', 'is', 'antarctica', 'considered', 'to', 'be', '?']\n",
            "what          2,054\n",
            "type          2,828\n",
            "of            1,997\n",
            "land          2,455\n",
            "is            2,003\n",
            "antarctica   12,615\n",
            "considered    2,641\n",
            "to            2,000\n",
            "be            2,022\n",
            "?             1,029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jayMk-aHPYVB"
      },
      "source": [
        "def from_df_to_model_dict(df, context_dict):\r\n",
        "\r\n",
        "  # initialize structures\r\n",
        "  input_ids = []\r\n",
        "  input_mask = []\r\n",
        "  input_type_ids = []\r\n",
        "  start_indexes = []\r\n",
        "  end_indexes = []\r\n",
        "\r\n",
        "  cut_counter = 0\r\n",
        "  max_iter = len(df)\r\n",
        "  for i, row in df.iterrows():\r\n",
        "\r\n",
        "    # print progress\r\n",
        "    if i % 1000 == 0 and i >0:\r\n",
        "      print(f\"\\r{i}/{max_iter}\", end=\"\")\r\n",
        "\r\n",
        "    # encode question and context\r\n",
        "    encoded_question = tokenizer.encode(row['question_text'])\r\n",
        "    encoded_context = tokenizer.encode(context_dict[row['context_id']])[1:]\r\n",
        "    \r\n",
        "    # concatenate input data \r\n",
        "    encoded_input = encoded_question + encoded_context\r\n",
        "\r\n",
        "    if len(encoded_input) > 512:\r\n",
        "      cut_counter += 1\r\n",
        "      encoded_input = encoded_input[:512]\r\n",
        "                                       \r\n",
        "    # create mask of ones\r\n",
        "    ones_mask = tf.ones_like(encoded_input)\r\n",
        "\r\n",
        "    # add padding and convert to tensor\r\n",
        "    encoded_input = tf.keras.preprocessing.sequence.pad_sequences([encoded_input], maxlen=512, padding='pre')\r\n",
        "    encoded_input = tf.squeeze(tf.convert_to_tensor(encoded_input))\r\n",
        "\r\n",
        "    # create input_type_ids\r\n",
        "    type_ids = tf.concat([tf.zeros_like(encoded_question, dtype=tf.int32), \r\n",
        "                          tf.ones_like(encoded_context, dtype=tf.int32)], \r\n",
        "                         axis=-1)\r\n",
        "\r\n",
        "    type_ids = tf.keras.preprocessing.sequence.pad_sequences([type_ids], maxlen=512, padding='pre')\r\n",
        "    type_ids = tf.squeeze(tf.convert_to_tensor(type_ids))\r\n",
        "\r\n",
        "    # create mask of zeros\r\n",
        "    zeros_mask = tf.zeros(tf.shape(encoded_input)[-1]-tf.shape(ones_mask)[-1], dtype=tf.int32)\r\n",
        "    mask = tf.concat([zeros_mask, ones_mask], axis=-1)\r\n",
        "\r\n",
        "    # append elements to lists\r\n",
        "    input_ids.append(encoded_input)\r\n",
        "    input_mask.append(mask)\r\n",
        "    input_type_ids.append(type_ids)\r\n",
        "\r\n",
        "    tokenized_answer = tokenizer.encode(row['answer_text'])[1: -1]\r\n",
        "    start_idx = list(encoded_input).index(tokenized_answer[0])\r\n",
        "    end_idx = start_idx + len(tokenized_answer)\r\n",
        "    \r\n",
        "    start_indexes.append(start_idx)\r\n",
        "    end_indexes.append(end_idx)\r\n",
        "\r\n",
        "  print(\"cut_counter: \", cut_counter)\r\n",
        "\r\n",
        "  # save input data as dictionary\r\n",
        "  inputs = {\r\n",
        "    'input_ids': tf.convert_to_tensor(input_ids),\r\n",
        "    'input_mask': tf.convert_to_tensor(input_mask),\r\n",
        "    'input_type_ids': tf.convert_to_tensor(input_type_ids)\r\n",
        "    }\r\n",
        "\r\n",
        "  return inputs, start_indexes, end_indexes"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irK7yfKKV1LU",
        "outputId": "08e545a3-f9bc-4964-9da7-be1950ad8ca8"
      },
      "source": [
        "train_dict, train_starts, train_ends = from_df_to_model_dict(train_df, train_context_dict)\r\n",
        "test_dict, test_starts, test_ends = from_df_to_model_dict(test_df, test_context_dict)\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "  print(train_starts[i], train_ends[i])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29000/30000cut_counter:  27\n",
            "Too long sequences ids:  [10968, 10969, 10970, 10971, 10972, 17342, 17343, 17344, 17345, 18916, 18917, 18918, 18919, 18920, 19957, 19958, 19959, 19960, 19961, 19962, 19963, 19964, 27803, 27804, 27805, 27806, 27807]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8_aWHe5TLYK"
      },
      "source": [
        "# longest answer\r\n",
        "max_len = 0\r\n",
        "for answer in train_df[\"answer_text\"]:\r\n",
        "  length = len(tokenizer.encode(answer))\r\n",
        "  max_len = max(length, max_len)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7lMar1cTLTF",
        "outputId": "d963ce61-2b7f-4ea0-ad2a-32d34c5bb583",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_len"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwi3lTmMKtV0",
        "outputId": "10d43baf-a9db-4dfc-9acf-afe2c1db2468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "id = 10969\r\n",
        "context = train_context_dict[train_df[\"context_id\"][id]]\r\n",
        "question = train_df[\"question_text\"][id]\r\n",
        "print(\"id: \", id)\r\n",
        "print(\"Question: \", question)\r\n",
        "print(\"Context: \", context)\r\n",
        "\r\n",
        "print(\"\\nTokenized question len: \", len(tokenizer.encode(question)))\r\n",
        "print(\"Tokenized context len: \", len(tokenizer.encode(context)))\r\n",
        "print(\"Total length: \", len(tokenizer.encode(context) + tokenizer.encode(question)))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id:  10969\n",
            "Question:  What was the title of Aerosmith's 1987 comeback album?\n",
            "Context:  Established acts benefited from the new commercial climate, with Whitesnake's self-titled album (1987) selling over 17 million copies, outperforming anything in Coverdale's or Deep Purple's catalogue before or since. It featured the rock anthem \"Here I Go Again '87\" as one of 4 UK top 20 singles. The follow-up Slip of the Tongue (1989) went platinum, but according to critics Steve Erlwine and Greg Prato, \"it was a considerable disappointment after the across-the-board success of Whitesnake\". Aerosmith's comeback album Permanent Vacation (1987) would begin a decade long revival of their popularity. Crazy Nights (1987) by Kiss was the band's highest charting release in the US since 1979 and the highest of their career in the UK. Mötley Crüe with Girls, Girls, Girls (1987) continued their commercial success and Def Leppard with Hysteria (1987) hit their commercial peak, the latter producing seven hit singles (a record for a hard rock act). Guns N' Roses released the best-selling début of all time, Appetite for Destruction (1987). With a \"grittier\" and \"rawer\" sound than most glam metal, it produced three top 10 hits, including the number one \"Sweet Child O' Mine\". Some of the glam rock bands that formed in the mid-1980s, such as White Lion and Cinderella experienced their biggest success during this period with their respective albums Pride (1987) and Long Cold Winter (1988) both going multi-platinum and launching a series of hit singles. In the last years of the decade, the most notable successes were New Jersey (1988) by Bon Jovi, OU812 (1988) by Van Halen, Open Up and Say... Ahh! (1988) by Poison, Pump (1989) by Aerosmith, and Mötley Crüe's most commercially successful album Dr. Feelgood (1989). New Jersey spawned five Top 10 singles, a record for a hard rock act. In 1988 from 25 June to 5 November, the number one spot on the Billboard 200 album chart was held by a hard rock album for 18 out of 20 consecutive weeks; the albums were OU812, Hysteria, Appetite for Destruction, and New Jersey. A final wave of glam rock bands arrived in the late 1980s, and experienced success with multi-platinum albums and hit singles from 1989 until the early 1990s, among them Extreme, Warrant Slaughter and FireHouse. Skid Row also released their eponymous début (1989), reaching number six on the Billboard 200, but they were to be one of the last major bands that emerged in the glam rock era.\n",
            "\n",
            "Tokenized question len:  15\n",
            "Tokenized context len:  558\n",
            "Total length:  573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8bAbjzwUTmK",
        "outputId": "3ac51314-7315-4baf-dd3b-d82eabe008df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "longest_id = [10968, 10969, 10970, 10971, 10972, 17342, 17343, 17344, 17345, 18916, 18917, 18918, 18919, 18920, 19957, 19958, 19959, 19960, 19961, 19962, 19963, 19964, 27803, 27804, 27805, 27806, 27807]\r\n",
        "\r\n",
        "lengths = [len(tokenizer.tokenize(train_context_dict[train_df[\"context_id\"][id]])) for id in longest_id]\r\n",
        "print(max(lengths))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "718\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc6pIVTOKH5Y",
        "outputId": "a244d917-1710-43b3-f833-6b65915ffbea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cristo = list(range(718))\r\n",
        "\r\n",
        "# ensure to preserve all sub-sequences of length limi-stride. \r\n",
        "def split_long_sequence(my_sequence, limit, stride):\r\n",
        "  rest = my_sequence\r\n",
        "  split = []\r\n",
        "  while len(rest) > limit:\r\n",
        "    left_hand = rest[:limit]\r\n",
        "    rest = rest[stride:]\r\n",
        "    split.append(left_hand)\r\n",
        "  split.append(rest)\r\n",
        "  return split \r\n",
        "\r\n",
        "limit = 512\r\n",
        "stride = 200\r\n",
        "for s in split_long_sequence(cristo, limit=limit, stride=stride):\r\n",
        "  print(s)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511]\n",
            "[256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qot8QnBv9IWL",
        "outputId": "abbeecc0-0f48-49b9-9295-705b66baaee4"
      },
      "source": [
        "print(train_dict['input_ids'][0])\r\n",
        "print(train_dict['input_mask'][0])\r\n",
        "print(train_dict['input_type_ids'][0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "   101  2054  2828  1997  2455  2003 12615  2641  2000  2022  1029   102\n",
            "   101 12615  1010  2006  2779  1010  2003  1996  3147  4355  1010  2852\n",
            " 10458  1010  1998  3612 10458  9983  1010  1998  2038  1996  3284  2779\n",
            "  6678  1997  2035  1996 17846  1012 12615  2003  2641  1037  5532  1010\n",
            "  2007  3296 13511  1997  2069  3263  3461  1006  1022  1999  1007  2247\n",
            "  1996  3023  1998  2521  2625  9514  1012  1996  4860  1999 12615  2038\n",
            "  2584  1597  2620  2683  1012  1016  6362  1006  1597 12521  2620  1012\n",
            "  1020  8157  1007  1010  2295  1996  2779  2005  1996  2353  4284  1006\n",
            "  1996  3147  4355  2112  1997  1996  2095  1007  2003  1597  2575  2509\n",
            "  6362  1006  1597  2620  2487  8157  1007  1012  2045  2024  2053  4568\n",
            "  2529  3901  1010  2021  5973  2013  1015  1010  2199  2000  1019  1010\n",
            "  2199  2111 13960  2802  1996  2095  2012  1996  2470  3703  7932  2408\n",
            "  1996  9983  1012 11767  3128  2000 12615  2421  2116  4127  1997 18670\n",
            "  1010 10327  1010 15289  1010  4264  1010  4013 16774  2050  1010  1998\n",
            "  3056  4176  1010  2107  2004 10210  2229  1010 11265 18900 19847  1010\n",
            " 18134  1010 13945  1998 16985  4305 24170  2015  1012 10072  1010  2073\n",
            "  2009  5158  1010  2003 27112  7265  1012   102], shape=(512,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(512,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(512,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_8US87gI9Ry",
        "outputId": "fb48022a-b4ed-49f4-9b55-bfa8f1bdb11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text = \"porca la madonna quella zozzona\"\r\n",
        "tokenizer.encode(text) + tokenizer.encode(text)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 18499,\n",
              " 3540,\n",
              " 2474,\n",
              " 11284,\n",
              " 10861,\n",
              " 4571,\n",
              " 1062,\n",
              " 18153,\n",
              " 11597,\n",
              " 2050,\n",
              " 102,\n",
              " 101,\n",
              " 18499,\n",
              " 3540,\n",
              " 2474,\n",
              " 11284,\n",
              " 10861,\n",
              " 4571,\n",
              " 1062,\n",
              " 18153,\n",
              " 11597,\n",
              " 2050,\n",
              " 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGDtxXJIzt6a"
      },
      "source": [
        "# Set up epochs and steps\r\n",
        "epochs = 3\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "train_data_size = len(train_dict['input_ids'])\r\n",
        "test_data_size = len(test_dict['input_ids'])\r\n",
        "train_steps_per_epoch = int(train_data_size / batch_size)\r\n",
        "test_steps_per_epoch = int(test_data_size / batch_size)\r\n",
        "\r\n",
        "# creates an optimizer with learning rate schedule\r\n",
        "# optimizer = nlp.optimization.create_optimizer(\r\n",
        "#     2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "905c8315acb842168afc8522d30689f1",
            "b9d7dc7cb46f45b79f93b18b5f6df11c",
            "688fc3d034f64ca2bb5e24ca507ee100",
            "21690099fb2846c58469b152c34b0367",
            "2548b6ba9a6c4942849c02d647d671bb",
            "42f7146e656f422a8e6961f5325fbe2a",
            "c5fd3df50b6b46f094e7c4832bd41352",
            "2d775dd441d0437e86a0e6348b5264dc",
            "ae99f967d1af4afeb65afb34d9c45e2d",
            "e916e523cc3c484a95a19954d5b9df4a",
            "fc3d7b1208a2496ba06edbb9cf681b6e",
            "d73b2eac3ecc48709f3b4150e3b455c5",
            "8615f0855ac14c33b1b899474799c95c",
            "126a0bfb70284c91ac661865627d06e6",
            "6397c2dd5f2c4989858626463950823b",
            "4fa74a717a6344a2b5db62bff77f7b11"
          ]
        },
        "id": "Z0r7ALiMiGHw",
        "outputId": "323893d5-d63d-4f31-b199-dbab617d1e08"
      },
      "source": [
        "from transformers import TFBertModel\r\n",
        "model = TFBertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "905c8315acb842168afc8522d30689f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae99f967d1af4afeb65afb34d9c45e2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi1xVDJUjsQQ",
        "outputId": "da995aa7-21d4-411f-8162-584bdb410a09"
      },
      "source": [
        "print(train_dict['input_type_ids'].shape)\r\n",
        "print(train_dict['input_ids'].shape)\r\n",
        "print(train_dict['input_mask'].shape)\r\n",
        "\r\n",
        "print(test_dict['input_type_ids'].shape)\r\n",
        "print(test_dict['input_ids'].shape)\r\n",
        "print(test_dict['input_mask'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 512)\n",
            "(10000, 512)\n",
            "(10000, 512)\n",
            "(10000, 512)\n",
            "(10000, 512)\n",
            "(10000, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soVsuX9tht_p",
        "outputId": "9e28ec82-b1ff-4900-8ce5-f3f363c2a9f2"
      },
      "source": [
        "def train_model(train_dict, steps, batch_size=32):\r\n",
        "  for i in range(0, steps):\r\n",
        "    input = {'input_ids' : train_dict['input_ids'][i:i+batch_size],\r\n",
        "            'input_mask' : train_dict['input_mask'][i:i+batch_size],\r\n",
        "            'input_type_ids' : train_dict['input_type_ids'][i:i+batch_size]\r\n",
        "            }\r\n",
        "    print('Batch: ' + str(i+1) + '/' + str(steps))\r\n",
        "    model(input, training = True)\r\n",
        "\r\n",
        "train_model(train_dict, train_steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch: 1/312\n",
            "Batch: 2/312\n",
            "Batch: 3/312\n",
            "Batch: 4/312\n",
            "Batch: 5/312\n",
            "Batch: 6/312\n",
            "Batch: 7/312\n",
            "Batch: 8/312\n",
            "Batch: 9/312\n",
            "Batch: 10/312\n",
            "Batch: 11/312\n",
            "Batch: 12/312\n",
            "Batch: 13/312\n",
            "Batch: 14/312\n",
            "Batch: 15/312\n",
            "Batch: 16/312\n",
            "Batch: 17/312\n",
            "Batch: 18/312\n",
            "Batch: 19/312\n",
            "Batch: 20/312\n",
            "Batch: 21/312\n",
            "Batch: 22/312\n",
            "Batch: 23/312\n",
            "Batch: 24/312\n",
            "Batch: 25/312\n",
            "Batch: 26/312\n",
            "Batch: 27/312\n",
            "Batch: 28/312\n",
            "Batch: 29/312\n",
            "Batch: 30/312\n",
            "Batch: 31/312\n",
            "Batch: 32/312\n",
            "Batch: 33/312\n",
            "Batch: 34/312\n",
            "Batch: 35/312\n",
            "Batch: 36/312\n",
            "Batch: 37/312\n",
            "Batch: 38/312\n",
            "Batch: 39/312\n",
            "Batch: 40/312\n",
            "Batch: 41/312\n",
            "Batch: 42/312\n",
            "Batch: 43/312\n",
            "Batch: 44/312\n",
            "Batch: 45/312\n",
            "Batch: 46/312\n",
            "Batch: 47/312\n",
            "Batch: 48/312\n",
            "Batch: 49/312\n",
            "Batch: 50/312\n",
            "Batch: 51/312\n",
            "Batch: 52/312\n",
            "Batch: 53/312\n",
            "Batch: 54/312\n",
            "Batch: 55/312\n",
            "Batch: 56/312\n",
            "Batch: 57/312\n",
            "Batch: 58/312\n",
            "Batch: 59/312\n",
            "Batch: 60/312\n",
            "Batch: 61/312\n",
            "Batch: 62/312\n",
            "Batch: 63/312\n",
            "Batch: 64/312\n",
            "Batch: 65/312\n",
            "Batch: 66/312\n",
            "Batch: 67/312\n",
            "Batch: 68/312\n",
            "Batch: 69/312\n",
            "Batch: 70/312\n",
            "Batch: 71/312\n",
            "Batch: 72/312\n",
            "Batch: 73/312\n",
            "Batch: 74/312\n",
            "Batch: 75/312\n",
            "Batch: 76/312\n",
            "Batch: 77/312\n",
            "Batch: 78/312\n",
            "Batch: 79/312\n",
            "Batch: 80/312\n",
            "Batch: 81/312\n",
            "Batch: 82/312\n",
            "Batch: 83/312\n",
            "Batch: 84/312\n",
            "Batch: 85/312\n",
            "Batch: 86/312\n",
            "Batch: 87/312\n",
            "Batch: 88/312\n",
            "Batch: 89/312\n",
            "Batch: 90/312\n",
            "Batch: 91/312\n",
            "Batch: 92/312\n",
            "Batch: 93/312\n",
            "Batch: 94/312\n",
            "Batch: 95/312\n",
            "Batch: 96/312\n",
            "Batch: 97/312\n",
            "Batch: 98/312\n",
            "Batch: 99/312\n",
            "Batch: 100/312\n",
            "Batch: 101/312\n",
            "Batch: 102/312\n",
            "Batch: 103/312\n",
            "Batch: 104/312\n",
            "Batch: 105/312\n",
            "Batch: 106/312\n",
            "Batch: 107/312\n",
            "Batch: 108/312\n",
            "Batch: 109/312\n",
            "Batch: 110/312\n",
            "Batch: 111/312\n",
            "Batch: 112/312\n",
            "Batch: 113/312\n",
            "Batch: 114/312\n",
            "Batch: 115/312\n",
            "Batch: 116/312\n",
            "Batch: 117/312\n",
            "Batch: 118/312\n",
            "Batch: 119/312\n",
            "Batch: 120/312\n",
            "Batch: 121/312\n",
            "Batch: 122/312\n",
            "Batch: 123/312\n",
            "Batch: 124/312\n",
            "Batch: 125/312\n",
            "Batch: 126/312\n",
            "Batch: 127/312\n",
            "Batch: 128/312\n",
            "Batch: 129/312\n",
            "Batch: 130/312\n",
            "Batch: 131/312\n",
            "Batch: 132/312\n",
            "Batch: 133/312\n",
            "Batch: 134/312\n",
            "Batch: 135/312\n",
            "Batch: 136/312\n",
            "Batch: 137/312\n",
            "Batch: 138/312\n",
            "Batch: 139/312\n",
            "Batch: 140/312\n",
            "Batch: 141/312\n",
            "Batch: 142/312\n",
            "Batch: 143/312\n",
            "Batch: 144/312\n",
            "Batch: 145/312\n",
            "Batch: 146/312\n",
            "Batch: 147/312\n",
            "Batch: 148/312\n",
            "Batch: 149/312\n",
            "Batch: 150/312\n",
            "Batch: 151/312\n",
            "Batch: 152/312\n",
            "Batch: 153/312\n",
            "Batch: 154/312\n",
            "Batch: 155/312\n",
            "Batch: 156/312\n",
            "Batch: 157/312\n",
            "Batch: 158/312\n",
            "Batch: 159/312\n",
            "Batch: 160/312\n",
            "Batch: 161/312\n",
            "Batch: 162/312\n",
            "Batch: 163/312\n",
            "Batch: 164/312\n",
            "Batch: 165/312\n",
            "Batch: 166/312\n",
            "Batch: 167/312\n",
            "Batch: 168/312\n",
            "Batch: 169/312\n",
            "Batch: 170/312\n",
            "Batch: 171/312\n",
            "Batch: 172/312\n",
            "Batch: 173/312\n",
            "Batch: 174/312\n",
            "Batch: 175/312\n",
            "Batch: 176/312\n",
            "Batch: 177/312\n",
            "Batch: 178/312\n",
            "Batch: 179/312\n",
            "Batch: 180/312\n",
            "Batch: 181/312\n",
            "Batch: 182/312\n",
            "Batch: 183/312\n",
            "Batch: 184/312\n",
            "Batch: 185/312\n",
            "Batch: 186/312\n",
            "Batch: 187/312\n",
            "Batch: 188/312\n",
            "Batch: 189/312\n",
            "Batch: 190/312\n",
            "Batch: 191/312\n",
            "Batch: 192/312\n",
            "Batch: 193/312\n",
            "Batch: 194/312\n",
            "Batch: 195/312\n",
            "Batch: 196/312\n",
            "Batch: 197/312\n",
            "Batch: 198/312\n",
            "Batch: 199/312\n",
            "Batch: 200/312\n",
            "Batch: 201/312\n",
            "Batch: 202/312\n",
            "Batch: 203/312\n",
            "Batch: 204/312\n",
            "Batch: 205/312\n",
            "Batch: 206/312\n",
            "Batch: 207/312\n",
            "Batch: 208/312\n",
            "Batch: 209/312\n",
            "Batch: 210/312\n",
            "Batch: 211/312\n",
            "Batch: 212/312\n",
            "Batch: 213/312\n",
            "Batch: 214/312\n",
            "Batch: 215/312\n",
            "Batch: 216/312\n",
            "Batch: 217/312\n",
            "Batch: 218/312\n",
            "Batch: 219/312\n",
            "Batch: 220/312\n",
            "Batch: 221/312\n",
            "Batch: 222/312\n",
            "Batch: 223/312\n",
            "Batch: 224/312\n",
            "Batch: 225/312\n",
            "Batch: 226/312\n",
            "Batch: 227/312\n",
            "Batch: 228/312\n",
            "Batch: 229/312\n",
            "Batch: 230/312\n",
            "Batch: 231/312\n",
            "Batch: 232/312\n",
            "Batch: 233/312\n",
            "Batch: 234/312\n",
            "Batch: 235/312\n",
            "Batch: 236/312\n",
            "Batch: 237/312\n",
            "Batch: 238/312\n",
            "Batch: 239/312\n",
            "Batch: 240/312\n",
            "Batch: 241/312\n",
            "Batch: 242/312\n",
            "Batch: 243/312\n",
            "Batch: 244/312\n",
            "Batch: 245/312\n",
            "Batch: 246/312\n",
            "Batch: 247/312\n",
            "Batch: 248/312\n",
            "Batch: 249/312\n",
            "Batch: 250/312\n",
            "Batch: 251/312\n",
            "Batch: 252/312\n",
            "Batch: 253/312\n",
            "Batch: 254/312\n",
            "Batch: 255/312\n",
            "Batch: 256/312\n",
            "Batch: 257/312\n",
            "Batch: 258/312\n",
            "Batch: 259/312\n",
            "Batch: 260/312\n",
            "Batch: 261/312\n",
            "Batch: 262/312\n",
            "Batch: 263/312\n",
            "Batch: 264/312\n",
            "Batch: 265/312\n",
            "Batch: 266/312\n",
            "Batch: 267/312\n",
            "Batch: 268/312\n",
            "Batch: 269/312\n",
            "Batch: 270/312\n",
            "Batch: 271/312\n",
            "Batch: 272/312\n",
            "Batch: 273/312\n",
            "Batch: 274/312\n",
            "Batch: 275/312\n",
            "Batch: 276/312\n",
            "Batch: 277/312\n",
            "Batch: 278/312\n",
            "Batch: 279/312\n",
            "Batch: 280/312\n",
            "Batch: 281/312\n",
            "Batch: 282/312\n",
            "Batch: 283/312\n",
            "Batch: 284/312\n",
            "Batch: 285/312\n",
            "Batch: 286/312\n",
            "Batch: 287/312\n",
            "Batch: 288/312\n",
            "Batch: 289/312\n",
            "Batch: 290/312\n",
            "Batch: 291/312\n",
            "Batch: 292/312\n",
            "Batch: 293/312\n",
            "Batch: 294/312\n",
            "Batch: 295/312\n",
            "Batch: 296/312\n",
            "Batch: 297/312\n",
            "Batch: 298/312\n",
            "Batch: 299/312\n",
            "Batch: 300/312\n",
            "Batch: 301/312\n",
            "Batch: 302/312\n",
            "Batch: 303/312\n",
            "Batch: 304/312\n",
            "Batch: 305/312\n",
            "Batch: 306/312\n",
            "Batch: 307/312\n",
            "Batch: 308/312\n",
            "Batch: 309/312\n",
            "Batch: 310/312\n",
            "Batch: 311/312\n",
            "Batch: 312/312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjgfgSUCmRGU",
        "outputId": "07b42f8d-c7f0-4690-8530-02fa07ca32e9"
      },
      "source": [
        "def test_model(test_dict, steps, batch_size=32):\r\n",
        "  output = []\r\n",
        "\r\n",
        "  for i in range(0, steps):\r\n",
        "    input = {'input_ids' : test_dict['input_ids'][i:i+batch_size],\r\n",
        "            'input_mask' : test_dict['input_mask'][i:i+batch_size],\r\n",
        "            'input_type_ids' : test_dict['input_type_ids'][i:i+batch_size]\r\n",
        "            }\r\n",
        "    print('Batch: ' + str(i+1) + '/' + str(steps))\r\n",
        "    output.append(model(input))\r\n",
        "  \r\n",
        "  return output\r\n",
        "\r\n",
        "test_answers = test_model(test_dict, test_steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch: 1/312\n",
            "Batch: 2/312\n",
            "Batch: 3/312\n",
            "Batch: 4/312\n",
            "Batch: 5/312\n",
            "Batch: 6/312\n",
            "Batch: 7/312\n",
            "Batch: 8/312\n",
            "Batch: 9/312\n",
            "Batch: 10/312\n",
            "Batch: 11/312\n",
            "Batch: 12/312\n",
            "Batch: 13/312\n",
            "Batch: 14/312\n",
            "Batch: 15/312\n",
            "Batch: 16/312\n",
            "Batch: 17/312\n",
            "Batch: 18/312\n",
            "Batch: 19/312\n",
            "Batch: 20/312\n",
            "Batch: 21/312\n",
            "Batch: 22/312\n",
            "Batch: 23/312\n",
            "Batch: 24/312\n",
            "Batch: 25/312\n",
            "Batch: 26/312\n",
            "Batch: 27/312\n",
            "Batch: 28/312\n",
            "Batch: 29/312\n",
            "Batch: 30/312\n",
            "Batch: 31/312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3Zo7WdavAZP",
        "outputId": "cb89ba96-7793-428c-a809-ac331923a2aa"
      },
      "source": [
        "print(test_answers[0].last_hidden_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[-0.4465253   0.48536447  0.06580014 ... -0.46521625  0.41014314\n",
            "   -0.70420337]\n",
            "  [-0.6818489  -0.2513821   0.5476869  ... -0.3495175   0.79528636\n",
            "   -0.9575961 ]\n",
            "  [-0.33148208  0.00827573  0.59227216 ... -0.5239812   0.08607539\n",
            "   -1.0944345 ]\n",
            "  ...\n",
            "  [-1.0840538   0.35074574  0.7235429  ...  0.43597403  0.7232471\n",
            "   -0.30706415]\n",
            "  [-0.08872701 -1.2204639   1.1156192  ... -0.00800674 -0.06154624\n",
            "   -1.140662  ]\n",
            "  [ 0.55041736  0.35058394  0.09902531 ... -0.11558585 -0.48601955\n",
            "   -0.3842366 ]]\n",
            "\n",
            " [[-0.44596645  0.5361833   0.12666115 ... -0.4712901   0.39068177\n",
            "   -0.7523664 ]\n",
            "  [-0.51936555 -0.13520418  0.48739904 ... -0.37786257  0.79161364\n",
            "   -0.98738134]\n",
            "  [-0.2422797   0.05043562  0.59685683 ... -0.52779245  0.10194599\n",
            "   -1.0443174 ]\n",
            "  ...\n",
            "  [ 0.19997582  0.23308192 -0.20614423 ...  0.37549567 -0.14534032\n",
            "    0.47882754]\n",
            "  [-0.29459804  0.00491316 -0.3172179  ... -0.82158023  0.09964563\n",
            "   -0.937211  ]\n",
            "  [ 0.55980796  0.37440133  0.11636388 ... -0.08858828 -0.49803293\n",
            "   -0.3949921 ]]\n",
            "\n",
            " [[-0.3971096   0.55834854  0.15928122 ... -0.4930889   0.39986756\n",
            "   -0.7667159 ]\n",
            "  [-0.6039041  -0.15113147  0.52039266 ... -0.35929275  0.7514293\n",
            "   -0.9642469 ]\n",
            "  [-0.27888402  0.04955295  0.6078857  ... -0.4937016   0.07968308\n",
            "   -1.0424143 ]\n",
            "  ...\n",
            "  [ 1.2716238   0.76523113 -0.7310419  ... -0.94712365 -0.1618941\n",
            "   -0.815099  ]\n",
            "  [ 0.4921194   0.33123472  0.18119943 ... -0.15567008 -0.52356416\n",
            "   -0.38989243]\n",
            "  [ 0.5903977   0.33710968  0.07523477 ... -0.0548023  -0.4929698\n",
            "   -0.3866683 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.41343302  0.5584874   0.04579552 ... -0.5059794   0.5474481\n",
            "   -0.7425054 ]\n",
            "  [-0.47625816 -0.13601297  0.548702   ... -0.30570638  0.86248255\n",
            "   -0.93044823]\n",
            "  [-0.21789034  0.06997211  0.6952813  ... -0.49185833  0.12646656\n",
            "   -1.1424139 ]\n",
            "  ...\n",
            "  [-0.19588181  1.2556465   0.11989778 ...  0.38773704  0.23037189\n",
            "   -1.0824634 ]\n",
            "  [-0.5148717   0.3039231   0.03445739 ... -0.60662055 -0.11723022\n",
            "   -1.480084  ]\n",
            "  [ 0.6057962   0.20573823  0.06791105 ... -0.17610958 -0.43153602\n",
            "   -0.37346038]]\n",
            "\n",
            " [[-0.6218308   0.3043962   0.07802992 ... -0.2773604   0.3768834\n",
            "   -0.50988543]\n",
            "  [-0.68664676 -0.19001922  0.74798685 ... -0.32016292  0.7416032\n",
            "   -0.94287395]\n",
            "  [-0.36640066  0.09819663  0.71524477 ... -0.4141747   0.1556237\n",
            "   -1.168071  ]\n",
            "  ...\n",
            "  [ 0.56753206  0.93794394 -0.01185935 ... -1.058376    0.31732234\n",
            "   -0.19543211]\n",
            "  [-0.21385314 -0.2115477   1.4223548  ... -0.76362765  0.22268188\n",
            "   -0.37602052]\n",
            "  [ 0.45804256  0.38484114  0.22994556 ... -0.12424636 -0.56061405\n",
            "   -0.3668747 ]]\n",
            "\n",
            " [[-0.5513968   0.37449065 -0.00913489 ... -0.344908    0.339925\n",
            "   -0.5388648 ]\n",
            "  [-0.7400105  -0.12548748  0.7180364  ... -0.3495242   0.7229358\n",
            "   -0.90735686]\n",
            "  [-0.37582013  0.0816226   0.6748082  ... -0.462842    0.10532609\n",
            "   -1.1299119 ]\n",
            "  ...\n",
            "  [ 0.32011122 -0.13233097  1.1751547  ... -0.17139629  0.01740751\n",
            "   -1.5036514 ]\n",
            "  [-0.03270278 -0.1002508  -0.20115969 ... -0.3990683   0.00937145\n",
            "   -1.473174  ]\n",
            "  [ 0.5257581   0.32927382  0.1260633  ... -0.09548131 -0.5803119\n",
            "   -0.32968143]]], shape=(32, 512, 768), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45JIZXiOwP6E",
        "outputId": "38018c3a-95d1-4a26-fbc0-20a2b0659f51"
      },
      "source": [
        "idx = test_answers[0].last_hidden_state[0]\r\n",
        "idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(512, 768), dtype=float32, numpy=\n",
              "array([[-0.4465253 ,  0.48536447,  0.06580014, ..., -0.46521625,\n",
              "         0.41014314, -0.70420337],\n",
              "       [-0.6818489 , -0.2513821 ,  0.5476869 , ..., -0.3495175 ,\n",
              "         0.79528636, -0.9575961 ],\n",
              "       [-0.33148208,  0.00827573,  0.59227216, ..., -0.5239812 ,\n",
              "         0.08607539, -1.0944345 ],\n",
              "       ...,\n",
              "       [-1.0840538 ,  0.35074574,  0.7235429 , ...,  0.43597403,\n",
              "         0.7232471 , -0.30706415],\n",
              "       [-0.08872701, -1.2204639 ,  1.1156192 , ..., -0.00800674,\n",
              "        -0.06154624, -1.140662  ],\n",
              "       [ 0.55041736,  0.35058394,  0.09902531, ..., -0.11558585,\n",
              "        -0.48601955, -0.3842366 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "cm4swH2b4Ht_",
        "outputId": "4989d0ef-f9f3-4d54-b365-b03e60e5c771"
      },
      "source": [
        "tokenizer.decode(np.argmax(idx, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[unused200] [unused617] [unused303] [unused303] [unused303] [unused303] [unused268] [unused268] [unused268] [unused303] [unused268] [unused268] [unused268] [unused303] [unused268] [unused268] [unused268] [unused268] [unused303] [unused303] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused303] [unused268] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused303] [unused303] [unused268] [unused303] [unused303] [unused268] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused303] [unused268] [unused303] [unused268] [unused268] [unused303] [unused303] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused303] [unused303] [unused303] [unused303] [unused268] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused303] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused458] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused303] [unused268] [unused268] [unused268] [unused303] [unused303] [unused303] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused268] [unused200] [unused19] [unused411] [unused649] [unused403] [unused652] [unused145] [unused200] [unused396] [unused46] [unused411] [unused167] [unused624] [unused468] [unused575] [unused130] [unused550] [unused54] [unused468] [unused88] [unused652] [unused7] [unused465] [unused189] [unused468] [unused457] [unused255] [unused282] [unused550] [unused625] [unused403] [unused347] [unused282] [unused500] [unused54] [unused54] [unused12] [unused167] [unused319] [unused19] [unused29] [unused678] [unused155] [unused54] [unused468] [unused678] [unused570] [unused695] [unused12] [unused665] [unused445] [unused95] [unused167] [unused624] [unused54] [unused54] [unused54] [unused54] [unused581] [unused268] [unused54] [unused695] [unused550] [unused64] [unused14] [unused695] [unused88] [unused85] [unused54] [unused162] [unused54] [unused1] [unused465] [unused632] [unused233] [unused500] [unused162] [unused482] [unused457] [unused14] [unused227] [unused625] [unused162] [unused482] [unused713] [unused282] [unused162] [unused709] [unused236] [unused468] [unused695] [unused710] [unused598] [unused401] [unused550] [unused227] [unused401] [unused745] [unused695] [unused599] [unused585] [unused54] [unused581] [unused550] [unused91] [unused91] [unused95] [unused110] [unused673] [unused29] [unused88] [unused465] [unused430] [unused328] [unused88] [unused465] [unused88] [unused282] [unused550] [unused88] [unused347] [unused500] [unused54] [unused162] [unused54] [unused347] [unused162] [unused54] [unused322] [unused282] [unused550] [unused145] [unused200] [unused396] [unused88] [unused701] [unused575] [unused701] [unused550] [unused701] [unused468] [unused468] [unused268] [unused601] [unused701] [unused374] [unused571] [unused733] [unused701] [unused537] [unused145]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uISxKA-ByHkU"
      },
      "source": [
        "int_indexes = []\r\n",
        "for id in idx:\r\n",
        "  int_indexes.append([id[-2], id[-1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f554jQCD2k9u",
        "outputId": "9774b168-08ce-46f7-8cf8-1d4bb74d7952"
      },
      "source": [
        "idx[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(768,), dtype=float32, numpy=\n",
              "array([-4.46525306e-01,  4.85364467e-01,  6.58001378e-02,  4.71078724e-01,\n",
              "       -4.78263587e-01, -1.06993869e-01,  1.12684917e+00, -3.90133917e-01,\n",
              "        1.38233513e-01,  1.15629986e-01, -1.96294591e-01, -6.29772484e-01,\n",
              "       -2.84878433e-01,  5.34518957e-01,  5.14786899e-01,  4.44629073e-01,\n",
              "        1.03844553e-01,  6.91295564e-01, -2.27408230e-01,  9.72810313e-02,\n",
              "        4.71048623e-01, -7.89988190e-02,  7.51327097e-01,  1.58075243e-01,\n",
              "       -6.11185990e-02,  1.17476657e-02, -2.52782345e-01, -1.48210025e+00,\n",
              "       -7.44268894e-01, -1.95111185e-01, -5.63248217e-01,  7.19994545e-01,\n",
              "       -1.90814175e-02, -5.12300432e-01,  4.11216706e-01, -2.07561985e-01,\n",
              "       -4.91175473e-01, -2.02412933e-01,  8.61362278e-01, -1.97490662e-01,\n",
              "       -1.84415698e-01, -4.09926832e-01,  5.78411400e-01, -8.86907354e-02,\n",
              "       -3.24657738e-01, -1.69748947e-01, -3.83694077e+00,  1.88484922e-01,\n",
              "       -4.50488269e-01, -9.69166040e-01, -1.16077825e-01, -4.98630464e-01,\n",
              "        1.22619748e-01,  2.20151424e-01, -2.49791563e-01,  6.11157179e-01,\n",
              "        9.21866819e-02, -7.41670132e-01,  1.84634280e+00,  1.16621099e-01,\n",
              "       -1.22311972e-01,  5.59438109e-01, -6.42976165e-01,  5.15684843e-01,\n",
              "       -4.67163503e-01,  1.05076158e+00, -8.90154988e-02, -2.87455797e-01,\n",
              "       -4.89382803e-01, -3.69537771e-02,  1.11972228e-01,  5.21442235e-01,\n",
              "        8.86670947e-01,  3.06124687e-01,  1.01026624e-01, -6.83033094e-02,\n",
              "       -3.50445807e-01,  1.05596566e+00, -5.88037968e-01, -4.39052016e-01,\n",
              "        1.56909466e-01,  1.17919877e-01, -3.18020582e-02, -8.83968234e-01,\n",
              "        3.55015665e-01,  4.09642816e-01,  4.83175427e-01, -7.69969702e-01,\n",
              "       -5.33152759e-01,  1.74328342e-01,  5.26997268e-01,  3.49609554e-01,\n",
              "        9.91157055e-01,  3.88350606e-01, -1.83365062e-01,  2.47612372e-01,\n",
              "        4.29550618e-01,  1.04476131e-01,  5.26708543e-01, -4.43768576e-02,\n",
              "       -2.93830067e-01,  7.41389036e-01,  2.58476913e-01, -6.43098831e-01,\n",
              "       -3.02254856e-01,  3.97992909e-01, -1.58162510e+00,  7.88053572e-01,\n",
              "       -6.32019401e-01,  2.78999773e-03,  7.43068755e-04,  5.15521049e-01,\n",
              "       -5.73485076e-01, -1.47278905e-01,  7.48762727e-01,  1.42048523e-02,\n",
              "        6.21083558e-01, -4.41617042e-01,  5.92673898e-01, -4.56220329e-01,\n",
              "        1.62410766e-01,  2.53824711e-01, -7.13986717e-03,  2.20286265e-01,\n",
              "       -1.32979527e-01,  3.56600821e-01,  1.13120139e-01, -1.34244525e+00,\n",
              "        5.05889654e-01,  1.05277872e+00, -2.91635364e-01, -8.61508176e-02,\n",
              "       -4.15319800e-01,  9.28501338e-02, -5.37240803e-01, -8.60117972e-01,\n",
              "       -1.89885169e-01,  3.11861634e-01, -5.82216382e-02,  3.21979851e-01,\n",
              "       -1.00664198e+00, -8.76145899e-01, -2.04596937e-01, -9.01580870e-01,\n",
              "        5.02605975e-01, -4.77997571e-01,  4.50448811e-01,  2.69568145e-01,\n",
              "       -5.05704165e-01, -1.00194111e-01,  3.40683460e-01, -3.51171345e-01,\n",
              "       -7.13831306e-01, -1.20081520e+00, -5.89791536e-01, -3.68367434e-01,\n",
              "        2.64993131e-01, -3.37410003e-01,  1.80367529e-01,  1.07844472e+00,\n",
              "        7.32812658e-02,  7.78013349e-01, -1.28735721e-01,  5.87769032e-01,\n",
              "       -3.52906764e-01,  3.48735780e-01,  3.70595306e-01,  4.77792054e-01,\n",
              "        8.01074803e-02, -3.08555186e-01,  1.75795555e-02,  1.31071404e-01,\n",
              "        7.51646101e-01, -9.97111142e-01,  1.86541378e-01,  3.49333405e-01,\n",
              "        3.93749475e-01,  2.52500087e-01,  6.42822623e-01, -2.59123277e-02,\n",
              "       -4.80599344e-01, -1.17263831e-02, -3.90832946e-02, -4.77050453e-01,\n",
              "       -2.04516381e-01,  7.38591671e-01,  9.78335515e-02,  7.41326749e-01,\n",
              "       -8.22511986e-02,  2.83661783e-01, -1.71708429e+00, -6.48589849e-01,\n",
              "        1.03529108e+00,  3.37448895e-01,  5.61672688e-01,  3.34288597e-01,\n",
              "        1.99089199e-02,  4.46826756e-01, -2.34240666e-01, -4.19605792e-01,\n",
              "       -8.56262147e-02,  4.50185329e-01, -4.67951447e-01,  7.31627405e-01,\n",
              "       -2.76968963e-02,  1.87227201e+00,  2.09708035e-01, -1.76446944e-01,\n",
              "        3.01153176e-02, -2.03858346e-01, -4.73738670e-01, -1.18874490e+00,\n",
              "       -6.19555950e-01,  2.65383333e-01, -2.23275661e-01, -2.20529363e-01,\n",
              "       -5.29576600e-01, -1.81198642e-01, -1.77525729e-03,  1.38290912e-01,\n",
              "       -4.79934871e-01, -9.77054954e-01, -4.16407526e-01,  3.75192821e-01,\n",
              "       -4.06868845e-01, -6.39100671e-01, -2.07210004e-01, -3.37969303e-01,\n",
              "        5.92799366e-01, -2.01239514e+00,  2.36627087e-01, -7.90583491e-01,\n",
              "       -6.58245921e-01, -1.49974585e-01, -3.17364752e-01, -2.31467739e-01,\n",
              "        1.83057904e-01, -4.90057409e-01,  3.68393719e-01,  6.03613742e-02,\n",
              "       -1.17799804e-01,  8.71653378e-01, -1.19202122e-01, -6.22458816e-01,\n",
              "       -4.91516292e-02,  1.66675542e-03, -2.91593134e-01, -7.65301228e-01,\n",
              "        3.10450941e-01,  2.01979861e-01, -6.11825585e-02,  4.41551059e-01,\n",
              "       -1.24665357e-01,  4.37314034e-01,  2.40662828e-01,  5.79855889e-02,\n",
              "       -1.92460001e-01,  2.88527012e-01, -8.38555336e-01, -9.52952743e-01,\n",
              "       -5.80954850e-01, -4.91316058e-03, -1.39977843e-01,  3.10958713e-01,\n",
              "       -1.22545213e-01, -2.29362071e-01,  2.25545466e-01,  5.15595190e-02,\n",
              "       -5.84967971e-01, -3.51178557e-01,  2.13135481e-01, -7.11464763e-01,\n",
              "       -2.58386999e-01,  8.57948482e-01,  5.17126024e-02, -2.56517619e-01,\n",
              "        1.03537130e+00, -6.24004126e-01, -4.60153341e-01, -2.92723119e-01,\n",
              "       -2.36342736e-02, -2.20075428e-01, -8.41366529e-01,  2.85033792e-01,\n",
              "       -3.65366489e-01, -5.27811766e-01,  6.80659056e-01, -8.50692809e-01,\n",
              "        6.99280798e-01,  2.33409822e-01, -7.77134180e-01,  7.03741431e-01,\n",
              "       -2.72028983e-01,  2.98470140e-01, -2.25013435e-01, -7.95050859e-01,\n",
              "        1.15248993e-01, -4.63414729e-01,  3.58007252e-01,  8.44407916e-01,\n",
              "       -7.66476452e-01,  8.22768986e-01, -7.23922670e-01,  8.97813022e-01,\n",
              "       -7.71912485e-02,  1.02582440e-01, -8.60270709e-02,  3.36311072e-01,\n",
              "       -3.63707757e+00,  9.56425428e-01, -4.38882858e-01,  2.73028940e-01,\n",
              "        4.25036438e-02,  4.97080535e-01,  8.55385244e-01,  7.22548723e-01,\n",
              "       -4.95109975e-01,  1.21510118e-01,  4.01804864e-01,  7.80786753e-01,\n",
              "       -7.65620708e-01,  3.14659506e-01, -3.80799502e-01, -3.98247600e-01,\n",
              "        9.06319499e-01, -8.44378583e-03,  4.93602365e-01, -2.58052647e-01,\n",
              "       -5.85848927e-01, -3.91609311e-01,  8.86961102e-01, -5.87413728e-01,\n",
              "        5.27272880e-01,  1.19457856e-01, -4.34052050e-02, -3.35727334e-02,\n",
              "        3.50780822e-02,  2.90820956e-01, -6.16114974e-01, -6.97646916e-01,\n",
              "        1.22476153e-01,  9.16810706e-02, -4.35930669e-01, -2.69963861e-01,\n",
              "       -1.58395529e-01, -7.80694842e-01,  4.20177251e-01, -5.36499381e-01,\n",
              "        6.56258345e-01, -9.44746435e-01, -9.30394828e-02,  6.31546974e-02,\n",
              "        4.40202862e-01, -3.43826741e-01,  1.17955841e-01,  1.27578890e+00,\n",
              "        2.80678928e-01,  4.92923111e-01, -1.70943767e-01,  5.56774497e-01,\n",
              "       -1.73037332e-02,  3.73201728e-01, -5.43605983e-01, -2.93905139e-01,\n",
              "        5.04151642e-01, -5.72956800e-01, -9.55609798e-01,  3.60829234e-01,\n",
              "        8.59735489e-01,  3.94100875e-01, -8.94595265e-01,  1.01582371e-01,\n",
              "        9.26503241e-02, -9.16468561e-01, -3.10169905e-02, -3.27655554e-01,\n",
              "       -1.10010076e+00,  4.07985300e-01, -7.11249113e-01,  9.25133675e-02,\n",
              "       -9.80594605e-02, -9.16236639e-01,  3.62044930e-01, -5.66595137e-01,\n",
              "        3.06214318e-02, -2.76707649e-01, -1.38178289e-01,  1.54744774e-01,\n",
              "       -7.52701283e-01, -2.27817968e-02,  4.23324734e-01,  7.68462896e-01,\n",
              "       -3.08850855e-01,  9.63223696e-01, -8.16604316e-01,  7.16307461e-01,\n",
              "       -3.25752378e-01,  7.26443529e-01, -2.01726064e-01, -2.39137322e-01,\n",
              "        5.12288451e-01,  2.18572721e-01, -1.30652785e-01,  8.20066690e-01,\n",
              "        5.91374457e-01,  7.35717043e-02,  7.93155015e-01,  4.23459470e-01,\n",
              "        7.22927094e-01, -3.15551341e-01, -5.04861295e-01,  6.23189628e-01,\n",
              "        2.72082448e-01, -3.38931471e-01, -5.72646499e-01, -2.32725948e-01,\n",
              "        6.91873670e-01, -4.10469532e-01, -3.08010191e-01,  2.68476129e-01,\n",
              "       -3.10580879e-01, -6.23890534e-02,  6.53765351e-02, -7.29857743e-01,\n",
              "        8.52488875e-02,  6.72276437e-01,  6.48016036e-01,  1.79170251e-01,\n",
              "       -6.49424344e-02, -5.15759170e-01, -7.90187120e-01, -4.37103271e-01,\n",
              "       -4.76971805e-01,  4.81074564e-02,  2.51642853e-01,  6.61391318e-01,\n",
              "        4.55339924e-02, -4.55957592e-01, -4.62426841e-01, -4.77613181e-01,\n",
              "       -1.56423211e+00, -1.31292716e-01,  1.08912066e-01,  2.69232184e-01,\n",
              "        1.90562919e-01, -8.00955415e-01,  3.42976809e-01, -4.58194435e-01,\n",
              "        1.05258405e+00, -3.06445539e-01, -1.08404741e-01, -1.73786238e-01,\n",
              "        1.07674249e-01,  3.40167016e-01,  6.47080123e-01, -5.17009079e-01,\n",
              "       -3.83193791e-01,  6.51307166e-01, -1.45781860e-02,  4.28600848e-01,\n",
              "        5.92833571e-03, -6.35011196e-01,  3.81885856e-01,  3.53519261e-01,\n",
              "       -4.21059549e-01, -1.91689104e-01, -6.55812562e-01, -5.53956866e-01,\n",
              "        6.87211871e-01, -8.33383203e-02, -1.37622249e+00, -6.21254504e-01,\n",
              "        9.28385675e-01,  6.15762234e-01,  7.20011711e-01, -3.68263572e-01,\n",
              "       -4.36877042e-01,  1.89853027e-01, -1.25249043e-01,  1.74061209e-01,\n",
              "       -3.96343112e-01,  2.27403298e-01, -1.36493631e-02,  3.44521403e-01,\n",
              "        9.50465024e-01, -2.57965960e-02,  4.76832688e-01, -2.02111378e-01,\n",
              "       -2.65008330e-01, -4.43439901e-01,  4.80421335e-02, -7.82693252e-02,\n",
              "        5.06537557e-01,  5.56043148e-01, -4.57054019e-01, -1.77225068e-01,\n",
              "       -7.95529187e-01,  4.21413243e-01, -8.17511305e-02,  2.48148263e-01,\n",
              "       -3.43975663e-01, -1.34177029e+00,  1.48219571e-01, -5.22321463e-01,\n",
              "        3.44697297e-01,  9.60395932e-01,  2.51657426e-01,  3.30077350e-01,\n",
              "        2.43760377e-01,  6.48576856e-01, -2.63165593e-01,  1.93755895e-01,\n",
              "        6.34878218e-01,  9.28906947e-02, -6.90409303e-01,  6.82283491e-02,\n",
              "        8.85078013e-02,  1.53516278e-01,  1.40100896e-01, -7.68733695e-02,\n",
              "        2.97991991e-01,  4.04662430e-01,  2.40797222e-01, -1.05733305e-01,\n",
              "       -1.07969709e-01, -8.67526472e-01, -5.03140271e-01,  4.48429942e-01,\n",
              "       -3.13764423e-01,  3.06934327e-01,  5.98791242e-01, -4.28691924e-01,\n",
              "       -3.10419053e-01, -2.65522718e-01, -6.04772568e-01, -3.07135820e-01,\n",
              "        8.69831681e-01, -1.15267128e-01, -5.71352899e-01,  1.54449373e-01,\n",
              "        1.03465252e-01,  6.20343328e-01, -1.35340190e+00, -1.18935220e-01,\n",
              "       -1.84613988e-01,  7.88484961e-02,  2.84039497e-01,  9.66942847e-01,\n",
              "        9.35017616e-02,  3.00051980e-02,  1.33134305e+00, -5.98070562e-01,\n",
              "        2.00185716e-01,  5.87391853e-01, -3.08616936e-01, -2.99733989e-02,\n",
              "        8.62374902e-03,  5.14781773e-02,  4.26585972e-01,  3.96077871e-01,\n",
              "       -2.28566661e-01, -4.87761587e-01,  4.27952796e-01, -2.05533415e-01,\n",
              "       -1.56340554e-01, -4.67557043e-01, -3.30963075e-01, -6.25140309e-01,\n",
              "       -4.37373668e-01,  9.29864347e-01, -1.33020729e-01,  4.55677241e-01,\n",
              "        4.95911837e-02,  1.91072375e-02,  2.81937182e-01,  1.11084545e+00,\n",
              "        3.68453205e-01, -2.01860920e-01, -8.27760398e-01,  1.65455282e-01,\n",
              "        1.47880554e-01, -8.59613493e-02, -5.37343621e-02, -8.42240229e-02,\n",
              "        6.60584927e-01, -3.51524591e-01,  7.84556508e-01, -1.02849007e+00,\n",
              "       -1.93746984e-01,  1.86822608e-01,  6.81839883e-03,  1.48525625e-01,\n",
              "        6.35732532e-01, -7.51653984e-02, -3.21491838e-01, -6.19935274e-01,\n",
              "        2.46034674e-02,  6.12681091e-01, -9.66923654e-01,  6.02025688e-01,\n",
              "       -3.96324426e-01, -3.81630380e-04,  2.62356341e-01,  8.88863444e-01,\n",
              "        4.94208112e-02, -1.50612667e-01, -7.59268105e-01,  6.05982006e-01,\n",
              "       -3.75560790e-01,  6.98129117e-01,  1.09034860e+00, -8.60258818e-01,\n",
              "       -6.92894399e-01,  5.42488694e-01, -4.78178650e-01, -1.52932182e-01,\n",
              "       -1.41508177e-01, -1.32381886e-01,  2.37372100e-01,  8.53151381e-01,\n",
              "        2.83199459e-01,  1.98659748e-02, -5.04754893e-02, -2.73932338e-01,\n",
              "       -9.01082218e-01, -4.64630902e-01, -9.34102088e-02,  9.40939069e-01,\n",
              "        3.16503271e-02,  5.98629832e-01,  4.69397783e-01, -2.81533569e-01,\n",
              "       -1.24699987e-01,  5.58721244e-01,  2.90181071e-01, -6.64957941e-01,\n",
              "       -1.02050170e-01,  8.48820806e-01, -3.98229212e-01, -1.22712922e+00,\n",
              "       -3.72835755e-01, -3.37158561e-01,  1.33153081e-01,  4.12341177e-01,\n",
              "       -5.10720551e-01, -1.45558989e+00, -5.14694571e-01,  6.32207632e-01,\n",
              "       -6.44630373e-01,  1.04397573e-02,  8.54703665e-01, -5.89659870e-01,\n",
              "       -1.24740589e+00,  8.48256573e-02,  4.71999019e-01,  1.71623319e-01,\n",
              "        1.58608407e-01, -4.08442289e-01, -5.27650416e-02,  1.46729350e-01,\n",
              "        9.16565895e-01,  8.08348060e-01,  2.29647994e-01,  1.33636355e-01,\n",
              "       -1.50677919e-01, -7.21859396e-01, -6.35089993e-01, -1.44336134e-01,\n",
              "       -8.38927776e-02, -2.78313607e-01,  3.83393764e-01, -4.17792276e-02,\n",
              "       -4.80252564e-01, -4.20669317e-01,  3.87875855e-01,  7.10046411e-01,\n",
              "        5.95469177e-01, -4.63430941e-01,  1.28268349e+00, -3.40211093e-01,\n",
              "        1.83644928e-02, -1.76286161e-01,  7.08848894e-01,  5.62485456e-01,\n",
              "        2.86529124e-01, -2.09451392e-01, -4.07776177e-01,  2.28606731e-01,\n",
              "       -6.83002651e-01, -3.74198765e-01,  1.50657147e-01, -3.85564357e-01,\n",
              "        5.12989998e-01,  9.78273571e-01, -4.60212618e-01,  1.52290672e-01,\n",
              "        3.25308263e-01, -4.20666367e-01,  5.73403120e-01,  1.16769113e-02,\n",
              "       -5.27471960e-01,  1.60449594e-01,  2.88795441e-01,  1.05308676e+00,\n",
              "       -1.38705224e-01,  6.49748966e-02,  3.31183791e-01,  3.46759185e-02,\n",
              "        8.04586053e-01, -1.20558418e-01,  7.86161065e-01, -9.81201082e-02,\n",
              "       -8.21660459e-02, -3.98352072e-02,  1.07348666e-01,  1.01123083e+00,\n",
              "       -2.52668798e-01, -2.16622815e-01, -3.46096337e-01, -5.24828076e-01,\n",
              "        7.36106277e-01,  1.43774033e-01, -1.98940575e-01, -5.75042903e-01,\n",
              "       -1.84106708e-01,  1.13249816e-01, -2.76291706e-02, -1.39123845e+00,\n",
              "       -5.69087267e-01, -2.86135525e-01,  6.06007159e-01,  6.51685536e-01,\n",
              "        1.16237089e-01,  2.20629871e-01,  4.21816528e-01, -3.38326186e-01,\n",
              "       -7.71713793e-01,  2.92175442e-01, -6.80790901e-01,  4.75554526e-01,\n",
              "        2.87843108e-01,  2.12847739e-02, -7.81902194e-01, -2.27846786e-01,\n",
              "        9.93088245e-01,  5.07641971e-01,  7.44594336e-01, -4.29592431e-01,\n",
              "        8.68699014e-01,  5.55468500e-01,  1.26887727e+00,  2.80820519e-01,\n",
              "        4.68934000e-01, -7.16630876e-01,  1.75473571e-01, -3.01597893e-01,\n",
              "       -4.51794565e-01,  1.49562180e-01, -1.59666717e-01,  2.58286521e-02,\n",
              "        3.24248075e-01, -2.00826019e-01,  2.44580269e-01, -6.03089988e-01,\n",
              "       -1.59683287e-01, -4.65216249e-01,  4.10143137e-01, -7.04203367e-01],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "Rrl5kE6byaG-",
        "outputId": "96b75306-89d2-41d7-f6b6-d8247623f835"
      },
      "source": [
        "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(idx[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}